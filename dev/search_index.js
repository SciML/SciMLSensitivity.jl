var documenterSearchIndex = {"docs":
[{"location":"Benchmark/#Benchmarks","page":"Benchmarks","title":"Benchmarks","text":"","category":"section"},{"location":"Benchmark/#Note-on-benchmarking-and-getting-the-best-performance-out-of-the-SciML-stack's-adjoints","page":"Benchmarks","title":"Note on benchmarking and getting the best performance out of the SciML stack's adjoints","text":"","category":"section"},{"location":"Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"From our recent papers, it's clear that EnzymeVJP is the fastest, especially when the program is set up to be fully non-allocating mutating functions. Thus for all benchmarking, especially with PDEs, this should be done. Neural network libraries don't make use of mutation effectively except for SimpleChains.jl, so we recommend creating a neural ODE / universal ODE with ZygoteVJP and Flux first, but then check the correctness by moving the implementation over to SimpleChains and if possible EnzymeVJP. This can be an order of magnitude improvement (or more) in many situations over all the previous benchmarks using Zygote and Flux, and thus it's highly recommended in scenarios that require performance.","category":"page"},{"location":"Benchmark/#Vs-Torchdiffeq-1-million-and-less-ODEs","page":"Benchmarks","title":"Vs Torchdiffeq 1 million and less ODEs","text":"","category":"section"},{"location":"Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"A raw ODE solver benchmark showcases >30x performance advantage for DifferentialEquations.jl for ODEs ranging in size from 3 to nearly 1 million.","category":"page"},{"location":"Benchmark/#Vs-Torchdiffeq-on-neural-ODE-training","page":"Benchmarks","title":"Vs Torchdiffeq on neural ODE training","text":"","category":"section"},{"location":"Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"A training benchmark using the spiral ODE from the original neural ODE paper demonstrates a 100x performance advantage for DiffEqFlux in training neural ODEs.","category":"page"},{"location":"Benchmark/#Vs-torchsde-on-small-SDEs","page":"Benchmarks","title":"Vs torchsde on small SDEs","text":"","category":"section"},{"location":"Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"Using the code from torchsde's README, we demonstrated a >70,000x performance advantage over torchsde. Further benchmarking is planned, but was found to be computationally infeasible at this time.","category":"page"},{"location":"Benchmark/#A-bunch-of-adjoint-choices-on-neural-ODEs","page":"Benchmarks","title":"A bunch of adjoint choices on neural ODEs","text":"","category":"section"},{"location":"Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"Quick summary:","category":"page"},{"location":"Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"BacksolveAdjoint can be the fastest (but use with caution!); about 25% faster\nUsing ZygoteVJP is faster than other vjp choices with FastDense due to the overloads","category":"page"},{"location":"Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"using DiffEqFlux,\n    OrdinaryDiffEq, Flux, Optim, Plots, SciMLSensitivity,\n    Zygote, BenchmarkTools, Random\n\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u .^ 3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\ndudt2 = FastChain((x, p) -> x .^ 3,\n    FastDense(2, 50, tanh),\n    FastDense(50, 2))\nRandom.seed!(100)\np = initial_params(dudt2)\n\nprob_neuralode = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)\n\nfunction loss_neuralode(p)\n    pred = Array(prob_neuralode(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode, p)\n# 2.709 ms (56506 allocations: 6.62 MiB)\n\nprob_neuralode_interpolating = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps,\n    sensealg = InterpolatingAdjoint(autojacvec = ReverseDiffVJP(true)))\n\nfunction loss_neuralode_interpolating(p)\n    pred = Array(prob_neuralode_interpolating(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_interpolating, p)\n# 5.501 ms (103835 allocations: 2.57 MiB)\n\nprob_neuralode_interpolating_zygote = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps,\n    sensealg = InterpolatingAdjoint(autojacvec = ZygoteVJP()))\n\nfunction loss_neuralode_interpolating_zygote(p)\n    pred = Array(prob_neuralode_interpolating_zygote(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_interpolating_zygote, p)\n# 2.899 ms (56150 allocations: 6.61 MiB)\n\nprob_neuralode_backsolve = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps,\n    sensealg = BacksolveAdjoint(autojacvec = ReverseDiffVJP(true)))\n\nfunction loss_neuralode_backsolve(p)\n    pred = Array(prob_neuralode_backsolve(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_backsolve, p)\n# 4.871 ms (85855 allocations: 2.20 MiB)\n\nprob_neuralode_quad = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps,\n    sensealg = QuadratureAdjoint(autojacvec = ReverseDiffVJP(true)))\n\nfunction loss_neuralode_quad(p)\n    pred = Array(prob_neuralode_quad(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_quad, p)\n# 11.748 ms (79549 allocations: 3.87 MiB)\n\nprob_neuralode_backsolve_tracker = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps,\n    sensealg = BacksolveAdjoint(autojacvec = TrackerVJP()))\n\nfunction loss_neuralode_backsolve_tracker(p)\n    pred = Array(prob_neuralode_backsolve_tracker(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_backsolve_tracker, p)\n# 27.604 ms (186143 allocations: 12.22 MiB)\n\nprob_neuralode_backsolve_zygote = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps,\n    sensealg = BacksolveAdjoint(autojacvec = ZygoteVJP()))\n\nfunction loss_neuralode_backsolve_zygote(p)\n    pred = Array(prob_neuralode_backsolve_zygote(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_backsolve_zygote, p)\n# 2.091 ms (49883 allocations: 6.28 MiB)\n\nprob_neuralode_backsolve_false = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps,\n    sensealg = BacksolveAdjoint(autojacvec = ReverseDiffVJP(false)))\n\nfunction loss_neuralode_backsolve_false(p)\n    pred = Array(prob_neuralode_backsolve_false(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_backsolve_false, p)\n# 4.822 ms (9956 allocations: 1.03 MiB)\n\nprob_neuralode_tracker = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps,\n    sensealg = TrackerAdjoint())\n\nfunction loss_neuralode_tracker(p)\n    pred = Array(prob_neuralode_tracker(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_tracker, p)\n# 12.614 ms (76346 allocations: 3.12 MiB)","category":"page"},{"location":"examples/sde/optimization_sde/#Optimization-of-Stochastic-Differential-Equations","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"","category":"section"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"Here we demonstrate sensealg = ForwardDiffSensitivity() (provided by SciMLSensitivity.jl) for forward-mode automatic differentiation of a small stochastic differential equation. For large parameter equations, like neural stochastic differential equations, you should use reverse-mode automatic differentiation. However, forward-mode can be more efficient for low numbers of parameters (<100). (Note: the default is reverse-mode AD, which is more suitable for things like neural SDEs!)","category":"page"},{"location":"examples/sde/optimization_sde/#Example-1:-Fitting-Data-with-SDEs-via-Method-of-Moments-and-Parallelism","page":"Optimization of Stochastic Differential Equations","title":"Example 1: Fitting Data with SDEs via Method of Moments and Parallelism","text":"","category":"section"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"Let's do the most common scenario: fitting data. Let's say our ecological system is a stochastic process. Each time we solve this equation we get a different solution, so we need a sensible data source.","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"using DifferentialEquations, SciMLSensitivity, Plots\n\nfunction lotka_volterra!(du, u, p, t)\n    x, y = u\n    α, β, γ, δ = p\n    du[1] = dx = α * x - β * x * y\n    du[2] = dy = δ * x * y - γ * y\nend\nu0 = [1.0, 1.0]\ntspan = (0.0, 10.0)\n\nfunction multiplicative_noise!(du, u, p, t)\n    x, y = u\n    du[1] = p[5] * x\n    du[2] = p[6] * y\nend\np = [1.5, 1.0, 3.0, 1.0, 0.3, 0.3]\n\nprob = SDEProblem(lotka_volterra!, multiplicative_noise!, u0, tspan, p)\nsol = solve(prob)\nplot(sol)","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"(Image: )","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"Let's assume that we are observing the seasonal behavior of this system and have 10,000 years of data, corresponding to 10,000 observations of this timeseries. We can utilize this to get the seasonal means and variances. To simulate that scenario, we will generate 10,000 trajectories from the SDE to build our dataset:","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"using Statistics\nensembleprob = EnsembleProblem(prob)\n@time sol = solve(ensembleprob, SOSRI(), saveat = 0.1, trajectories = 10_000)\ntruemean = mean(sol, dims = 3)[:, :]\ntruevar = var(sol, dims = 3)[:, :]","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"From here, we wish to utilize the method of moments to fit the SDE's parameters. Thus our loss function will be to solve the SDE a bunch of times and compute moment equations and use these as our loss against the original series. We then plot the evolution of the means and variances to verify the fit. For example:","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"function loss(p)\n    tmp_prob = remake(prob, p = p)\n    ensembleprob = EnsembleProblem(tmp_prob)\n    tmp_sol = solve(ensembleprob, SOSRI(), saveat = 0.1, trajectories = 1000)\n    arrsol = Array(tmp_sol)\n    sum(abs2, truemean - mean(arrsol, dims = 3)) +\n    0.1sum(abs2, truevar - var(arrsol, dims = 3)),\n    arrsol\nend\n\nfunction cb2(p, l, arrsol)\n    @show p, l\n    means = mean(arrsol, dims = 3)[:, :]\n    vars = var(arrsol, dims = 3)[:, :]\n    p1 = plot(sol[1].t, means', lw = 5)\n    scatter!(p1, sol[1].t, truemean')\n    p2 = plot(sol[1].t, vars', lw = 5)\n    scatter!(p2, sol[1].t, truevar')\n    p = plot(p1, p2, layout = (2, 1))\n    display(p)\n    false\nend","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"We can then use Optimization.solve to fit the SDE:","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"using Optimization, Zygote, OptimizationFlux\npinit = [1.2, 0.8, 2.5, 0.8, 0.1, 0.1]\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, pinit)\n@time res = Optimization.solve(optprob, ADAM(0.05), callback = cb2, maxiters = 100)","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"Notice that both the parameters of the deterministic drift equations and the stochastic portion (the diffusion equation) are fit through this process! Also notice that the final fit of the moment equations is close:","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"(Image: )","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"The time for the full fitting process was:","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"250.654845 seconds (4.69 G allocations: 104.868 GiB, 11.87% gc time)","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"approximately 4 minutes.","category":"page"},{"location":"examples/sde/optimization_sde/#Example-2:-Fitting-SDEs-via-Bayesian-Quasi-Likelihood-Approaches","page":"Optimization of Stochastic Differential Equations","title":"Example 2: Fitting SDEs via Bayesian Quasi-Likelihood Approaches","text":"","category":"section"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"An inference method which can often be much more efficient is the quasi-likelihood approach. This approach matches the random likelihood of the SDE output with the random sampling of a Bayesian inference problem to more efficiently directly estimate the posterior distribution. For more information, please see the Turing.jl Bayesian Differential Equations tutorial.","category":"page"},{"location":"examples/sde/optimization_sde/#Example-3:-Controlling-SDEs-to-an-objective","page":"Optimization of Stochastic Differential Equations","title":"Example 3: Controlling SDEs to an objective","text":"","category":"section"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"In this example, we will find the parameters of the SDE that force the solution to be close to the constant 1.","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"using DifferentialEquations, DiffEqFlux, Optimization, OptimizationFlux, Plots\n\nfunction lotka_volterra!(du, u, p, t)\n    x, y = u\n    α, β, δ, γ = p\n    du[1] = dx = α * x - β * x * y\n    du[2] = dy = -δ * y + γ * x * y\nend\n\nfunction lotka_volterra_noise!(du, u, p, t)\n    du[1] = 0.1u[1]\n    du[2] = 0.1u[2]\nend\n\nu0 = [1.0, 1.0]\ntspan = (0.0, 10.0)\np = [2.2, 1.0, 2.0, 0.4]\nprob_sde = SDEProblem(lotka_volterra!, lotka_volterra_noise!, u0, tspan)\n\nfunction predict_sde(p)\n    return Array(solve(prob_sde, SOSRI(), p = p,\n        sensealg = ForwardDiffSensitivity(), saveat = 0.1))\nend\n\nloss_sde(p) = sum(abs2, x - 1 for x in predict_sde(p))","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"For this training process, because the loss function is stochastic, we will use the ADAM optimizer from Flux.jl. The Optimization.solve function is the same as before. However, to speed up the training process, we will use a global counter so that way we only plot the current results every 10 iterations. This looks like:","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"callback = function (p, l)\n    display(l)\n    remade_solution = solve(remake(prob_sde, p = p), SOSRI(), saveat = 0.1)\n    plt = plot(remade_solution, ylim = (0, 6))\n    display(plt)\n    return false\nend","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"Let's optimize","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"adtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_sde(x), adtype)\n\noptprob = Optimization.OptimizationProblem(optf, p)\nresult_sde = Optimization.solve(optprob, ADAM(0.1),\n    callback = callback, maxiters = 100)","category":"page"},{"location":"examples/sde/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"(Image: )","category":"page"},{"location":"examples/optimal_control/feedback_control/#Universal-Differential-Equations-for-Neural-Feedback-Control","page":"Universal Differential Equations for Neural Feedback Control","title":"Universal Differential Equations for Neural Feedback Control","text":"","category":"section"},{"location":"examples/optimal_control/feedback_control/","page":"Universal Differential Equations for Neural Feedback Control","title":"Universal Differential Equations for Neural Feedback Control","text":"You can also mix a known differential equation and a neural differential equation, so that the parameters and the neural network are estimated simultaneously!","category":"page"},{"location":"examples/optimal_control/feedback_control/","page":"Universal Differential Equations for Neural Feedback Control","title":"Universal Differential Equations for Neural Feedback Control","text":"We will assume that we know the dynamics of the second equation (linear dynamics), and our goal is to find a neural network that is dependent on the current state of the dynamical system that will control the second equation to stay close to 1.","category":"page"},{"location":"examples/optimal_control/feedback_control/","page":"Universal Differential Equations for Neural Feedback Control","title":"Universal Differential Equations for Neural Feedback Control","text":"using Flux, Optimization, OptimizationPolyalgorithms,\n    SciMLSensitivity, Zygote, DifferentialEquations, Plots, Random\n\nrng = Random.default_rng()\nu0 = 1.1f0\ntspan = (0.0f0, 25.0f0)\ntsteps = 0.0f0:1.0:25.0f0\n\nmodel_univ = Flux.Chain(Flux.Dense(2, 16, tanh),\n    Flux.Dense(16, 16, tanh),\n    Flux.Dense(16, 1))\n\n# The model weights are destructured into a vector of parameters\np_model, re = Flux.destructure(model_univ)\nn_weights = length(p_model)\n\n# Parameters of the second equation (linear dynamics)\np_system = Float32[0.5, -0.5]\n\np_all = [p_model; p_system]\nθ = Float32[u0; p_all]\n\nfunction dudt_univ!(du, u, p, t)\n    # Destructure the parameters\n    model_weights = p[1:n_weights]\n    α = p[end - 1]\n    β = p[end]\n\n    # The neural network outputs a control taken by the system\n    # The system then produces an output\n    model_control, system_output = u\n\n    # Dynamics of the control and system\n    dmodel_control = re(model_weights)(u)[1]\n    dsystem_output = α * system_output + β * model_control\n\n    # Update in place\n    du[1] = dmodel_control\n    du[2] = dsystem_output\nend\n\nprob_univ = ODEProblem(dudt_univ!, [0.0f0, u0], tspan, p_all)\nsol_univ = solve(prob_univ, Tsit5(), abstol = 1e-8, reltol = 1e-6)\n\nfunction predict_univ(θ)\n    return Array(solve(prob_univ, Tsit5(), u0 = [0.0f0, θ[1]], p = θ[2:end],\n        sensealg = InterpolatingAdjoint(autojacvec = ReverseDiffVJP(true)),\n        saveat = tsteps))\nend\n\nloss_univ(θ) = sum(abs2, predict_univ(θ)[2, :] .- 1)\nl = loss_univ(θ)","category":"page"},{"location":"examples/optimal_control/feedback_control/","page":"Universal Differential Equations for Neural Feedback Control","title":"Universal Differential Equations for Neural Feedback Control","text":"list_plots = []\niter = 0\ncallback = function (θ, l)\n    global list_plots, iter\n\n    if iter == 0\n        list_plots = []\n    end\n    iter += 1\n\n    println(l)\n\n    plt = plot(predict_univ(θ)', ylim = (0, 6))\n    push!(list_plots, plt)\n    display(plt)\n    return false\nend","category":"page"},{"location":"examples/optimal_control/feedback_control/","page":"Universal Differential Equations for Neural Feedback Control","title":"Universal Differential Equations for Neural Feedback Control","text":"adtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_univ(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, θ)\nresult_univ = Optimization.solve(optprob, PolyOpt(),\n    callback = callback)","category":"page"},{"location":"tutorials/training_tips/local_minima/#Strategies-to-Avoid-Local-Minima","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"","category":"section"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"Local minima can be an issue with fitting neural differential equations. However, there are many strategies to avoid local minima:","category":"page"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"Insert stochasticity into the loss function through minibatching\nWeigh the loss function to allow for fitting earlier portions first\nIteratively grow the fit\nTraining the initial conditions and the parameters to start","category":"page"},{"location":"tutorials/training_tips/local_minima/#Iterative-Growing-Of-Fits-to-Reduce-Probability-of-Bad-Local-Minima","page":"Strategies to Avoid Local Minima","title":"Iterative Growing Of Fits to Reduce Probability of Bad Local Minima","text":"","category":"section"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"In this example, we will show how to use strategy (4) in order to increase the robustness of the fit. Let's start with the same neural ODE example we've used before, except with one small twist: we wish to find the neural ODE that fits on (0,5.0). Naively, we use the same training strategy as before:","category":"page"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"using DifferentialEquations,\n    ComponentArrays, SciMLSensitivity, Optimization,\n    OptimizationFlux\nusing Lux, Plots, Random\n\nrng = Random.default_rng()\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 5.0f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = Float32[-0.1 2.0; -2.0 -0.1]\n    du .= ((u .^ 3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\ndudt2 = Lux.Chain(x -> x .^ 3,\n    Lux.Dense(2, 16, tanh),\n    Lux.Dense(16, 2))\n\npinit, st = Lux.setup(rng, dudt2)\npinit = ComponentArray(pinit)\n\nfunction neuralode_f(u, p, t)\n    dudt2(u, p, st)[1]\nend\n\nfunction predict_neuralode(p)\n    prob = ODEProblem(neuralode_f, u0, tspan, p)\n    sol = solve(prob, Vern7(), saveat = tsteps, abstol = 1e-6, reltol = 1e-6)\n    Array(sol)\nend\n\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, (ode_data[:, 1:size(pred, 2)] .- pred))\n    return loss, pred\nend\n\niter = 0\ncallback = function (p, l, pred; doplot = false)\n    global iter\n    iter += 1\n\n    println(l)\n    if doplot\n        # plot current prediction against data\n        plt = scatter(tsteps[1:size(pred, 2)], ode_data[1, 1:size(pred, 2)], label = \"data\")\n        scatter!(plt, tsteps[1:size(pred, 2)], pred[1, :], label = \"prediction\")\n        display(plot(plt))\n    end\n\n    return false\nend\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_neuralode(x), adtype)\n\noptprob = Optimization.OptimizationProblem(optf, pinit)\nresult_neuralode = Optimization.solve(optprob,\n    ADAM(0.05), callback = callback,\n    maxiters = 300)\n\npred = predict_neuralode(result_neuralode.u)\nplt = scatter(tsteps[1:size(pred, 2)], ode_data[1, 1:size(pred, 2)], label = \"data\")\nscatter!(plt, tsteps[1:size(pred, 2)], pred[1, :], label = \"prediction\")","category":"page"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"However, we've now fallen into a trap of a local minimum. If the optimizer changes the parameters, so it dips early, it will increase the loss because there will be more error in the later parts of the time series. Thus it tends to just stay flat and never fit perfectly. This thus suggests strategies (2) and (3): do not allow the later parts of the time series to influence the fit until the later stages. Strategy (3) seems more robust, so this is what will be demonstrated.","category":"page"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"Let's start by reducing the timespan to (0,1.5):","category":"page"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"function predict_neuralode(p)\n    prob = ODEProblem(neuralode_f, u0, (0.0f0, 1.5f0), p)\n    sol = solve(prob, Vern7(), saveat = tsteps, abstol = 1e-6, reltol = 1e-6)\n    Array(sol)\nend\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_neuralode(x), adtype)\n\noptprob = Optimization.OptimizationProblem(optf, pinit)\nresult_neuralode2 = Optimization.solve(optprob,\n    ADAM(0.05), callback = callback,\n    maxiters = 300)\n\npred = predict_neuralode(result_neuralode2.u)\nplt = scatter(tsteps[1:size(pred, 2)], ode_data[1, 1:size(pred, 2)], label = \"data\")\nscatter!(plt, tsteps[1:size(pred, 2)], pred[1, :], label = \"prediction\")","category":"page"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"This fits beautifully. Now let's grow the timespan and utilize the parameters from our (0,1.5) fit as the initial condition to our next fit:","category":"page"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"function predict_neuralode(p)\n    prob = ODEProblem(neuralode_f, u0, (0.0f0, 3.0f0), p)\n    sol = solve(prob, Vern7(), saveat = tsteps, abstol = 1e-6, reltol = 1e-6)\n    Array(sol)\nend\n\noptprob = Optimization.OptimizationProblem(optf, result_neuralode2.u)\nresult_neuralode3 = Optimization.solve(optprob,\n    ADAM(0.05), maxiters = 300,\n    callback = callback)\n\npred = predict_neuralode(result_neuralode3.u)\nplt = scatter(tsteps[1:size(pred, 2)], ode_data[1, 1:size(pred, 2)], label = \"data\")\nscatter!(plt, tsteps[1:size(pred, 2)], pred[1, :], label = \"prediction\")","category":"page"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"Once again, a great fit. Now we utilize these parameters as the initial condition to the full fit:","category":"page"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"function predict_neuralode(p)\n    prob = ODEProblem(neuralode_f, u0, (0.0f0, 5.0f0), p)\n    sol = solve(prob, Vern7(), saveat = tsteps, abstol = 1e-6, reltol = 1e-6)\n    Array(sol)\nend\n\noptprob = Optimization.OptimizationProblem(optf, result_neuralode3.u)\nresult_neuralode4 = Optimization.solve(optprob,\n    ADAM(0.01), maxiters = 500,\n    callback = callback)\n\npred = predict_neuralode(result_neuralode4.u)\nplt = scatter(tsteps[1:size(pred, 2)], ode_data[1, 1:size(pred, 2)], label = \"data\")\nscatter!(plt, tsteps[1:size(pred, 2)], pred[1, :], label = \"prediction\")","category":"page"},{"location":"tutorials/training_tips/local_minima/#Training-both-the-initial-conditions-and-the-parameters-to-start","page":"Strategies to Avoid Local Minima","title":"Training both the initial conditions and the parameters to start","text":"","category":"section"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"In this example, we will show how to use strategy (4) in order to accomplish the same goal, except rather than growing the trajectory iteratively, we can train on the whole trajectory. We do this by allowing the neural ODE to learn both the initial conditions and parameters to start, and then reset the initial conditions back and train only the parameters. Note: this strategy is demonstrated for the (0, 5) time span and (0, 10), any longer and more iterations will be required. Alternatively, one could use a mix of (4) and (5), or breaking up the trajectory into chunks and just (5).","category":"page"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"using Flux, Plots, DifferentialEquations, SciMLSensitivity\n\n#Starting example with tspan (0, 5)\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 5.0f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u .^ 3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\n#Using flux here to easily demonstrate the idea, but this can be done with Optimization.solve!\ndudt2 = Chain(Dense(2, 16, tanh),\n    Dense(16, 2))\n\np, re = Flux.destructure(dudt2) # use this p as the initial condition!\ndudt(u, p, t) = re(p)(u) # need to restrcture for backprop!\nprob = ODEProblem(dudt, u0, tspan)\n\nfunction predict_n_ode()\n    Array(solve(prob, u0 = u0, p = p, saveat = tsteps))\nend\n\nfunction loss_n_ode()\n    pred = predict_n_ode()\n    sqnorm(x) = sum(abs2, x)\n    loss = sum(abs2, ode_data .- pred)\n    loss\nend\n\nfunction callback(; doplot = true) #callback function to observe training\n    pred = predict_n_ode()\n    display(sum(abs2, ode_data .- pred))\n    if doplot\n        # plot current prediction against data\n        pl = plot(tsteps, ode_data[1, :], label = \"data\")\n        plot!(pl, tsteps, pred[1, :], label = \"prediction\")\n        display(plot(pl))\n    end\n    return false\nend\npredict_n_ode()\nloss_n_ode()\ncallback()\n\ndata = Iterators.repeated((), 1000)\n\n#Specify to flux to include both the initial conditions (IC) and parameters of the NODE to train\nFlux.train!(loss_n_ode, Flux.params(u0, p), data,\n    Flux.Optimise.ADAM(0.05), cb = callback)\n\n#Here we reset the IC back to the original and train only the NODE parameters\nu0 = Float32[2.0; 0.0]\nFlux.train!(loss_n_ode, Flux.params(p), data,\n    Flux.Optimise.ADAM(0.05), cb = callback)\n\ncallback()\n\n#Now use the same technique for a longer tspan (0, 10)\ndatasize = 30\ntspan = (0.0f0, 10.0f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\ndudt2 = Chain(Dense(2, 16, tanh),\n    Dense(16, 2))\n\np, re = Flux.destructure(dudt2) # use this p as the initial condition!\ndudt(u, p, t) = re(p)(u) # need to restrcture for backprop!\nprob = ODEProblem(dudt, u0, tspan)\n\ndata = Iterators.repeated((), 1500)\n\nFlux.train!(loss_n_ode, Flux.params(u0, p), data,\n    Flux.Optimise.ADAM(0.05), cb = callback)\n\nu0 = Float32[2.0; 0.0]\nFlux.train!(loss_n_ode, Flux.params(p), data,\n    Flux.Optimise.ADAM(0.05), cb = callback)\n\ncallback()","category":"page"},{"location":"tutorials/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"And there we go, a set of robust strategies for fitting an equation that would otherwise get stuck in a local optima.","category":"page"},{"location":"tutorials/training_tips/multiple_nn/#Simultaneous-Fitting-of-Multiple-Neural-Networks","page":"Simultaneous Fitting of Multiple Neural Networks","title":"Simultaneous Fitting of Multiple Neural Networks","text":"","category":"section"},{"location":"tutorials/training_tips/multiple_nn/","page":"Simultaneous Fitting of Multiple Neural Networks","title":"Simultaneous Fitting of Multiple Neural Networks","text":"In many cases users are interested in fitting multiple neural networks or parameters simultaneously. This tutorial addresses how to perform this kind of study.","category":"page"},{"location":"tutorials/training_tips/multiple_nn/","page":"Simultaneous Fitting of Multiple Neural Networks","title":"Simultaneous Fitting of Multiple Neural Networks","text":"The following is a fully working demo on the Fitzhugh-Nagumo ODE:","category":"page"},{"location":"tutorials/training_tips/multiple_nn/","page":"Simultaneous Fitting of Multiple Neural Networks","title":"Simultaneous Fitting of Multiple Neural Networks","text":"using Lux, DiffEqFlux, ComponentArrays, Optimization, OptimizationNLopt,\n    DifferentialEquations, Random\n\nrng = Random.default_rng()\nRandom.seed!(rng, 1)\n\nfunction fitz(du, u, p, t)\n    v, w = u\n    a, b, τinv, l = p\n    du[1] = v - v^3 / 3 - w + l\n    du[2] = τinv * (v + a - b * w)\nend\n\np_ = Float32[0.7, 0.8, 1 / 12.5, 0.5]\nu0 = [1.0f0; 1.0f0]\ntspan = (0.0f0, 10.0f0)\nprob = ODEProblem(fitz, u0, tspan, p_)\nsol = solve(prob, Tsit5(), saveat = 0.5)\n\n# Ideal data\nX = Array(sol)\nXₙ = X + Float32(1e-3) * randn(eltype(X), size(X))  #noisy data\n\n# For xz term\nNN_1 = Lux.Chain(Lux.Dense(2, 16, tanh), Lux.Dense(16, 1))\np1, st1 = Lux.setup(rng, NN_1)\n\n# for xy term\nNN_2 = Lux.Chain(Lux.Dense(3, 16, tanh), Lux.Dense(16, 1))\np2, st2 = Lux.setup(rng, NN_2)\nscaling_factor = 1.0f0\n\np1 = ComponentArray(p1)\np2 = ComponentArray(p2)\n\np = ComponentArray{eltype(p1)}()\np = ComponentArray(p; p1)\np = ComponentArray(p; p2)\np = ComponentArray(p; scaling_factor)\n\nfunction dudt_(u, p, t)\n    v, w = u\n    z1 = NN_1([v, w], p.p1, st1)[1]\n    z2 = NN_2([v, w, t], p.p2, st2)[1]\n    [z1[1], p.scaling_factor * z2[1]]\nend\nprob_nn = ODEProblem(dudt_, u0, tspan, p)\nsol_nn = solve(prob_nn, Tsit5(), saveat = sol.t)\n\nfunction predict(θ)\n    Array(solve(prob_nn, Vern7(), p = θ, saveat = sol.t,\n        abstol = 1e-6, reltol = 1e-6,\n        sensealg = InterpolatingAdjoint(autojacvec = ReverseDiffVJP(true))))\nend\n\n# No regularisation right now\nfunction loss(θ)\n    pred = predict(θ)\n    sum(abs2, Xₙ .- pred), pred\nend\nloss(p)\nconst losses = []\ncallback(θ, l, pred) = begin\n    push!(losses, l)\n    if length(losses) % 50 == 0\n        println(losses[end])\n    end\n    false\nend\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\n\noptprob = Optimization.OptimizationProblem(optf, p)\nres1_uode = Optimization.solve(optprob, ADAM(0.01), callback = callback, maxiters = 500)\n\noptprob2 = Optimization.OptimizationProblem(optf, res1_uode.u)\nres2_uode = Optimization.solve(optprob2, NLopt.LD_LBFGS(), maxiters = 10000,\n    callback = callback)","category":"page"},{"location":"tutorials/training_tips/multiple_nn/","page":"Simultaneous Fitting of Multiple Neural Networks","title":"Simultaneous Fitting of Multiple Neural Networks","text":"The key is that Optimization.solve acts on a single parameter vector p. Thus what we do here is concatenate all the parameters into a single ComponentVector p and then train on this parameter vector. Whenever we need to evaluate the neural networks, we dereference the vector and grab the key that corresponds to the neural network. For example, the p1 portion is p.p1, which is why the first neural network's evolution is written like NN_1([v,w], p.p1).","category":"page"},{"location":"tutorials/training_tips/multiple_nn/","page":"Simultaneous Fitting of Multiple Neural Networks","title":"Simultaneous Fitting of Multiple Neural Networks","text":"This method is flexible to use with many optimizers and in fairly optimized ways. We can also see with the scaling_factor that we can grab parameters directly out of the vector and use them as needed.","category":"page"},{"location":"examples/dae/physical_constraints/#Enforcing-Physical-Constraints-via-Universal-Differential-Algebraic-Equations","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"","category":"section"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"As shown in the stiff ODE tutorial, differential-algebraic equations (DAEs) can be used to impose physical constraints. One way to define a DAE is through an ODE with a singular mass matrix. For example, if we make Mu' = f(u) where the last row of M is all zeros, then we have a constraint defined by the right-hand side. Using NeuralODEMM, we can use this to define a neural ODE where the sum of all 3 terms must add to one. An example of this is as follows:","category":"page"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"using Lux, ComponentArrays, DiffEqFlux, Optimization, OptimizationNLopt,\n    DifferentialEquations, Plots\n\nusing Random\nrng = Random.default_rng()\n\nfunction f!(du, u, p, t)\n    y₁, y₂, y₃ = u\n    k₁, k₂, k₃ = p\n    du[1] = -k₁ * y₁ + k₃ * y₂ * y₃\n    du[2] = k₁ * y₁ - k₃ * y₂ * y₃ - k₂ * y₂^2\n    du[3] = y₁ + y₂ + y₃ - 1\n    return nothing\nend\n\nu₀ = [1.0, 0, 0]\nM = [1.0 0 0\n    0 1.0 0\n    0 0 0]\n\ntspan = (0.0, 1.0)\np = [0.04, 3e7, 1e4]\n\nstiff_func = ODEFunction(f!, mass_matrix = M)\nprob_stiff = ODEProblem(stiff_func, u₀, tspan, p)\nsol_stiff = solve(prob_stiff, Rodas5(), saveat = 0.1)\n\nnn_dudt2 = Lux.Chain(Lux.Dense(3, 64, tanh),\n    Lux.Dense(64, 2))\n\npinit, st = Lux.setup(rng, nn_dudt2)\n\nmodel_stiff_ndae = NeuralODEMM(nn_dudt2, (u, p, t) -> [u[1] + u[2] + u[3] - 1],\n    tspan, M, Rodas5(autodiff = false), saveat = 0.1)\nmodel_stiff_ndae(u₀, ComponentArray(pinit), st)\n\nfunction predict_stiff_ndae(p)\n    return model_stiff_ndae(u₀, p, st)[1]\nend\n\nfunction loss_stiff_ndae(p)\n    pred = predict_stiff_ndae(p)\n    loss = sum(abs2, Array(sol_stiff) .- pred)\n    return loss, pred\nend\n\n# callback = function (p, l, pred) #callback function to observe training\n#   display(l)\n#   return false\n# end\n\nl1 = first(loss_stiff_ndae(ComponentArray(pinit)))\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_stiff_ndae(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, ComponentArray(pinit))\nresult_stiff = Optimization.solve(optprob, NLopt.LD_LBFGS(), maxiters = 100)","category":"page"},{"location":"examples/dae/physical_constraints/#Step-by-Step-Description","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Step-by-Step Description","text":"","category":"section"},{"location":"examples/dae/physical_constraints/#Load-Packages","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Load Packages","text":"","category":"section"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"using Lux, ComponentArrays, DiffEqFlux, Optimization, OptimizationNLopt,\n    DifferentialEquations, Plots\n\nusing Random\nrng = Random.default_rng()","category":"page"},{"location":"examples/dae/physical_constraints/#Differential-Equation","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Differential Equation","text":"","category":"section"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"First, we define our differential equations as a highly stiff problem, which makes the fitting difficult.","category":"page"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"function f!(du, u, p, t)\n    y₁, y₂, y₃ = u\n    k₁, k₂, k₃ = p\n    du[1] = -k₁ * y₁ + k₃ * y₂ * y₃\n    du[2] = k₁ * y₁ - k₃ * y₂ * y₃ - k₂ * y₂^2\n    du[3] = y₁ + y₂ + y₃ - 1\n    return nothing\nend","category":"page"},{"location":"examples/dae/physical_constraints/#Parameters","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Parameters","text":"","category":"section"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"u₀ = [1.0, 0, 0]\n\nM = [1.0 0 0\n    0 1.0 0\n    0 0 0]\n\ntspan = (0.0, 1.0)\n\np = [0.04, 3e7, 1e4]","category":"page"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"u₀ = Initial Conditions\nM = Semi-explicit Mass Matrix (last row is the constraint equation and are therefore all zeros)\ntspan = Time span over which to evaluate\np = parameters k1, k2 and k3 of the differential equation above","category":"page"},{"location":"examples/dae/physical_constraints/#ODE-Function,-Problem-and-Solution","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"ODE Function, Problem and Solution","text":"","category":"section"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"We define and solve our ODE problem to generate the “labeled” data which will be used to train our Neural Network.","category":"page"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"stiff_func = ODEFunction(f!, mass_matrix = M)\nprob_stiff = ODEProblem(stiff_func, u₀, tspan, p)\nsol_stiff = solve(prob_stiff, Rodas5(), saveat = 0.1)","category":"page"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"Because this is a DAE, we need to make sure to use a compatible solver. Rodas5 works well for this example.","category":"page"},{"location":"examples/dae/physical_constraints/#Neural-Network-Layers","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Neural Network Layers","text":"","category":"section"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"Next, we create our layers using Lux.Chain. We use this instead of Flux.Chain because it is more suited to SciML applications (similarly for Lux.Dense). The input to our network will be the initial conditions fed in as u₀.","category":"page"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"nn_dudt2 = Lux.Chain(Lux.Dense(3, 64, tanh),\n    Lux.Dense(64, 2))\n\npinit, st = Lux.setup(rng, nn_dudt2)\n\nmodel_stiff_ndae = NeuralODEMM(nn_dudt2, (u, p, t) -> [u[1] + u[2] + u[3] - 1],\n    tspan, M, Rodas5(autodiff = false), saveat = 0.1)\nmodel_stiff_ndae(u₀, ComponentArray(pinit), st)","category":"page"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"Because this is a stiff problem, we have manually imposed that sum constraint via (u,p,t) -> [u[1] + u[2] + u[3] - 1], making the fitting easier.","category":"page"},{"location":"examples/dae/physical_constraints/#Prediction-Function","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Prediction Function","text":"","category":"section"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"For simplicity, we define a wrapper function that only takes in the model's parameters to make predictions.","category":"page"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"function predict_stiff_ndae(p)\n    return model_stiff_ndae(u₀, p, st)[1]\nend","category":"page"},{"location":"examples/dae/physical_constraints/#Train-Parameters","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Train Parameters","text":"","category":"section"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"Training our network requires a loss function, an optimizer, and a callback function to display the progress.","category":"page"},{"location":"examples/dae/physical_constraints/#Loss","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Loss","text":"","category":"section"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"We first make our predictions based on the current parameters, then calculate the loss from these predictions. In this case, we use least squares as our loss.","category":"page"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"function loss_stiff_ndae(p)\n    pred = predict_stiff_ndae(p)\n    loss = sum(abs2, sol_stiff .- pred)\n    return loss, pred\nend\n\nl1 = first(loss_stiff_ndae(ComponentArray(pinit)))","category":"page"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"Notice that we are feeding the parameters of model_stiff_ndae to the loss_stiff_ndae function. model_stiff_node.p are the weights of our NN and is of size 386 (4 * 64 + 65 * 2) including the biases.","category":"page"},{"location":"examples/dae/physical_constraints/#Optimizer","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Optimizer","text":"","category":"section"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"The optimizer is BFGS(see below).","category":"page"},{"location":"examples/dae/physical_constraints/#Callback","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Callback","text":"","category":"section"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"The callback function displays the loss during training.","category":"page"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"callback = function (p, l, pred) #callback function to observe training\n    display(l)\n    return false\nend","category":"page"},{"location":"examples/dae/physical_constraints/#Train","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Train","text":"","category":"section"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"Finally, training with Optimization.solve by passing: loss function, model parameters, optimizer, callback and maximum iteration.","category":"page"},{"location":"examples/dae/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"adtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_stiff_ndae(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, ComponentArray(pinit))\nresult_stiff = Optimization.solve(optprob, NLopt.LD_LBFGS(), maxiters = 100)","category":"page"},{"location":"examples/ode/second_order_neural/#Neural-Second-Order-Ordinary-Differential-Equation","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"","category":"section"},{"location":"examples/ode/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"The neural ODE focuses and finding a neural network such that:","category":"page"},{"location":"examples/ode/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"u^prime = NN(u)","category":"page"},{"location":"examples/ode/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"However, often in physics-based modeling, the key object is not the velocity but the acceleration: knowing the acceleration tells you the force field and thus the generating process for the dynamical system. Thus what we want to do is find the force, i.e.:","category":"page"},{"location":"examples/ode/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"u^primeprime = NN(u)","category":"page"},{"location":"examples/ode/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"(Note that in order to be the acceleration, we should divide the output of the neural network by the mass!)","category":"page"},{"location":"examples/ode/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"An example of training a neural network on a second order ODE is as follows:","category":"page"},{"location":"examples/ode/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"using DifferentialEquations,\n    Flux, Optimization, OptimizationFlux, RecursiveArrayTools,\n    Random\n\nu0 = Float32[0.0; 2.0]\ndu0 = Float32[0.0; 0.0]\ntspan = (0.0f0, 1.0f0)\nt = range(tspan[1], tspan[2], length = 20)\n\nmodel = Flux.Chain(Flux.Dense(2, 50, tanh), Flux.Dense(50, 2))\np, re = Flux.destructure(model)\n\nff(du, u, p, t) = re(p)(u)\nprob = SecondOrderODEProblem{false}(ff, du0, u0, tspan, p)\n\nfunction predict(p)\n    Array(solve(prob, Tsit5(), p = p, saveat = t))\nend\n\ncorrect_pos = Float32.(transpose(hcat(collect(0:0.05:1)[2:end], collect(2:-0.05:1)[2:end])))\n\nfunction loss_n_ode(p)\n    pred = predict(p)\n    sum(abs2, correct_pos .- pred[1:2, :]), pred\nend\n\ndata = Iterators.repeated((), 1000)\nopt = ADAM(0.01)\n\nl1 = loss_n_ode(p)\n\ncallback = function (p, l, pred)\n    println(l)\n    l < 0.01\nend\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_n_ode(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, p)\n\nres = Optimization.solve(optprob, opt; callback = callback, maxiters = 1000)","category":"page"},{"location":"examples/bayesian/turing_bayesian/#Bayesian-Estimation-of-Differential-Equations-with-Probabilistic-Programming","page":"Bayesian Estimation of Differential Equations with Probabilistic Programming","title":"Bayesian Estimation of Differential Equations with Probabilistic Programming","text":"","category":"section"},{"location":"examples/bayesian/turing_bayesian/","page":"Bayesian Estimation of Differential Equations with Probabilistic Programming","title":"Bayesian Estimation of Differential Equations with Probabilistic Programming","text":"For a good overview of how to use the tools of SciML in conjunction with the Turing.jl probabilistic programming language, see the Bayesian Differential Equation Tutorial.","category":"page"},{"location":"examples/dde/delay_diffeq/#Delay-Differential-Equations","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"","category":"section"},{"location":"examples/dde/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"Other differential equation problem types from DifferentialEquations.jl are supported. For example, we can build a layer with a delay differential equation like:","category":"page"},{"location":"examples/dde/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"using DifferentialEquations, Optimization, SciMLSensitivity,\n    OptimizationPolyalgorithms\n\n# Define the same LV equation, but including a delay parameter\nfunction delay_lotka_volterra!(du, u, h, p, t)\n    x, y = u\n    α, β, δ, γ = p\n    du[1] = dx = (α - β * y) * h(p, t - 0.1)[1]\n    du[2] = dy = (δ * x - γ) * y\nend\n\n# Initial parameters\np = [2.2, 1.0, 2.0, 0.4]\n\n# Define a vector containing delays for each variable (although only the first\n# one is used)\nh(p, t) = ones(eltype(p), 2)\n\n# Initial conditions\nu0 = [1.0, 1.0]\n\n# Define the problem as a delay differential equation\nprob_dde = DDEProblem(delay_lotka_volterra!, u0, h, (0.0, 10.0),\n    constant_lags = [0.1])\n\nfunction predict_dde(p)\n    return Array(solve(prob_dde, MethodOfSteps(Tsit5()),\n        u0 = u0, p = p, saveat = 0.1,\n        sensealg = ReverseDiffAdjoint()))\nend\n\nloss_dde(p) = sum(abs2, x - 1 for x in predict_dde(p))\n\nusing Plots\ncallback = function (p, l...; doplot = false)\n    display(loss_dde(p))\n    doplot &&\n        display(plot(solve(remake(prob_dde, p = p), MethodOfSteps(Tsit5()), saveat = 0.1),\n            ylim = (0, 6)))\n    return false\nend\n\ncallback(p, loss_dde(p)...)\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_dde(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, p)\nresult_dde = Optimization.solve(optprob, PolyOpt(), maxiters = 300, callback = callback)","category":"page"},{"location":"examples/dde/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"Notice that we chose sensealg = ReverseDiffAdjoint() to utilize the ReverseDiff.jl reverse-mode to handle the delay differential equation.","category":"page"},{"location":"examples/dde/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"We define a callback to display the solution at the current parameters for each step of the training:","category":"page"},{"location":"examples/dde/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"using Plots\ncallback = function (p, l...; doplot = false)\n    display(loss_dde(p))\n    doplot &&\n        display(plot(solve(remake(prob_dde, p = p), MethodOfSteps(Tsit5()), saveat = 0.1),\n            ylim = (0, 6)))\n    return false\nend\n\ncallback(p, loss_dde(p)...)","category":"page"},{"location":"examples/dde/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"We use Optimization.solve to optimize the parameters for our loss function:","category":"page"},{"location":"examples/dde/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"adtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_dde(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, p)\nresult_dde = Optimization.solve(optprob, PolyOpt(), callback = callback)","category":"page"},{"location":"examples/ode/exogenous_input/#Handling-Exogenous-Input-Signals","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"","category":"section"},{"location":"examples/ode/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"The key to using exogenous input signals is the same as in the rest of the SciML universe: just use the function in the definition of the differential equation. For example, if it's a standard differential equation, you can use the form","category":"page"},{"location":"examples/ode/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"I(t) = t^2\n\nfunction f(du, u, p, t)\n    du[1] = I(t)\n    du[2] = u[1]\nend","category":"page"},{"location":"examples/ode/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"so that I(t) is an exogenous input signal into f. Another form that could be useful is a closure. For example:","category":"page"},{"location":"examples/ode/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"function f(du, u, p, t, I)\n    du[1] = I(t)\n    du[2] = u[1]\nend\n\n_f(du, u, p, t) = f(du, u, p, t, x -> x^2)","category":"page"},{"location":"examples/ode/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"which encloses an extra argument into f so that _f is now the interface-compliant differential equation definition.","category":"page"},{"location":"examples/ode/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"Note that you can also learn what the exogenous equation is from data. For an example on how to do this, you can use the Optimal Control Example, which shows how to parameterize a u(t) by a universal function and learn that from data.","category":"page"},{"location":"examples/ode/exogenous_input/#Example-of-a-Neural-ODE-with-Exogenous-Input","page":"Handling Exogenous Input Signals","title":"Example of a Neural ODE with Exogenous Input","text":"","category":"section"},{"location":"examples/ode/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"In the following example, a discrete exogenous input signal ex is defined and used as an input into the neural network of a neural ODE system.","category":"page"},{"location":"examples/ode/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"using DifferentialEquations, Lux, ComponentArrays, DiffEqFlux, Optimization,\n    OptimizationPolyalgorithms, OptimizationFlux, Plots, Random\n\nrng = Random.default_rng()\ntspan = (0.1f0, Float32(10.0))\ntsteps = range(tspan[1], tspan[2], length = 100)\nt_vec = collect(tsteps)\nex = vec(ones(Float32, length(tsteps), 1))\nf(x) = (atan(8.0 * x - 4.0) + atan(4.0)) / (2.0 * atan(4.0))\n\nfunction hammerstein_system(u)\n    y = zeros(size(u))\n    for k in 2:length(u)\n        y[k] = 0.2 * f(u[k - 1]) + 0.8 * y[k - 1]\n    end\n    return y\nend\n\ny = Float32.(hammerstein_system(ex))\nplot(collect(tsteps), y, ticks = :native)\n\nnn_model = Lux.Chain(Lux.Dense(2, 8, tanh), Lux.Dense(8, 1))\np_model, st = Lux.setup(rng, nn_model)\n\nu0 = Float32.([0.0])\n\nfunction dudt(u, p, t)\n    global st\n    #input_val = u_vals[Int(round(t*10)+1)]\n    out, st = nn_model(vcat(u[1], ex[Int(round(10 * 0.1))]), p, st)\n    return out\nend\n\nprob = ODEProblem(dudt, u0, tspan, nothing)\n\nfunction predict_neuralode(p)\n    _prob = remake(prob, p = p)\n    Array(solve(_prob, Tsit5(), saveat = tsteps, abstol = 1e-8, reltol = 1e-6))\nend\n\nfunction loss(p)\n    sol = predict_neuralode(p)\n    N = length(sol)\n    return sum(abs2.(y[1:N] .- sol')) / N\nend\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, ComponentArray(p_model))\n\nres0 = Optimization.solve(optprob, PolyOpt(), maxiters = 100)\n\nsol = predict_neuralode(res0.u)\nplot(tsteps, sol')\nN = length(sol)\nscatter!(tsteps, y[1:N])","category":"page"},{"location":"examples/ode/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"(Image: )","category":"page"},{"location":"manual/direct_forward_sensitivity/#forward_sense","page":"Direct Forward Sensitivity Analysis of ODEs","title":"Direct Forward Sensitivity Analysis of ODEs","text":"","category":"section"},{"location":"manual/direct_forward_sensitivity/","page":"Direct Forward Sensitivity Analysis of ODEs","title":"Direct Forward Sensitivity Analysis of ODEs","text":"ODEForwardSensitivityProblem\nextract_local_sensitivities","category":"page"},{"location":"manual/direct_forward_sensitivity/#SciMLSensitivity.ODEForwardSensitivityProblem","page":"Direct Forward Sensitivity Analysis of ODEs","title":"SciMLSensitivity.ODEForwardSensitivityProblem","text":"function ODEForwardSensitivityProblem(f::Union{Function,DiffEqBase.AbstractODEFunction},                                       u0,tspan,p=nothing,                                       alg::AbstractForwardSensitivityAlgorithm = ForwardSensitivity();                                       kwargs...)\n\nLocal forward sensitivity analysis gives a solution along with a timeseries of the sensitivities. Thus, if one wishes to have a derivative at every possible time point, directly using the ODEForwardSensitivityProblem can be the most efficient method.\n\nwarning: Warning\nODEForwardSensitivityProblem requires being able to solve   a differential equation defined by the parameter struct p. Even though   DifferentialEquations.jl can support any parameter struct type, usage   with ODEForwardSensitivityProblem requires that p could be a valid   type for being the initial condition u0 of an array. This means that   many simple types, such as Tuples and NamedTuples, will work as   parameters in normal contexts but will fail during ODEForwardSensitivityProblem   construction. To work around this issue for complicated cases like nested structs,   look into defining p using AbstractArray libraries such as RecursiveArrayTools.jl   or ComponentArrays.jl.\n\nODEForwardSensitivityProblem Syntax\n\nODEForwardSensitivityProblem is similar to an ODEProblem, but takes an AbstractForwardSensitivityAlgorithm that describes how to append the forward sensitivity equation calculation to the time evolution to simultaneously compute the derivative of the solution with respect to parameters.\n\nODEForwardSensitivityProblem(f::SciMLBase.AbstractODEFunction,u0,\n                             tspan,p=nothing,\n                             sensealg::AbstractForwardSensitivityAlgorithm = ForwardSensitivity();\n                             kwargs...)\n\nOnce constructed, this problem can be used in solve just like any other ODEProblem. The solution can be deconstructed into the ODE solution and sensitivities parts using the extract_local_sensitivities function, with the following dispatches:\n\nextract_local_sensitivities(sol, asmatrix::Val=Val(false)) # Decompose the entire time series\nextract_local_sensitivities(sol, i::Integer, asmatrix::Val=Val(false)) # Decompose sol[i]\nextract_local_sensitivities(sol, t::Union{Number,AbstractVector}, asmatrix::Val=Val(false)) # Decompose sol(t)\n\nFor information on the mathematics behind these calculations, consult the sensitivity math page\n\nExample using an ODEForwardSensitivityProblem\n\nTo define a sensitivity problem, simply use the ODEForwardSensitivityProblem type instead of an ODE type. For example, we generate an ODE with the sensitivity equations attached to the Lotka-Volterra equations by:\n\nfunction f(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + u[1]*u[2]\nend\n\np = [1.5,1.0,3.0]\nprob = ODEForwardSensitivityProblem(f,[1.0;1.0],(0.0,10.0),p)\n\nThis generates a problem which the ODE solvers can solve:\n\nsol = solve(prob,DP8())\n\nNote that the solution is the standard ODE system and the sensitivity system combined. We can use the following helper functions to extract the sensitivity information:\n\nx,dp = extract_local_sensitivities(sol)\nx,dp = extract_local_sensitivities(sol,i)\nx,dp = extract_local_sensitivities(sol,t)\n\nIn each case, x is the ODE values and dp is the matrix of sensitivities The first gives the full timeseries of values and dp[i] contains the time series of the sensitivities of all components of the ODE with respect to ith parameter. The second returns the ith time step, while the third interpolates to calculate the sensitivities at time t. For example, if we do:\n\nx,dp = extract_local_sensitivities(sol)\nda = dp[1]\n\nthen da is the timeseries for fracpartial u(t)partial p. We can plot this\n\nplot(sol.t,da',lw=3)\n\ntransposing so that the rows (the timeseries) is plotted.\n\n(Image: Local Sensitivity Solution)\n\nHere we see that there is a periodicity to the sensitivity which matches the periodicity of the Lotka-Volterra solutions. However, as time goes on, the sensitivity increases. This matches the analysis of Wilkins in Sensitivity Analysis for Oscillating Dynamical Systems.\n\nWe can also quickly see that these values are equivalent to those given by automatic differentiation and numerical differentiation through the ODE solver:\n\nusing ForwardDiff, Calculus\nfunction test_f(p)\n  prob = ODEProblem(f,eltype(p).([1.0,1.0]),eltype(p).((0.0,10.0)),p)\n  solve(prob,Vern9(),abstol=1e-14,reltol=1e-14,save_everystep=false)[end]\nend\n\np = [1.5,1.0,3.0]\nfd_res = ForwardDiff.jacobian(test_f,p)\ncalc_res = Calculus.finite_difference_jacobian(test_f,p)\n\nHere we just checked the derivative at the end point.\n\nInternal representation of the Solution\n\nFor completeness, we detail the internal representation. When using ForwardDiffSensitivity, the representation is with Dual numbers under the standard interpretation. The values for the ODE's solution at time i are the ForwardDiff.value.(sol[i]) portions, and the derivative with respect to parameter j is given by ForwardDiff.partials.(sol[i])[j].\n\nWhen using ForwardSensitivity, the solution to the ODE are the first n components of the solution. This means we can grab the matrix of solution values like:\n\nx = sol[1:sol.prob.indvars,:]\n\nSince each sensitivity is a vector of derivatives for each function, the sensitivities are each of size sol.prob.indvars. We can pull out the parameter sensitivities from the solution as follows:\n\nda = sol[sol.prob.indvars+1:sol.prob.indvars*2,:]\ndb = sol[sol.prob.indvars*2+1:sol.prob.indvars*3,:]\ndc = sol[sol.prob.indvars*3+1:sol.prob.indvars*4,:]\n\nThis means that da[1,i] is the derivative of the x(t) by the parameter a at time sol.t[i]. Note that all the functionality available to ODE solutions is available in this case, including interpolations and plot recipes (the recipes will plot the expanded system).\n\n\n\n","category":"type"},{"location":"manual/direct_forward_sensitivity/#SciMLSensitivity.extract_local_sensitivities","page":"Direct Forward Sensitivity Analysis of ODEs","title":"SciMLSensitivity.extract_local_sensitivities","text":"extractlocalsensitivities\n\nExtracts the time series for the local sensitivities from the ODE solution. This requires that the ODE was defined via ODEForwardSensitivityProblem.\n\nextract_local_sensitivities(sol, asmatrix::Val = Val(false)) # Decompose the entire time series\nextract_local_sensitivities(sol, i::Integer, asmatrix::Val = Val(false)) # Decompose sol[i]\nextract_local_sensitivities(sol, t::Union{Number, AbstractVector},\n                            asmatrix::Val = Val(false)) # Decompose sol(t)\n\n\n\n\n\n","category":"function"},{"location":"examples/neural_ode/neural_ode_flux/#Neural-Ordinary-Differential-Equations-with-Flux","page":"Neural Ordinary Differential Equations with Flux","title":"Neural Ordinary Differential Equations with Flux","text":"","category":"section"},{"location":"examples/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux","title":"Neural Ordinary Differential Equations with Flux","text":"All the tools of SciMLSensitivity.jl can be used with Flux.jl. A lot of the examples have been written to use FastChain and sciml_train, but in all cases this can be changed to the Chain and Flux.train! workflow.","category":"page"},{"location":"examples/neural_ode/neural_ode_flux/#Using-Flux-Chain-neural-networks-with-Flux.train!","page":"Neural Ordinary Differential Equations with Flux","title":"Using Flux Chain neural networks with Flux.train!","text":"","category":"section"},{"location":"examples/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux","title":"Neural Ordinary Differential Equations with Flux","text":"This should work almost automatically by using solve. Here is an example of optimizing u0 and p.","category":"page"},{"location":"examples/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux","title":"Neural Ordinary Differential Equations with Flux","text":"using OrdinaryDiffEq, SciMLSensitivity, Flux, Plots\n\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u .^ 3)'true_A)'\nend\nt = range(tspan[1], tspan[2], length = datasize)\nprob = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob, Tsit5(), saveat = t))\n\ndudt2 = Flux.Chain(x -> x .^ 3,\n    Flux.Dense(2, 50, tanh),\n    Flux.Dense(50, 2))\np, re = Flux.destructure(dudt2) # use this p as the initial condition!\ndudt(u, p, t) = re(p)(u) # need to restrcture for backprop!\nprob = ODEProblem(dudt, u0, tspan)\n\nfunction predict_n_ode()\n    Array(solve(prob, Tsit5(), u0 = u0, p = p, saveat = t))\nend\n\nfunction loss_n_ode()\n    pred = predict_n_ode()\n    loss = sum(abs2, ode_data .- pred)\n    loss\nend\n\nloss_n_ode() # n_ode.p stores the initial parameters of the neural ODE\n\ncallback = function (; doplot = false) #callback function to observe training\n    pred = predict_n_ode()\n    display(sum(abs2, ode_data .- pred))\n    # plot current prediction against data\n    pl = scatter(t, ode_data[1, :], label = \"data\")\n    scatter!(pl, t, pred[1, :], label = \"prediction\")\n    display(plot(pl))\n    return false\nend\n\n# Display the ODE with the initial parameter values.\ncallback()\n\ndata = Iterators.repeated((), 1000)\nres1 = Flux.train!(loss_n_ode, Flux.params(u0, p), data, ADAM(0.05), cb = callback)\n\ncallback()","category":"page"},{"location":"examples/neural_ode/neural_ode_flux/#Using-Flux-Chain-neural-networks-with-Optimization.jl","page":"Neural Ordinary Differential Equations with Flux","title":"Using Flux Chain neural networks with Optimization.jl","text":"","category":"section"},{"location":"examples/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux","title":"Neural Ordinary Differential Equations with Flux","text":"Flux neural networks can be used with Optimization.jl by using the Flux.destructure function. In this case, if dudt is a Flux chain, then:","category":"page"},{"location":"examples/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux","title":"Neural Ordinary Differential Equations with Flux","text":"p, re = Flux.destructure(chain)","category":"page"},{"location":"examples/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux","title":"Neural Ordinary Differential Equations with Flux","text":"returns p which is the vector of parameters for the chain and re which is a function re(p) that reconstructs the neural network with new parameters p. Using this function, we can thus build our neural differential equations in an explicit parameter style.","category":"page"},{"location":"examples/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux","title":"Neural Ordinary Differential Equations with Flux","text":"Let's use this to build and train a neural ODE from scratch. In this example, we will optimize both the neural network parameters p and the input initial condition u0. Notice that Optimization.jl works on a vector input, so we have to concatenate u0 and p and then in the loss function split to the pieces.","category":"page"},{"location":"examples/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux","title":"Neural Ordinary Differential Equations with Flux","text":"using Flux, OrdinaryDiffEq, SciMLSensitivity, Optimization, OptimizationOptimisers,\n    OptimizationNLopt, Plots\n\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u .^ 3)'true_A)'\nend\nt = range(tspan[1], tspan[2], length = datasize)\nprob = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob, Tsit5(), saveat = t))\n\ndudt2 = Flux.Chain(x -> x .^ 3,\n    Flux.Dense(2, 50, tanh),\n    Flux.Dense(50, 2))\np, re = Flux.destructure(dudt2) # use this p as the initial condition!\ndudt(u, p, t) = re(p)(u) # need to restrcture for backprop!\nprob = ODEProblem(dudt, u0, tspan)\n\nθ = [u0; p] # the parameter vector to optimize\n\nfunction predict_n_ode(θ)\n    Array(solve(prob, Tsit5(), u0 = θ[1:2], p = θ[3:end], saveat = t))\nend\n\nfunction loss_n_ode(θ)\n    pred = predict_n_ode(θ)\n    loss = sum(abs2, ode_data .- pred)\n    loss, pred\nend\n\nloss_n_ode(θ)\n\ncallback = function (θ, l, pred; doplot = false) #callback function to observe training\n    display(l)\n    # plot current prediction against data\n    pl = scatter(t, ode_data[1, :], label = \"data\")\n    scatter!(pl, t, pred[1, :], label = \"prediction\")\n    display(plot(pl))\n    return false\nend\n\n# Display the ODE with the initial parameter values.\ncallback(θ, loss_n_ode(θ)...)\n\n# use Optimization.jl to solve the problem\nadtype = Optimization.AutoZygote()\n\noptf = Optimization.OptimizationFunction((p, _) -> loss_n_ode(p), adtype)\noptprob = Optimization.OptimizationProblem(optf, θ)\n\nresult_neuralode = Optimization.solve(optprob,\n    OptimizationOptimisers.Adam(0.05),\n    callback = callback,\n    maxiters = 300)","category":"page"},{"location":"examples/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux","title":"Neural Ordinary Differential Equations with Flux","text":"Notice that the advantage of this format is that we can use Optim's optimizers, like LBFGS with a full Chain object, for all of Flux's neural networks, like convolutional neural networks.","category":"page"},{"location":"examples/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux","title":"Neural Ordinary Differential Equations with Flux","text":"(Image: )","category":"page"},{"location":"manual/direct_adjoint_sensitivities/#adjoint_sense","page":"Direct Adjoint Sensitivities of Differential Equations","title":"Direct Adjoint Sensitivities of Differential Equations","text":"","category":"section"},{"location":"manual/direct_adjoint_sensitivities/#First-Order-Adjoint-Sensitivities","page":"Direct Adjoint Sensitivities of Differential Equations","title":"First Order Adjoint Sensitivities","text":"","category":"section"},{"location":"manual/direct_adjoint_sensitivities/","page":"Direct Adjoint Sensitivities of Differential Equations","title":"Direct Adjoint Sensitivities of Differential Equations","text":"adjoint_sensitivities","category":"page"},{"location":"manual/direct_adjoint_sensitivities/#SciMLSensitivity.adjoint_sensitivities","page":"Direct Adjoint Sensitivities of Differential Equations","title":"SciMLSensitivity.adjoint_sensitivities","text":"adjoint_sensitivities(sol,alg;t=nothing,\n                            dgdu_discrete = nothing, dgdp_discrete = nothing,\n                            dgdu_continuous = nothing, dgdp_continuous = nothing,\n                            g=nothing,\n                            abstol=1e-6,reltol=1e-3,\n                            checkpoints=sol.t,\n                            corfunc_analytical=nothing,\n                            callback = nothing,\n                            sensealg=InterpolatingAdjoint(),\n                            kwargs...)\n\nAdjoint sensitivity analysis is used to find the gradient of the solution with respect to some functional of the solution. Often, this is used in an optimization problem to return the gradient with respect to some cost function. It is equivalent to \"backpropagation\" or reverse-mode automatic differentiation of a differential equation.\n\nUsing adjoint_sensitivities directly lets you do three things. First, it can allow you to be more efficient, since the sensitivity calculation can be done directly on a cost function, avoiding the overhead of building the derivative of the full concretized solution. It can also allow you to be more efficient by directly controlling the forward solve that is then reversed over. Lastly, it allows one to define a continuous cost function on the continuous solution, instead of just at discrete data points.\n\nwarning: Warning\nAdjoint sensitivity analysis functionality requires being able to solve   a differential equation defined by the parameter struct p. Even though   DifferentialEquations.jl can support any parameter struct type, usage   with adjoint sensitivity analysis requires that p could be a valid   type for being the initial condition u0 of an array. This means that   many simple types, such as Tuples and NamedTuples, will work as   parameters in normal contexts but will fail during adjoint differentiation.   To work around this issue for complicated cases like nested structs, look   into defining p using AbstractArray libraries such as RecursiveArrayTools.jl   or ComponentArrays.jl so that p is an AbstractArray with a concrete element type.\n\nwarning: Warning\nNon-checkpointed InterpolatingAdjoint and QuadratureAdjoint sensealgs   require that the forward solution sol(t) has an accurate dense   solution unless checkpointing is used. This means that you should   not use solve(prob,alg,saveat=ts) unless checkpointing. If specific   saving is required, one should solve dense solve(prob,alg), use the   solution in the adjoint, and then sol(ts) interpolate.\n\nMathematical Definition\n\nAdjoint sensitivity analysis finds the gradient of a cost function G defined by the infinitesimal cost over the whole time period (t_0 T), given by the equation:\n\nG(up)=G(u(cdotp))=int_t_0^Tg(u(tp)pt)dt\n\nIt does so by solving the adjoint problem:\n\nfracdlambda^stardt=g_u(u(tp)p)-lambda^star(t)f_u(tu(tp)p)thinspacethinspacethinspacelambda^star(T)=0\n\nand obtaining the sensitivities through the integral:\n\nfracdGdp=int_t_0^Tlambda^star(t)f_p(t)+g_p(t)dt+lambda^star(t_0)u_p(t_0)\n\nAs defined, that cost function only has non-zero values over nontrivial intervals. However, often one may want to include in the cost function loss values at discrete points, for example, matching the data at time points t. In this case, terms of g can be represented by Dirac delta functions, which are then applied to the corresponding lambda^star and fracdGdp equations.\n\nFor more information, see Sensitivity Math Details.\n\nPositional Arguments\n\nsol: the solution from the forward pass of the ODE. Note that if not using a checkpointing sensitivity algorithm, then it's assumed that the (dense) interpolation of the forward solution is of sufficient accuracy for recreating the solution at any time point.\nalg: the algorithm (i.e., DiffEq solver) to use for the solution of the adjoint problem.\n\nKeyword Arguments\n\nt: the time points at which the discrete cost function is to be evaluated. This argument is only required if discrete cost functions are declared.\ng: the continuous instantaneous cost g(upt) at a given time point represented by a Julia function g(u,p,t). This argument is only required if there is a continuous instantaneous cost contribution.\ndgdu_discrete: the partial derivative g_u evaluated at the discrete (Dirac delta) times. If discrete cost values are given, then dgdu_discrete is required.\ndgdp_discrete: the partial derivative g_p evaluated at the discrete (Dirac delta) times. If discrete cost values are given, then dgdp_discrete is not required and is assumed to be zero.\ndgdu_continuous: the partial derivative g_u evaluated at times not corresponding to terms with an associated Dirac delta. If g is given, then this term is not required and will be approximated by numerical or (forward-mode) automatic differentiation (via the autodiff keyword argument in the sensealg) if this term is not given by the user.\ndgdp_continuous: the partial derivative g_p evaluated at times not corresponding to terms with an associated Dirac delta. If g is given, then this term is not required and will be approximated by numerical or (forward-mode) automatic differentiation (via the autojacvec keyword argument in the sensealg) if this term is not given by the user.\nabstol: the absolute tolerance of the adjoint solve. Defaults to 1e-3\nreltol: the relative tolerance of the adjoint solve. Defaults to 1e-3\ncheckpoints: the values to use for the checkpoints of the reverse solve, if the adjoint sensealg has checkpointing = true. Defaults to sol.t, i.e. the saved points in the sol.\ncorfunc_analytical: the function corresponding to the conversion from an Ito to a Stratanovich definition of an SDE, i.e.\n\nFor sensitivity analysis of an SDE in the Ito sense dX = a(Xt)dt + b(Xt)dW_t with conversion term - 12 b_X b, corfunc_analytical denotes b_X b. Only used if thesol.prob isa SDEProblem`. If not given, this is   computed using automatic differentiation. Note that this inside of the reverse solve SDE then implies automatic   differentiation of a function being automatic differentiated, and nested higher order automatic differentiation   has more restrictions on the function plus some performance disadvantages.\n\ncallback: callback functions to be used in the adjoint solve. Defaults to nothing.\nsensealg: the choice for what adjoint method to use for the reverse solve. Defaults to InterpolatingAdjoint(). See the sensitivity algorithms page for more details.\nkwargs: any extra keyword arguments passed to the adjoint solve.\n\nDetailed Description\n\nFor discrete adjoints where the cost functions only depend on parameters through the ODE solve itself (for example, parameter estimation with L2 loss), use:\n\ndu0,dp = adjoint_sensitivities(sol,alg;t=ts,dgdu_discrete=dg,\n                               sensealg=InterpolatingAdjoint(),\n                               checkpoints=sol.t,kwargs...)\n\nwhere alg is the ODE algorithm to solve the adjoint problem, dgdu_discrete is the jump function, sensealg is the sensitivity algorithm, and ts are the time points for data. dg is given by:\n\ndg(out,u,p,t,i)\n\nwhich is the in-place gradient of the cost functional g at time point ts[i] with u=u(t).\n\nFor continuous functionals, the form is:\n\ndu0,dp = adjoint_sensitivities(sol,alg;dgdu_continuous=dgdu,g=g,\n                               dgdp_continuous = dgdp,\n                               sensealg=InterpolatingAdjoint(),\n                               checkpoints=sol.t,kwargs...)\n\nfor the cost functional\n\ng(u,p,t)\n\nwith in-place gradient\n\ndgdu(out,u,p,t)\ndgdp(out,u,p,t)\n\nIf the gradient is omitted, i.e.\n\ndu0,dp = adjoint_sensitivities(sol,alg;g=g,kwargs...)\n\nthen we assume dgdp is zero and dgdu will be computed automatically using ForwardDiff or finite differencing, depending on the autodiff setting in the AbstractSensitivityAlgorithm. Note that the keyword arguments are passed to the internal ODE solver for solving the adjoint problem.\n\nnote: Note\nMixing discrete and continuous terms in the cost function is allowed\n\nExamples\n\nExample discrete adjoints on a cost function\n\nIn this example, we will show solving for the adjoint sensitivities of a discrete cost functional. First, let's solve the ODE and get a high quality continuous solution:\n\nfunction f(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + u[1]*u[2]\nend\n\np = [1.5,1.0,3.0]\nprob = ODEProblem(f,[1.0;1.0],(0.0,10.0),p)\nsol = solve(prob,Vern9(),abstol=1e-10,reltol=1e-10)\n\nNow let's calculate the sensitivity of the ell_2 error against 1 at evenly spaced points in time, that is:\n\nL(upt)=sum_i=1^nfracVert1-u(t_ip)Vert^22\n\nfor t_i = 05i. This is the assumption that the data is data[i]=1.0. For this function, notice we have that:\n\nbeginaligned\ndg_1=-1+u_1 \ndg_2=-1+u_2 \n quad vdots\nendaligned\n\nand thus:\n\ndg(out,u,p,t,i) = (out.=-1.0.+u)\n\nAlso, we can omit dgdp because the cost function doesn't dependent on p. If we had data, we'd just replace 1.0 with data[i]. To get the adjoint sensitivities, call:\n\nts = 0:0.5:10\nres = adjoint_sensitivities(sol,Vern9();t=ts,dg_discrete=dg,abstol=1e-14,\n                            reltol=1e-14)\n\nThis is super high accuracy. As always, there's a tradeoff between accuracy and computation time. We can check this almost exactly matches the autodifferentiation and numerical differentiation results:\n\nusing ForwardDiff,Calculus,Tracker\nfunction G(p)\n  tmp_prob = remake(prob,u0=convert.(eltype(p),prob.u0),p=p)\n  sol = solve(tmp_prob,Vern9(),abstol=1e-14,reltol=1e-14,saveat=ts,\n              sensealg=SensitivityADPassThrough())\n  A = convert(Array,sol)\n  sum(((1 .- A).^2)./2)\nend\nG([1.5,1.0,3.0])\nres2 = ForwardDiff.gradient(G,[1.5,1.0,3.0])\nres3 = Calculus.gradient(G,[1.5,1.0,3.0])\nres4 = Tracker.gradient(G,[1.5,1.0,3.0])\nres5 = ReverseDiff.gradient(G,[1.5,1.0,3.0])\n\nand see this gives the same values.\n\nExample controlling adjoint method choices and checkpointing\n\nIn the previous examples, all calculations were done using the interpolating method. This maximizes speed, but at a cost of requiring a dense sol. If it is not possible to hold a dense forward solution in memory, then one can use checkpointing. For example:\n\nts = [0.0,0.2,0.5,0.7]\nsol = solve(prob,Vern9(),saveat=ts)\n\nCreates a non-dense solution with checkpoints at [0.0,0.2,0.5,0.7]. Now we can do:\n\nres = adjoint_sensitivities(sol,Vern9();t=ts,dg_discrete=dg,\n                            sensealg=InterpolatingAdjoint(checkpointing=true))\n\nWhen grabbing a Jacobian value during the backwards solution, it will no longer interpolate to get the value. Instead, it will start a forward solution at the nearest checkpoint to build local interpolants in a way that conserves memory. By default, the checkpoints are at sol.t, but we can override this:\n\nres = adjoint_sensitivities(sol,Vern9();t=ts,dg_discrte=dg,\n                            sensealg=InterpolatingAdjoint(checkpointing=true),\n                            checkpoints = [0.0,0.5])\n\nExample continuous adjoints on an energy functional\n\nIn this case, we'd like to calculate the adjoint sensitivity of the scalar energy functional:\n\nG(up)=int_0^Tfracsum_i=1^nu_i^2(t)2dt\n\nwhich is:\n\ng(u,p,t) = (sum(u).^2) ./ 2\n\nNotice that the gradient of this function with respect to the state u is:\n\nfunction dg(out,u,p,t)\n  out[1]= u[1] + u[2]\n  out[2]= u[1] + u[2]\nend\n\nTo get the adjoint sensitivities, we call:\n\nres = adjoint_sensitivities(sol,Vern9();dg_continuous=dg,g=g,abstol=1e-8,\n                                 reltol=1e-8,iabstol=1e-8,ireltol=1e-8)\n\nNotice that we can check this against autodifferentiation and numerical differentiation as follows:\n\nusing QuadGK\nfunction G(p)\n  tmp_prob = remake(prob,p=p)\n  sol = solve(tmp_prob,Vern9(),abstol=1e-14,reltol=1e-14)\n  res,err = quadgk((t)-> (sum(sol(t)).^2)./2,0.0,10.0,atol=1e-14,rtol=1e-10)\n  res\nend\nres2 = ForwardDiff.gradient(G,[1.5,1.0,3.0])\nres3 = Calculus.gradient(G,[1.5,1.0,3.0])\n\n\n\n","category":"function"},{"location":"manual/direct_adjoint_sensitivities/#Second-Order-Adjoint-Sensitivities","page":"Direct Adjoint Sensitivities of Differential Equations","title":"Second Order Adjoint Sensitivities","text":"","category":"section"},{"location":"manual/direct_adjoint_sensitivities/","page":"Direct Adjoint Sensitivities of Differential Equations","title":"Direct Adjoint Sensitivities of Differential Equations","text":"second_order_sensitivities\nsecond_order_sensitivity_product","category":"page"},{"location":"manual/direct_adjoint_sensitivities/#SciMLSensitivity.second_order_sensitivities","page":"Direct Adjoint Sensitivities of Differential Equations","title":"SciMLSensitivity.second_order_sensitivities","text":"H = secondordersensitivities(loss,prob,alg,args...;                                sensealg=ForwardDiffOverAdjoint(InterpolatingAdjoint(autojacvec=ReverseDiffVJP())),                                kwargs...)\n\nSecond order sensitivity analysis is used for the fast calculation of Hessian matrices.\n\nwarning: Warning\nAdjoint sensitivity analysis functionality requires being able to solve   a differential equation defined by the parameter struct p. Even though   DifferentialEquations.jl can support any parameter struct type, usage   with adjoint sensitivity analysis requires that p could be a valid   type for being the initial condition u0 of an array. This means that   many simple types, such as Tuples and NamedTuples, will work as   parameters in normal contexts but will fail during adjoint differentiation.   To work around this issue for complicated cases like nested structs, look   into defining p using AbstractArray libraries such as RecursiveArrayTools.jl   or ComponentArrays.jl so that p is an AbstractArray with a concrete element type.\n\nExample second order sensitivity analysis calculation\n\nusing SciMLSensitivity, OrdinaryDiffEq, ForwardDiff\nusing Test\n\nfunction lotka!(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + p[4]*u[1]*u[2]\nend\n\np = [1.5,1.0,3.0,1.0]; u0 = [1.0;1.0]\nprob = ODEProblem(lotka!,u0,(0.0,10.0),p)\nloss(sol) = sum(sol)\nv = ones(4)\n\nH  = second_order_sensitivities(loss,prob,Vern9(),saveat=0.1,abstol=1e-12,reltol=1e-12)\n\nArguments\n\nThe arguments for this function match adjoint_sensitivities. The only notable difference is sensealg which requires a second order sensitivity algorithm, of which currently the only choice is ForwardDiffOverAdjoint which uses forward-over-reverse to mix a forward-mode sensitivity analysis with an adjoint sensitivity analysis for a faster computation than either double forward or double reverse. ForwardDiffOverAdjoint's positional argument just accepts a first order sensitivity algorithm.\n\n\n\n","category":"function"},{"location":"manual/direct_adjoint_sensitivities/#SciMLSensitivity.second_order_sensitivity_product","page":"Direct Adjoint Sensitivities of Differential Equations","title":"SciMLSensitivity.second_order_sensitivity_product","text":"Hv = secondordersensitivity_product(loss,v,prob,alg,args...;                                sensealg=ForwardDiffOverAdjoint(InterpolatingAdjoint(autojacvec=ReverseDiffVJP())),                                kwargs...)\n\nSecond order sensitivity analysis product is used for the fast calculation of Hessian-vector products Hv without requiring the construction of the Hessian matrix.\n\nwarning: Warning\nAdjoint sensitivity analysis functionality requires being able to solve   a differential equation defined by the parameter struct p. Even though   DifferentialEquations.jl can support any parameter struct type, usage   with adjoint sensitivity analysis requires that p could be a valid   type for being the initial condition u0 of an array. This means that   many simple types, such as Tuples and NamedTuples, will work as   parameters in normal contexts but will fail during adjoint differentiation.   To work around this issue for complicated cases like nested structs, look   into defining p using AbstractArray libraries such as RecursiveArrayTools.jl   or ComponentArrays.jl so that p is an AbstractArray with a concrete element type.\n\nExample second order sensitivity analysis calculation\n\nusing SciMLSensitivity, OrdinaryDiffEq, ForwardDiff\nusing Test\n\nfunction lotka!(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + p[4]*u[1]*u[2]\nend\n\np = [1.5,1.0,3.0,1.0]; u0 = [1.0;1.0]\nprob = ODEProblem(lotka!,u0,(0.0,10.0),p)\nloss(sol) = sum(sol)\nv = ones(4)\n\nHv = second_order_sensitivity_product(loss,v,prob,Vern9(),saveat=0.1,abstol=1e-12,reltol=1e-12)\n\nArguments\n\nThe arguments for this function match adjoint_sensitivities. The only notable difference is sensealg which requires a second order sensitivity algorithm, of which currently the only choice is ForwardDiffOverAdjoint which uses forward-over-reverse to mix a forward-mode sensitivity analysis with an adjoint sensitivity analysis for a faster computation than either double forward or double reverse. ForwardDiffOverAdjoint's positional argument just accepts a first order sensitivity algorithm.\n\n\n\n","category":"function"},{"location":"examples/neural_ode/neural_gde/#Neural-Graph-Differential-Equations","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"This tutorial has been adapted from here.","category":"page"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"In this tutorial, we will use Graph Differential Equations (GDEs) to perform classification on the CORA Dataset. We shall be using the Graph Neural Networks primitives from the package GraphNeuralNetworks.","category":"page"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"# Load the packages\nusing GraphNeuralNetworks, DifferentialEquations\nusing DiffEqFlux: NeuralODE\nusing GraphNeuralNetworks.GNNGraphs: normalized_adjacency\nusing Lux, NNlib, Optimisers, Zygote, Random, ComponentArrays\nusing Lux: AbstractExplicitLayer, glorot_normal, zeros32\nimport Lux: initialparameters, initialstates\nusing SciMLSensitivity\nusing Statistics: mean\nusing MLDatasets: Cora\nusing CUDA\nCUDA.allowscalar(false)\ndevice = CUDA.functional() ? gpu : cpu\n\n# Download the dataset\ndataset = Cora();\n\n# Preprocess the data and compute adjacency matrix\nclasses = dataset.metadata[\"classes\"]\ng = mldataset2gnngraph(dataset) |> device\nonehotbatch(data, labels) = device(labels) .== reshape(data, 1, size(data)...)\nonecold(y) = map(argmax, eachcol(y))\nX = g.ndata.features\ny = onehotbatch(g.ndata.targets, classes) # a dense matrix is not the optimal, but we don't want to use Flux here\n\nÃ = normalized_adjacency(g, add_self_loops = true) |> device\n\n(; train_mask, val_mask, test_mask) = g.ndata\nytrain = y[:, train_mask]\n\n# Model and Data Configuration\nnin = size(X, 1)\nnhidden = 16\nnout = length(classes)\nepochs = 20\n\n# Define the graph neural network\nstruct ExplicitGCNConv{F1, F2, F3, F4} <: AbstractExplicitLayer\n    in_chs::Int\n    out_chs::Int\n    activation::F1\n    init_Ã::F2  # nomalized_adjacency matrix\n    init_weight::F3\n    init_bias::F4\nend\n\nfunction Base.show(io::IO, l::ExplicitGCNConv)\n    print(io, \"ExplicitGCNConv($(l.in_chs) => $(l.out_chs)\")\n    (l.activation == identity) || print(io, \", \", l.activation)\n    print(io, \")\")\nend\n\nfunction initialparameters(rng::AbstractRNG, d::ExplicitGCNConv)\n    return (weight = d.init_weight(rng, d.out_chs, d.in_chs),\n        bias = d.init_bias(rng, d.out_chs, 1))\nend\n\ninitialstates(rng::AbstractRNG, d::ExplicitGCNConv) = (Ã = d.init_Ã(),)\n\nfunction ExplicitGCNConv(Ã, ch::Pair{Int, Int}, activation = identity;\n    init_weight = glorot_normal, init_bias = zeros32)\n    init_Ã = () -> copy(Ã)\n    return ExplicitGCNConv{typeof(activation), typeof(init_Ã), typeof(init_weight),\n        typeof(init_bias)}(first(ch), last(ch), activation,\n        init_Ã, init_weight, init_bias)\nend\n\nfunction (l::ExplicitGCNConv)(x::AbstractMatrix, ps, st::NamedTuple)\n    z = ps.weight * x * st.Ã\n    return l.activation.(z .+ ps.bias), st\nend\n\n# Define the Neural GDE\nfunction diffeqsol_to_array(x::ODESolution{T, N, <:AbstractVector{<:CuArray}}) where {T, N}\n    return dropdims(gpu(x); dims = 3)\nend\ndiffeqsol_to_array(x::ODESolution) = dropdims(Array(x); dims = 3)\n\n# make NeuralODE work with Lux.Chain\n# remove this once https://github.com/SciML/DiffEqFlux.jl/issues/727 is fixed\ninitialparameters(rng::AbstractRNG, node::NeuralODE) = initialparameters(rng, node.model)\ninitialstates(rng::AbstractRNG, node::NeuralODE) = initialstates(rng, node.model)\n\ngnn = Chain(ExplicitGCNConv(Ã, nhidden => nhidden, relu),\n    ExplicitGCNConv(Ã, nhidden => nhidden, relu))\n\nnode = NeuralODE(gnn, (0.0f0, 1.0f0), Tsit5(), save_everystep = false,\n    reltol = 1e-3, abstol = 1e-3, save_start = false)\n\nmodel = Chain(ExplicitGCNConv(Ã, nin => nhidden, relu),\n    node,\n    diffeqsol_to_array,\n    Dense(nhidden, nout))\n\n# Loss\nlogitcrossentropy(ŷ, y) = mean(-sum(y .* logsoftmax(ŷ); dims = 1))\n\nfunction loss(x, y, mask, model, ps, st)\n    ŷ, st = model(x, ps, st)\n    return logitcrossentropy(ŷ[:, mask], y), st\nend\n\nfunction eval_loss_accuracy(X, y, mask, model, ps, st)\n    ŷ, _ = model(X, ps, st)\n    l = logitcrossentropy(ŷ[:, mask], y[:, mask])\n    acc = mean(onecold(ŷ[:, mask]) .== onecold(y[:, mask]))\n    return (loss = round(l, digits = 4), acc = round(acc * 100, digits = 2))\nend\n\n# Training\nfunction train()\n    ## Setup model\n    rng = Random.default_rng()\n    Random.seed!(rng, 0)\n\n    ps, st = Lux.setup(rng, model)\n    ps = ComponentArray(ps) |> device\n    st = st |> device\n\n    ## Optimizer\n    opt = Optimisers.ADAM(0.01f0)\n    st_opt = Optimisers.setup(opt, ps)\n\n    ## Training Loop\n    for _ in 1:epochs\n        (l, st), back = pullback(p -> loss(X, ytrain, train_mask, model, p, st), ps)\n        gs = back((one(l), nothing))[1]\n        st_opt, ps = Optimisers.update(st_opt, ps, gs)\n        @show eval_loss_accuracy(X, y, val_mask, model, ps, st)\n    end\nend\n\ntrain()","category":"page"},{"location":"examples/neural_ode/neural_gde/#Step-by-Step-Explanation","page":"Neural Graph Differential Equations","title":"Step by Step Explanation","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/#Load-the-Required-Packages","page":"Neural Graph Differential Equations","title":"Load the Required Packages","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"# Load the packages\nusing GraphNeuralNetworks, DifferentialEquations\nusing DiffEqFlux: NeuralODE\nusing GraphNeuralNetworks.GNNGraphs: normalized_adjacency\nusing Lux, NNlib, Optimisers, Zygote, Random, ComponentArrays\nusing Lux: AbstractExplicitLayer, glorot_normal, zeros32\nimport Lux: initialparameters, initialstates\nusing SciMLSensitivity\nusing Statistics: mean\nusing MLDatasets: Cora\nusing CUDA\nCUDA.allowscalar(false)\ndevice = CUDA.functional() ? gpu : cpu","category":"page"},{"location":"examples/neural_ode/neural_gde/#Load-the-Dataset","page":"Neural Graph Differential Equations","title":"Load the Dataset","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"The dataset is available in the desired format in the MLDatasets repository. We shall download the dataset from there.","category":"page"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"dataset = Cora();","category":"page"},{"location":"examples/neural_ode/neural_gde/#Preprocessing-the-Data","page":"Neural Graph Differential Equations","title":"Preprocessing the Data","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"Convert the data to GNNGraph and get the adjacency matrix from the graph g.","category":"page"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"classes = dataset.metadata[\"classes\"]\ng = mldataset2gnngraph(dataset) |> device\nonehotbatch(data, labels) = device(labels) .== reshape(data, 1, size(data)...)\nonecold(y) = map(argmax, eachcol(y))\nX = g.ndata.features\ny = onehotbatch(g.ndata.targets, classes) # a dense matrix is not the optimal, but we don't want to use Flux here\n\nÃ = normalized_adjacency(g, add_self_loops = true) |> device","category":"page"},{"location":"examples/neural_ode/neural_gde/#Training-Data","page":"Neural Graph Differential Equations","title":"Training Data","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"GNNs operate on an entire graph, so we can't do any sort of minibatching here. We predict the entire dataset, but train the model in a semi-supervised learning fashion.","category":"page"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"(; train_mask, val_mask, test_mask) = g.ndata\nytrain = y[:, train_mask]","category":"page"},{"location":"examples/neural_ode/neural_gde/#Model-and-Data-Configuration","page":"Neural Graph Differential Equations","title":"Model and Data Configuration","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"We shall use only 16 hidden state dimensions.","category":"page"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"nin = size(X, 1)\nnhidden = 16\nnout = length(classes)\nepochs = 20","category":"page"},{"location":"examples/neural_ode/neural_gde/#Define-the-Graph-Neural-Network","page":"Neural Graph Differential Equations","title":"Define the Graph Neural Network","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"Here, we define a type of graph neural networks called GCNConv. We use the name ExplicitGCNConv to avoid naming conflicts with GraphNeuralNetworks. For more information on defining a layer with Lux, please consult to the doc.","category":"page"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"struct ExplicitGCNConv{F1, F2, F3} <: AbstractExplicitLayer\n    Ã::AbstractMatrix  # nomalized_adjacency matrix\n    in_chs::Int\n    out_chs::Int\n    activation::F1\n    init_weight::F2\n    init_bias::F3\nend\n\nfunction Base.show(io::IO, l::ExplicitGCNConv)\n    print(io, \"ExplicitGCNConv($(l.in_chs) => $(l.out_chs)\")\n    (l.activation == identity) || print(io, \", \", l.activation)\n    print(io, \")\")\nend\n\nfunction initialparameters(rng::AbstractRNG, d::ExplicitGCNConv)\n    return (weight = d.init_weight(rng, d.out_chs, d.in_chs),\n        bias = d.init_bias(rng, d.out_chs, 1))\nend\n\nfunction ExplicitGCNConv(Ã, ch::Pair{Int, Int}, activation = identity;\n    init_weight = glorot_normal, init_bias = zeros32)\n    return ExplicitGCNConv{typeof(activation), typeof(init_weight), typeof(init_bias)}(Ã,\n        first(ch),\n        last(ch),\n        activation,\n        init_weight,\n        init_bias)\nend\n\nfunction (l::ExplicitGCNConv)(x::AbstractMatrix, ps, st::NamedTuple)\n    z = ps.weight * x * l.Ã\n    return l.activation.(z .+ ps.bias), st\nend","category":"page"},{"location":"examples/neural_ode/neural_gde/#Neural-Graph-Ordinary-Differential-Equations","page":"Neural Graph Differential Equations","title":"Neural Graph Ordinary Differential Equations","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"Let us now define the final model. We will use two GNN layers for approximating the gradients for the neural ODE. We use one additional GCNConv layer to project the data to a latent space and a Dense layer to project it from the latent space to the predictions. Finally, a softmax layer gives us the probability of the input belonging to each target category.","category":"page"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"function diffeqsol_to_array(x::ODESolution{T, N, <:AbstractVector{<:CuArray}}) where {T, N}\n    return dropdims(gpu(x); dims = 3)\nend\ndiffeqsol_to_array(x::ODESolution) = dropdims(Array(x); dims = 3)\n\ngnn = Chain(ExplicitGCNConv(Ã, nhidden => nhidden, relu),\n    ExplicitGCNConv(Ã, nhidden => nhidden, relu))\n\nnode = NeuralODE(gnn, (0.0f0, 1.0f0), Tsit5(), save_everystep = false,\n    reltol = 1e-3, abstol = 1e-3, save_start = false)\n\nmodel = Chain(ExplicitGCNConv(Ã, nin => nhidden, relu),\n    node,\n    diffeqsol_to_array,\n    Dense(nhidden, nout))","category":"page"},{"location":"examples/neural_ode/neural_gde/#Training-Configuration","page":"Neural Graph Differential Equations","title":"Training Configuration","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/#Loss-Function-and-Accuracy","page":"Neural Graph Differential Equations","title":"Loss Function and Accuracy","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"We shall be using the standard categorical crossentropy loss function, which is used for multiclass classification tasks.","category":"page"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"logitcrossentropy(ŷ, y) = mean(-sum(y .* logsoftmax(ŷ); dims = 1))\n\nfunction loss(x, y, mask, model, ps, st)\n    ŷ, st = model(x, ps, st)\n    return logitcrossentropy(ŷ[:, mask], y), st\nend\n\nfunction eval_loss_accuracy(X, y, mask, model, ps, st)\n    ŷ, _ = model(X, ps, st)\n    l = logitcrossentropy(ŷ[:, mask], y[:, mask])\n    acc = mean(onecold(ŷ[:, mask]) .== onecold(y[:, mask]))\n    return (loss = round(l, digits = 4), acc = round(acc * 100, digits = 2))\nend","category":"page"},{"location":"examples/neural_ode/neural_gde/#Setup-Model","page":"Neural Graph Differential Equations","title":"Setup Model","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"We need to manually set up our mode with Lux, and convert the parameters to ComponentArray so that they can work well with sensitivity algorithms.","category":"page"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"rng = Random.default_rng()\nRandom.seed!(rng, 0)\n\nps, st = Lux.setup(rng, model)\nps = ComponentArray(ps) |> device\nst = st |> device","category":"page"},{"location":"examples/neural_ode/neural_gde/#Optimizer","page":"Neural Graph Differential Equations","title":"Optimizer","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"For this task, we will be using the ADAM optimizer with a learning rate of 0.01.","category":"page"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"opt = Optimisers.Adam(0.01f0)\nst_opt = Optimisers.setup(opt, ps)","category":"page"},{"location":"examples/neural_ode/neural_gde/#Training-Loop","page":"Neural Graph Differential Equations","title":"Training Loop","text":"","category":"section"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"Finally, we use the package Optimisers to learn the parameters ps. We run the training loop for epochs number of iterations.","category":"page"},{"location":"examples/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"for _ in 1:epochs\n    (l, st), back = pullback(p -> loss(X, ytrain, train_mask, model, p, st), ps)\n    gs = back((one(l), nothing))[1]\n    st_opt, ps = Optimisers.update(st_opt, ps, gs)\n    @show eval_loss_accuracy(X, y, val_mask, model, ps, st)\nend","category":"page"},{"location":"manual/nonlinear_solve_sensitivities/#sensitivity_nonlinear","page":"Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)","text":"","category":"section"},{"location":"manual/nonlinear_solve_sensitivities/","page":"Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)","text":"SteadyStateAdjoint","category":"page"},{"location":"manual/nonlinear_solve_sensitivities/#SciMLSensitivity.SteadyStateAdjoint","page":"Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)","title":"SciMLSensitivity.SteadyStateAdjoint","text":"SteadyStateAdjoint{CS, AD, FDT, VJP, LS} <: AbstractAdjointSensitivityAlgorithm{CS, AD, FDT}\n\nAn implementation of the adjoint differentiation of a nonlinear solve. Uses the implicit function theorem to directly compute the derivative of the solution to f(up) = 0 with respect to p.\n\nConstructor\n\nSteadyStateAdjoint(; chunk_size = 0, autodiff = true,\n                   diff_type = Val{:central},\n                   autojacvec = autodiff, linsolve = nothing)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nautojacvec: Calculate the vector-Jacobian product (J'*v) via automatic differentiation with special seeding. The total set of choices are:\nnothing: uses an automatic algorithm to automatically choose the vjp. This is the default and recommended for most users.\nfalse: the Jacobian is constructed via FiniteDiff.jl\ntrue: the Jacobian is constructed via ForwardDiff.jl\nTrackerVJP: Uses Tracker.jl for the vjp.\nZygoteVJP: Uses Zygote.jl for the vjp.\nEnzymeVJP: Uses Enzyme.jl for the vjp.\nReverseDiffVJP(compile=false): Uses ReverseDiff.jl for the vjp. compile is a boolean for whether to precompile the tape, which should only be done if there are no branches (if or while statements) in the f function.\nlinsolve: the linear solver used in the adjoint solve. Defaults to nothing, which uses a polyalgorithm to choose an efficient algorithm automatically.\n\nFor more details on the vjp choices, please consult the sensitivity algorithms documentation page or the docstrings of the vjp types.\n\nReferences\n\nJohnson, S. G., Notes on Adjoint Methods for 18.336, Online at http://math.mit.edu/stevenj/18.336/adjoint.pdf (2007)\n\n\n\n\n\n","category":"type"},{"location":"examples/ode/prediction_error_method/#pemethod","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"","category":"section"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"When identifying linear systems from noisy data, the prediction-error method [Ljung] is close to a gold standard when it comes to the quality of the models it produces, but is also one of the computationally more expensive methods due to its reliance on iterative, gradient-based estimation. When we are identifying nonlinear models, we typically do not have the luxury of closed-form, non-iterative solutions, while PEM is easier to adapt to the nonlinear setting.[Larsson]","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"Fundamentally, PEM changes the problem from minimizing a loss based on the simulation performance, to minimizing a loss based on shorter-term predictions. There are several benefits of doing so, and this example will highlight two:","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"The loss is often easier to optimize.\nIn addition to an accurate simulator, you also obtain a prediction for the system.\nWith PEM, it's possible to estimate disturbance models.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"The last point will not be illustrated in this tutorial, but we will briefly expand upon it here. Gaussian, zero-mean measurement noise is usually not very hard to handle. Disturbances that affect the state of the system may, however, cause all sorts of havoc on the estimate. Consider wind affecting an aircraft, deriving a statistical and dynamical model of the wind may be doable, but unless you measure the exact wind affecting the aircraft, making use of the model during parameter estimation is impossible. The wind is an unmeasured load disturbance that affects the state of the system through its own dynamics model. Using the techniques illustrated in this tutorial, it's possible to estimate the influence of the wind during the experiment that generated the data and reduce or eliminate the bias it otherwise causes in the parameter estimates.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We will start by illustrating a common problem with simulation-error minimization. Imagine a pendulum with unknown length that is to be estimated. A small error in the pendulum length causes the frequency of oscillation to change. Over sufficiently large horizon, two sinusoidal signals with different frequencies become close to orthogonal to each other. If some form of squared-error loss is used, the loss landscape will be horribly non-convex in this case, indeed, we will illustrate exactly this below.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"Another case that poses a problem for simulation-error estimation is when the system is unstable or chaotic. A small error in either the initial condition or the parameters may cause the simulation error to diverge and its gradient to become meaningless.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"In both of these examples, we may make use of measurements we have of the evolution of the system to prevent the simulation error from diverging. For instance, if we have measured the angle of the pendulum, we can make use of this measurement to adjust the angle during the simulation to make sure it stays close to the measured angle. Instead of performing a pure simulation, we instead say that we predict the state a while forward in time, given all the measurements until the current time point. By minimizing this prediction rather than the pure simulation, we can often prevent the model error from diverging even though we have a poor initial guess.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We start by defining a model of the pendulum. The model takes a parameter L corresponding to the length of the pendulum.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"using DifferentialEquations, Optimization, OptimizationPolyalgorithms, Plots, Statistics,\n    DataInterpolations, ForwardDiff\n\ntspan = (0.1, 20.0)\ntsteps = range(tspan[1], tspan[2], length = 1000)\n\nu0 = [0.0, 3.0] # Initial angle and angular velocity\n\nfunction simulator(du, u, p, t) # Pendulum dynamics\n    g = 9.82 # Gravitational constant\n    L = p isa Number ? p : p[1] # Length of the pendulum\n    gL = g / L\n    θ = u[1]\n    dθ = u[2]\n    du[1] = dθ\n    du[2] = -gL * sin(θ)\nend","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We assume that the true length of the pendulum is L = 1, and generate some data from this system.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"prob = ODEProblem(simulator, u0, tspan, 1.0) # Simulate with L = 1\nsol = solve(prob, Tsit5(), saveat = tsteps, abstol = 1e-8, reltol = 1e-8)\ny = sol[1, :] # This is the data we have available for parameter estimation\nplot(y, title = \"Pendulum simulation\", label = \"angle\")","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We also define functions that simulate the system and calculate the loss, given a parameter p corresponding to the length.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"function simulate(p)\n    _prob = remake(prob, p = p)\n    solve(_prob, Tsit5(), saveat = tsteps, abstol = 1e-8, reltol = 1e-8)\nend\n\nfunction simloss(p)\n    yh = simulate(p)\n    if !SciMLBase.successful_retcode(yh.retcode)\n        return Inf\n    end\n    e2 = yh[1, :]\n    e2 .= abs2.(y .- e2)\n    return mean(e2)\nend","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We now look at the loss landscape as a function of the pendulum length:","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"Ls = 0.01:0.01:2\nsimlosses = simloss.(Ls)\nfig_loss = plot(Ls, simlosses, title = \"Loss landscape\", xlabel = \"Pendulum length\",\n    ylabel = \"MSE loss\", lab = \"Simulation loss\")","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"This figure is interesting, the loss is of course 0 for the true value L=1, but for values L  1, the overall slope actually points in the wrong direction! Moreover, the loss is oscillatory, indicating that this is a terrible function to optimize, and that we would need a very good initial guess for a local search to converge to the true value. Note, this example is chosen to be one-dimensional in order to allow these kinds of visualizations, and one-dimensional problems are typically not hard to solve, but the reasoning extends to higher-dimensional and harder problems.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We will now move on to defining a predictor model. Our predictor will be very simple, each time step, we will calculate the error e between the simulated angle theta and the measured angle y. A part of this error will be used to correct the state of the pendulum. The correction we use is linear and looks like Ke = K(y - theta). We have formed what is commonly referred to as a (linear) observer. The Kalman filter is a particular kind of linear observer, where K is calculated based on a statistical model of the disturbances that act on the system. We will stay with a simple, fixed-gain observer here for simplicity.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"To feed the sampled data into the continuous-time simulation, we make use of an interpolator. We also define new functions, predictor that contains the pendulum dynamics with the observer correction, a prediction function that performs the rollout (we're not using the word simulation to not confuse with the setting above) and a loss function.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"y_int = LinearInterpolation(y, tsteps)\n\nfunction predictor(du, u, p, t)\n    g = 9.82\n    L, K, y = p # pendulum length, observer gain and measurements\n    gL = g / L\n    θ = u[1]\n    dθ = u[2]\n    yt = y(t)\n    e = yt - θ\n    du[1] = dθ + K * e\n    du[2] = -gL * sin(θ)\nend\n\npredprob = ODEProblem(predictor, u0, tspan, nothing)\n\nfunction prediction(p)\n    p_full = (p..., y_int)\n    _prob = remake(predprob, u0 = eltype(p).(u0), p = p_full)\n    solve(_prob, Tsit5(), saveat = tsteps, abstol = 1e-8, reltol = 1e-8)\nend\n\nfunction predloss(p)\n    yh = prediction(p)\n    if !SciMLBase.successful_retcode(yh.retcode)\n        return Inf\n    end\n    e2 = yh[1, :]\n    e2 .= abs2.(y .- e2)\n    return mean(e2)\nend\n\npredlosses = map(Ls) do L\n    p = (L, 1) # use K = 1\n    predloss(p)\nend\n\nplot!(Ls, predlosses, lab = \"Prediction loss\")","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"Once gain, we look at the loss as a function of the parameter, and this time it looks a lot better. The loss is not convex, but the gradient points in the right direction over a much larger interval. Here, we arbitrarily set the observer gain to K=1, we will later let the optimizer learn this parameter.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"For completeness, we also perform estimation using both losses. We choose an initial guess we know will be hard for the simulation-error minimization just to drive home the point:","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"L0 = [0.7] # Initial guess of pendulum length\nadtype = Optimization.AutoForwardDiff()\noptf = Optimization.OptimizationFunction((x, p) -> simloss(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, L0)\n\nressim = Optimization.solve(optprob, PolyOpt(),\n    maxiters = 5000)\nysim = simulate(ressim.u)[1, :]\n\nplot(tsteps, [y ysim], label = [\"Data\" \"Simulation model\"])\n\np0 = [0.7, 1.0] # Initial guess of length and observer gain K\noptf2 = Optimization.OptimizationFunction((p, _) -> predloss(p), adtype)\noptprob2 = Optimization.OptimizationProblem(optf2, p0)\n\nrespred = Optimization.solve(optprob2, PolyOpt(),\n    maxiters = 5000)\nypred = simulate(respred.u)[1, :]\n\nplot!(tsteps, ypred, label = \"Prediction model\")","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"The estimated parameters (L K) are","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"respred.u","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"Now, we might ask ourselves why we used a correct on the form Ke and didn't instead set the angle in the simulation equal to the measurement. The reason is twofold","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"If our prediction of the angle is 100% based on the measurements, the model parameters do not matter for the prediction, and we thus cannot hope to learn their values.\nThe measurement is usually noisy, and we thus want to fuse the predictive power of the model with the information of the measurements. The Kalman filter is an optimal approach to this information fusion under special circumstances (linear model, Gaussian noise).","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We thus let the optimization learn the best value of the observer gain in order to make the best predictions.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"As a last step, we perform the estimation also with some measurement noise to verify that it does something reasonable:","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"yn = y .+ 0.1f0 .* randn.(Float32)\ny_int = LinearInterpolation(yn, tsteps) # redefine the interpolator to contain noisy measurements\n\noptf = Optimization.OptimizationFunction((x, p) -> predloss(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, p0)\n\nresprednoise = Optimization.solve(optprob, PolyOpt(),\n    maxiters = 5000)\n\nyprednoise = prediction(resprednoise.u)[1, :]\nplot!(tsteps, yprednoise, label = \"Prediction model with noisy measurements\")","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"resprednoise.u","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"This example has illustrated basic use of the prediction-error method for parameter estimation. In our example, the measurement we had corresponded directly to one of the states, and coming up with an observer/predictor that worked was not too hard. For more difficult cases, we may opt to use a nonlinear observer, such as an extended Kalman filter (EKF) or design a Kalman filter based on a linearization of the system around some operating point.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"As a last note, there are several other methods available to improve the loss landscape and avoid local minima, such as multiple-shooting. The prediction-error method can easily be combined with most of those methods.","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"References:","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"[Ljung]: Ljung, Lennart. \"System identification–-Theory for the user\".","category":"page"},{"location":"examples/ode/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"[Larsson]: Larsson, Roger, et al. \"Direct prediction-error identification of unstable nonlinear systems applied to flight test data.\"","category":"page"},{"location":"tutorials/direct_sensitivity/#direct_sensitivity","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"","category":"section"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"While sensitivity analysis tooling can be used implicitly via integration with automatic differentiation libraries, one can often times obtain more speed and flexibility with the direct sensitivity analysis interfaces. This tutorial demonstrates some of those functions.","category":"page"},{"location":"tutorials/direct_sensitivity/#Example-using-an-ODEForwardSensitivityProblem","page":"Direct Sensitivity Analysis Functionality","title":"Example using an ODEForwardSensitivityProblem","text":"","category":"section"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"Forward sensitivity analysis is performed by defining and solving an augmented ODE. To define this augmented ODE, use the ODEForwardSensitivityProblem type instead of an ODE type. For example, we generate an ODE with the sensitivity equations attached to the Lotka-Volterra equations by:","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"using OrdinaryDiffEq, SciMLSensitivity\n\nfunction f(du, u, p, t)\n    du[1] = dx = p[1] * u[1] - p[2] * u[1] * u[2]\n    du[2] = dy = -p[3] * u[2] + u[1] * u[2]\nend\n\np = [1.5, 1.0, 3.0]\nprob = ODEForwardSensitivityProblem(f, [1.0; 1.0], (0.0, 10.0), p)","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"This generates a problem which the ODE solvers can solve:","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"sol = solve(prob, DP8())","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"Note that the solution is the standard ODE system and the sensitivity system combined. We can use the following helper functions to extract the sensitivity information:","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"x, dp = extract_local_sensitivities(sol)\nx, dp = extract_local_sensitivities(sol, i)\nx, dp = extract_local_sensitivities(sol, t)","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"In each case, x is the ODE values and dp is the matrix of sensitivities The first gives the full timeseries of values and dp[i] contains the time series of the sensitivities of all components of the ODE with respect to ith parameter. The second returns the ith time step, while the third interpolates to calculate the sensitivities at time t. For example, if we do:","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"x, dp = extract_local_sensitivities(sol)\nda = dp[1]","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"then da is the timeseries for fracpartial u(t)partial p. We can plot this","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"using Plots\nplot(sol.t, da', lw = 3)","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"transposing so that the rows (the timeseries) is plotted.","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"(Image: Local Sensitivity Solution)","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"For more information on the internal representation of the ODEForwardSensitivityProblem solution, see the direct forward sensitivity analysis manual page.","category":"page"},{"location":"tutorials/direct_sensitivity/#Example-using-adjoint_sensitivities-for-discrete-adjoints","page":"Direct Sensitivity Analysis Functionality","title":"Example using adjoint_sensitivities for discrete adjoints","text":"","category":"section"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"In this example, we will show solving for the adjoint sensitivities of a discrete cost functional. First, let's solve the ODE and get a high quality continuous solution:","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"function f(du, u, p, t)\n    du[1] = dx = p[1] * u[1] - p[2] * u[1] * u[2]\n    du[2] = dy = -p[3] * u[2] + u[1] * u[2]\nend\n\np = [1.5, 1.0, 3.0]\nprob = ODEProblem(f, [1.0; 1.0], (0.0, 10.0), p)\nsol = solve(prob, Vern9(), abstol = 1e-10, reltol = 1e-10)","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"Now let's calculate the sensitivity of the ell_2 error against 1 at evenly spaced points in time, that is:","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"L(upt)=sum_i=1^nfracVert1-u(t_ip)Vert^22","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"for t_i = 05i. This is the assumption that the data is data[i]=1.0. For this function, notice we have that:","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"beginaligned\ndg_1=1-u_1 \ndg_2=1-u_2 \n quad vdots\nendaligned","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"and thus:","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"dg(out, u, p, t, i) = (out .= 1.0 .- u)","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"Also, we can omit dgdp, because the cost function doesn't dependent on p. If we had data, we'd just replace 1.0 with data[i]. To get the adjoint sensitivities, call:","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"ts = 0:0.5:10\nres = adjoint_sensitivities(sol, Vern9(), t = ts, dgdu_discrete = dg, abstol = 1e-14,\n    reltol = 1e-14)","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"This is super high accuracy. As always, there's a tradeoff between accuracy and computation time. We can check this almost exactly matches the autodifferentiation and numerical differentiation results:","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"using ForwardDiff, Calculus, ReverseDiff, Tracker\nfunction G(p)\n    tmp_prob = remake(prob, u0 = convert.(eltype(p), prob.u0), p = p)\n    sol = solve(tmp_prob, Vern9(), abstol = 1e-14, reltol = 1e-14, saveat = ts,\n        sensealg = SensitivityADPassThrough())\n    A = convert(Array, sol)\n    sum(((1 .- A) .^ 2) ./ 2)\nend\nres2 = ForwardDiff.gradient(G, [1.5, 1.0, 3.0])","category":"page"},{"location":"tutorials/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"and see this gives the same values.","category":"page"},{"location":"tutorials/parameter_estimation_ode/#odeparamestim","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"","category":"section"},{"location":"tutorials/parameter_estimation_ode/#Copy-Paste-Code","page":"Parameter Estimation of Ordinary Differential Equations","title":"Copy-Paste Code","text":"","category":"section"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"If you want to just get things running, try the following! Explanation will follow.","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"using DifferentialEquations,\n    Optimization, OptimizationPolyalgorithms, SciMLSensitivity,\n    Zygote, Plots\n\nfunction lotka_volterra!(du, u, p, t)\n    x, y = u\n    α, β, δ, γ = p\n    du[1] = dx = α * x - β * x * y\n    du[2] = dy = -δ * y + γ * x * y\nend\n\n# Initial condition\nu0 = [1.0, 1.0]\n\n# Simulation interval and intermediary points\ntspan = (0.0, 10.0)\ntsteps = 0.0:0.1:10.0\n\n# LV equation parameter. p = [α, β, δ, γ]\np = [1.5, 1.0, 3.0, 1.0]\n\n# Setup the ODE problem, then solve\nprob = ODEProblem(lotka_volterra!, u0, tspan, p)\nsol = solve(prob, Tsit5())\n\n# Plot the solution\nusing Plots\nplot(sol)\nsavefig(\"LV_ode.png\")\n\nfunction loss(p)\n    sol = solve(prob, Tsit5(), p = p, saveat = tsteps)\n    loss = sum(abs2, sol .- 1)\n    return loss, sol\nend\n\ncallback = function (p, l, pred)\n    display(l)\n    plt = plot(pred, ylim = (0, 6))\n    display(plt)\n    # Tell Optimization.solve to not halt the optimization. If return true, then\n    # optimization stops.\n    return false\nend\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, p)\n\nresult_ode = Optimization.solve(optprob, PolyOpt(),\n    callback = callback,\n    maxiters = 100)","category":"page"},{"location":"tutorials/parameter_estimation_ode/#Explanation","page":"Parameter Estimation of Ordinary Differential Equations","title":"Explanation","text":"","category":"section"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"First, let's create a Lotka-Volterra ODE using DifferentialEquations.jl. For more details, see the DifferentialEquations.jl documentation. The Lotka-Volterra equations have the form:","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"beginaligned\nfracdxdt = alpha x - beta x y      \nfracdydt = -delta y + gamma x y    \nendaligned","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"using DifferentialEquations,\n    Optimization, OptimizationPolyalgorithms,\n    SciMLSensitivity, Zygote, Plots\n\nfunction lotka_volterra!(du, u, p, t)\n    x, y = u\n    α, β, δ, γ = p\n    du[1] = dx = α * x - β * x * y\n    du[2] = dy = -δ * y + γ * x * y\nend\n\n# Initial condition\nu0 = [1.0, 1.0]\n\n# Simulation interval and intermediary points\ntspan = (0.0, 10.0)\ntsteps = 0.0:0.1:10.0\n\n# LV equation parameter. p = [α, β, δ, γ]\np = [1.5, 1.0, 3.0, 1.0]\n\n# Setup the ODE problem, then solve\nprob = ODEProblem(lotka_volterra!, u0, tspan, p)\nsol = solve(prob, Tsit5())\n\n# Plot the solution\nusing Plots\nplot(sol)\nsavefig(\"LV_ode.png\")","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"(Image: LV Solution Plot)","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"For this first example, we do not yet include a neural network. We take an AD-compatible solve function that takes the parameters and an initial condition and returns the solution of the differential equation. Next, we choose a loss function. Our goal will be to find parameters that make the Lotka-Volterra solution constant x(t)=1, so we define our loss as the squared distance from 1.","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"function loss(p)\n    sol = solve(prob, Tsit5(), p = p, saveat = tsteps)\n    loss = sum(abs2, sol .- 1)\n    return loss, sol\nend","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"Lastly, we use the Optimization.solve function to train the parameters using ADAM to arrive at parameters which optimize for our goal. Optimization.solve allows defining a callback that will be called at each step of our training loop. It takes in the current parameter vector and the returns of the last call to the loss function. We will display the current loss and make a plot of the current situation:","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"callback = function (p, l, pred)\n    display(l)\n    plt = plot(pred, ylim = (0, 6))\n    display(plt)\n    # Tell Optimization.solve to not halt the optimization. If return true, then\n    # optimization stops.\n    return false\nend","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"Let's optimize the model.","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"adtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, p)\n\nresult_ode = Optimization.solve(optprob, PolyOpt(),\n    callback = callback,\n    maxiters = 100)","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"In just seconds we found parameters which give a relative loss of 1e-16! We can get the final loss with result_ode.minimum, and get the optimal parameters with result_ode.u. For example, we can plot the final outcome and show that we solved the control problem and successfully found parameters to make the ODE solution constant:","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"remade_solution = solve(remake(prob, p = result_ode.u), Tsit5(),\n    saveat = tsteps)\nplot(remade_solution, ylim = (0, 6))","category":"page"},{"location":"tutorials/parameter_estimation_ode/","page":"Parameter Estimation of Ordinary Differential Equations","title":"Parameter Estimation of Ordinary Differential Equations","text":"(Image: Final plot)","category":"page"},{"location":"examples/hybrid_jump/hybrid_diffeq/#Training-Neural-Networks-in-Hybrid-Differential-Equations","page":"Training Neural Networks in Hybrid Differential Equations","title":"Training Neural Networks in Hybrid Differential Equations","text":"","category":"section"},{"location":"examples/hybrid_jump/hybrid_diffeq/","page":"Training Neural Networks in Hybrid Differential Equations","title":"Training Neural Networks in Hybrid Differential Equations","text":"Hybrid differential equations are differential equations with implicit or explicit discontinuities as specified by callbacks. In the following example, explicit dosing times are given for a pharmacometric model and the universal differential equation is trained to uncover the missing dynamical equations.","category":"page"},{"location":"examples/hybrid_jump/hybrid_diffeq/","page":"Training Neural Networks in Hybrid Differential Equations","title":"Training Neural Networks in Hybrid Differential Equations","text":"using DiffEqFlux, Flux, DifferentialEquations, Plots\nu0 = Float32[2.0; 0.0]\ndatasize = 100\ntspan = (0.0f0, 10.5f0)\ndosetimes = [1.0, 2.0, 4.0, 8.0]\n\nfunction affect!(integrator)\n    integrator.u = integrator.u .+ 1\nend\ncb_ = PresetTimeCallback(dosetimes, affect!, save_positions = (false, false))\nfunction trueODEfunc(du, u, p, t)\n    du .= -u\nend\nt = range(tspan[1], tspan[2], length = datasize)\n\nprob = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob, Tsit5(), callback = cb_, saveat = t))\ndudt2 = Flux.Chain(Flux.Dense(2, 50, tanh),\n    Flux.Dense(50, 2))\np, re = Flux.destructure(dudt2) # use this p as the initial condition!\n\nfunction dudt(du, u, p, t)\n    du[1:2] .= -u[1:2]\n    du[3:end] .= re(p)(u[1:2]) #re(p)(u[3:end])\nend\nz0 = Float32[u0; u0]\nprob = ODEProblem(dudt, z0, tspan)\n\naffect!(integrator) = integrator.u[1:2] .= integrator.u[3:end]\ncallback = PresetTimeCallback(dosetimes, affect!, save_positions = (false, false))\n\nfunction predict_n_ode()\n    _prob = remake(prob, p = p)\n    Array(solve(_prob, Tsit5(), u0 = z0, p = p, callback = callback, saveat = t,\n        sensealg = ReverseDiffAdjoint()))[1:2,\n        :]\n    #Array(solve(prob,Tsit5(),u0=z0,p=p,saveat=t))[1:2,:]\nend\n\nfunction loss_n_ode()\n    pred = predict_n_ode()\n    loss = sum(abs2, ode_data .- pred)\n    loss\nend\nloss_n_ode() # n_ode.p stores the initial parameters of the neural ODE\n\ncba = function (; doplot = false) #callback function to observe training\n    pred = predict_n_ode()\n    display(sum(abs2, ode_data .- pred))\n    # plot current prediction against data\n    pl = scatter(t, ode_data[1, :], label = \"data\")\n    scatter!(pl, t, pred[1, :], label = \"prediction\")\n    display(plot(pl))\n    return false\nend\ncba()\n\nps = Flux.params(p)\ndata = Iterators.repeated((), 200)\nFlux.train!(loss_n_ode, ps, data, ADAM(0.05), cb = cba)","category":"page"},{"location":"examples/hybrid_jump/hybrid_diffeq/","page":"Training Neural Networks in Hybrid Differential Equations","title":"Training Neural Networks in Hybrid Differential Equations","text":"(Image: Hybrid Universal Differential Equation)","category":"page"},{"location":"examples/hybrid_jump/hybrid_diffeq/#Note-on-Sensitivity-Methods","page":"Training Neural Networks in Hybrid Differential Equations","title":"Note on Sensitivity Methods","text":"","category":"section"},{"location":"examples/hybrid_jump/hybrid_diffeq/","page":"Training Neural Networks in Hybrid Differential Equations","title":"Training Neural Networks in Hybrid Differential Equations","text":"The continuous adjoint sensitivities BacksolveAdjoint, InterpolatingAdjoint, and QuadratureAdjoint are compatible with events for ODEs. BacksolveAdjoint and InterpolatingAdjoint can also handle events for SDEs. Use BacksolveAdjoint if the event terminates the time evolution and several states are saved. Currently, the continuous adjoint sensitivities do not support multiple events per time point.","category":"page"},{"location":"examples/hybrid_jump/hybrid_diffeq/","page":"Training Neural Networks in Hybrid Differential Equations","title":"Training Neural Networks in Hybrid Differential Equations","text":"All methods based on discrete sensitivity analysis via automatic differentiation, like ReverseDiffAdjoint, TrackerAdjoint, or ForwardDiffSensitivity are the methods to use (and ReverseDiffAdjoint is demonstrated above), are compatible with events. This applies to SDEs, DAEs, and DDEs as well.","category":"page"},{"location":"examples/ode/second_order_adjoints/#Newton-and-Hessian-Free-Newton-Krylov-with-Second-Order-Adjoint-Sensitivity-Analysis","page":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","title":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","text":"","category":"section"},{"location":"examples/ode/second_order_adjoints/","page":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","title":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","text":"In many cases it may be more optimal or more stable to fit using second order Newton-based optimization techniques. Since SciMLSensitivity.jl provides second order sensitivity analysis for fast Hessians and Hessian-vector products (via forward-over-reverse), we can utilize these in our neural/universal differential equation training processes.","category":"page"},{"location":"examples/ode/second_order_adjoints/","page":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","title":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","text":"sciml_train is set up to automatically use second order sensitivity analysis methods if a second order optimizer is requested via Optim.jl. Thus Newton and NewtonTrustRegion optimizers will use a second order Hessian-based optimization, while KrylovTrustRegion will utilize a Krylov-based method with Hessian-vector products (never forming the Hessian) for large parameter optimizations.","category":"page"},{"location":"examples/ode/second_order_adjoints/","page":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","title":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","text":"using Flux, DiffEqFlux, Optimization, OptimizationFlux, DifferentialEquations,\n    Plots, Random, OptimizationOptimJL\n\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u .^ 3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\ndudt2 = Flux.Chain(x -> x .^ 3,\n    Flux.Dense(2, 50, tanh),\n    Flux.Dense(50, 2))\nprob_neuralode = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)\n\nfunction predict_neuralode(p)\n    Array(prob_neuralode(u0, p)[1])\nend\n\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, ode_data .- pred)\n    return loss, pred\nend\n\n# Callback function to observe training\nlist_plots = []\niter = 0\ncallback = function (p, l, pred; doplot = false)\n    global list_plots, iter\n\n    if iter == 0\n        list_plots = []\n    end\n    iter += 1\n\n    display(l)\n\n    # plot current prediction against data\n    plt = scatter(tsteps, ode_data[1, :], label = \"data\")\n    scatter!(plt, tsteps, pred[1, :], label = \"prediction\")\n    push!(list_plots, plt)\n    if doplot\n        display(plot(plt))\n    end\n\n    return l < 0.01\nend\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_neuralode(x), adtype)\n\noptprob1 = Optimization.OptimizationProblem(optf, prob_neuralode.p)\npstart = Optimization.solve(optprob1, ADAM(0.01), callback = callback, maxiters = 100).u\n\noptprob2 = Optimization.OptimizationProblem(optf, pstart)\npmin = Optimization.solve(optprob2, NewtonTrustRegion(), callback = callback,\n    maxiters = 200)\npmin = Optimization.solve(optprob2, Optim.KrylovTrustRegion(), callback = callback,\n    maxiters = 200)","category":"page"},{"location":"examples/ode/second_order_adjoints/","page":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","title":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","text":"Note that we do not demonstrate Newton() because we have not found a single case where it is competitive with the other two methods. KrylovTrustRegion() is generally the fastest due to its use of Hessian-vector products.","category":"page"},{"location":"examples/hybrid_jump/bouncing_ball/#Bouncing-Ball-Hybrid-ODE-Optimization","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"","category":"section"},{"location":"examples/hybrid_jump/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"The bouncing ball is a classic hybrid ODE which can be represented in the DifferentialEquations.jl event handling system. This can be applied to ODEs, SDEs, DAEs, DDEs, and more. Let's now add the DiffEqFlux machinery to this problem in order to optimize the friction that's required to match data. Assume we have data for the ball's height after 15 seconds. Let's first start by implementing the ODE:","category":"page"},{"location":"examples/hybrid_jump/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"using Optimization, OptimizationPolyalgorithms, SciMLSensitivity, DifferentialEquations\n\nfunction f(du, u, p, t)\n    du[1] = u[2]\n    du[2] = -p[1]\nend\n\nfunction condition(u, t, integrator) # Event when event_f(u,t) == 0\n    u[1]\nend\n\nfunction affect!(integrator)\n    integrator.u[2] = -integrator.p[2] * integrator.u[2]\nend\n\ncallback = ContinuousCallback(condition, affect!)\nu0 = [50.0, 0.0]\ntspan = (0.0, 15.0)\np = [9.8, 0.8]\nprob = ODEProblem(f, u0, tspan, p)\nsol = solve(prob, Tsit5(), callback = callback)","category":"page"},{"location":"examples/hybrid_jump/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"Here we have a friction coefficient of 0.8. We want to refine this coefficient to find the value so that the predicted height of the ball at the endpoint is 20. We do this by minimizing a loss function against the value 20:","category":"page"},{"location":"examples/hybrid_jump/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"function loss(θ)\n    sol = solve(prob, Tsit5(), p = [9.8, θ[1]], callback = callback)\n    target = 20.0\n    abs2(sol[end][1] - target)\nend\n\nloss([0.8])\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, [0.8])\n@time res = Optimization.solve(optprob, PolyOpt(), maxiters = 300)\n@show res.u # [0.866554105436901]","category":"page"},{"location":"examples/hybrid_jump/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"This runs in about 0.091215 seconds (533.45 k allocations: 80.717 MiB) and finds an optimal drag coefficient.","category":"page"},{"location":"examples/hybrid_jump/bouncing_ball/#Note-on-Sensitivity-Methods","page":"Bouncing Ball Hybrid ODE Optimization","title":"Note on Sensitivity Methods","text":"","category":"section"},{"location":"examples/hybrid_jump/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"The continuous adjoint sensitivities BacksolveAdjoint, InterpolatingAdjoint, and QuadratureAdjoint are compatible with events for ODEs. BacksolveAdjoint and InterpolatingAdjoint can also handle events for SDEs. Use BacksolveAdjoint if the event terminates the time evolution and several states are saved. Currently, the continuous adjoint sensitivities do not support multiple events per time point.","category":"page"},{"location":"examples/hybrid_jump/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"All methods based on discrete sensitivity analysis via automatic differentiation, like ReverseDiffAdjoint, TrackerAdjoint, or ForwardDiffSensitivity are the methods to use (and ReverseDiffAdjoint is demonstrated above), are compatible with events. This applies to SDEs, DAEs, and DDEs as well.","category":"page"},{"location":"examples/sde/SDE_control/#Controlling-Stochastic-Differential-Equations","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"","category":"section"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"In this tutorial, we show how to use DiffEqFlux to control the time evolution of a system described by a stochastic differential equation (SDE). Specifically, we consider a continuously monitored qubit described by an SDE in the Ito sense with multiplicative scalar noise (see [1] for a reference):","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"dψ = b(ψ(t) Ω(t))ψ(t) dt + σ(ψ(t))ψ(t) dW_t ","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We use a predictive model to map the quantum state of the qubit, ψ(t), at each time to the control parameter Ω(t) which rotates the quantum state about the x-axis of the Bloch sphere to ultimately prepare and stabilize the qubit in the excited state.","category":"page"},{"location":"examples/sde/SDE_control/#Copy-Pasteable-Code","page":"Controlling Stochastic Differential Equations","title":"Copy-Pasteable Code","text":"","category":"section"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"Before getting to the explanation, here's some code to start with. We will follow a full explanation of the definition and training process:","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"# load packages\nusing DiffEqFlux\nusing SciMLSensitivity\nusing Optimization, OptimizationOptimisers\nusing StochasticDiffEq, DiffEqCallbacks, DiffEqNoiseProcess\nusing Zygote, Statistics, LinearAlgebra, Random\nusing Lux, Random, ComponentArrays\nusing Plots\n\nrng = Random.default_rng()\n\n#################################################\nlr = 0.01f0\nepochs = 100\n\nnumtraj = 16 # number of trajectories in parallel simulations for training\nnumtrajplot = 32 # .. for plotting\n\n# time range for the solver\ndt = 0.0005f0\ntinterval = 0.05f0\ntstart = 0.0f0\nNintervals = 20 # total number of intervals, total time = t_interval*Nintervals\ntspan = (tstart, tinterval * Nintervals)\nts = Array(tstart:dt:(Nintervals * tinterval + dt)) # time array for noise grid\n\n# Hamiltonian parameters\nΔ = 20.0f0\nΩmax = 10.0f0 # control parameter (maximum amplitude)\nκ = 0.3f0\n\n# loss hyperparameters\nC1 = Float32(1.0)  # evolution state fidelity\n\nstruct Parameters{flType, intType, tType}\n    lr::flType\n    epochs::intType\n    numtraj::intType\n    numtrajplot::intType\n    dt::flType\n    tinterval::flType\n    tspan::tType\n    Nintervals::intType\n    ts::Vector{flType}\n    Δ::flType\n    Ωmax::flType\n    κ::flType\n    C1::flType\nend\n\nmyparameters = Parameters{typeof(dt), typeof(numtraj), typeof(tspan)}(lr, epochs, numtraj,\n    numtrajplot, dt,\n    tinterval, tspan,\n    Nintervals, ts,\n    Δ, Ωmax, κ, C1)\n\n################################################\n# Define Neural Network\n\n# state-aware\nnn = Lux.Chain(Lux.Dense(4, 32, relu),\n    Lux.Dense(32, 1, tanh))\n\np_nn, st = Lux.setup(rng, nn)\np_nn = ComponentArray(p_nn)\n\n###############################################\n# initial state anywhere on the Bloch sphere\nfunction prepare_initial(dt, n_par)\n    # shape 4 x n_par\n    # input number of parallel realizations and dt for type inference\n    # random position on the Bloch sphere\n    theta = acos.(2 * rand(typeof(dt), n_par) .- 1)  # uniform sampling for cos(theta) between -1 and 1\n    phi = rand(typeof(dt), n_par) * 2 * pi  # uniform sampling for phi between 0 and 2pi\n    # real and imaginary parts ceR, cdR, ceI, cdI\n    u0 = [\n        cos.(theta / 2),\n        sin.(theta / 2) .* cos.(phi),\n        false * theta,\n        sin.(theta / 2) .* sin.(phi),\n    ]\n    return vcat(transpose.(u0)...) # build matrix\nend\n\n# target state\n# ψtar = |up>\n\nu0 = prepare_initial(myparameters.dt, myparameters.numtraj)\n\n###############################################\n# Define SDE\n\nfunction qubit_drift!(du, u, p, t)\n    # expansion coefficients |Ψ> = ce |e> + cd |d>\n    ceR, cdR, ceI, cdI = u # real and imaginary parts\n\n    # Δ: atomic frequency\n    # Ω: Rabi frequency for field in x direction\n    # κ: spontaneous emission\n    Δ, Ωmax, κ = p.myparameters\n    nn_weights = p.p_nn\n    Ω = (nn(u, nn_weights, st)[1] .* Ωmax)[1]\n\n    @inbounds begin\n        du[1] = 1 // 2 * (ceI * Δ - ceR * κ + cdI * Ω)\n        du[2] = -cdI * Δ / 2 + 1 * ceR * (cdI * ceI + cdR * ceR) * κ + ceI * Ω / 2\n        du[3] = 1 // 2 * (-ceR * Δ - ceI * κ - cdR * Ω)\n        du[4] = cdR * Δ / 2 + 1 * ceI * (cdI * ceI + cdR * ceR) * κ - ceR * Ω / 2\n    end\n    return nothing\nend\n\nfunction qubit_diffusion!(du, u, p, t)\n    ceR, cdR, ceI, cdI = u # real and imaginary parts\n\n    κ = p.myparameters[end]\n\n    du .= false\n\n    @inbounds begin\n        #du[1] = zero(ceR)\n        du[2] += sqrt(κ) * ceR\n        #du[3] = zero(ceR)\n        du[4] += sqrt(κ) * ceI\n    end\n    return nothing\nend\n\n# normalization callback\ncondition(u, t, integrator) = true\nfunction affect!(integrator)\n    integrator.u .= integrator.u / norm(integrator.u)\nend\ncallback = DiscreteCallback(condition, affect!, save_positions = (false, false))\n\nCreateGrid(t, W1) = NoiseGrid(t, W1)\nZygote.@nograd CreateGrid #avoid taking grads of this function\n\n# set scalar random process\nW = sqrt(myparameters.dt) * randn(typeof(myparameters.dt), size(myparameters.ts)) #for 1 trajectory\nW1 = cumsum([zero(myparameters.dt); W[1:(end - 1)]], dims = 1)\nNG = CreateGrid(myparameters.ts, W1)\n\n# get control pulses\np_all = ComponentArray(p_nn = p_nn,\n    myparameters = [myparameters.Δ, myparameters.Ωmax, myparameters.κ])\n# define SDE problem\nprob = SDEProblem{true}(qubit_drift!, qubit_diffusion!, vec(u0[:, 1]), myparameters.tspan,\n    p_all,\n    callback = callback, noise = NG)\n\n#########################################\n# compute loss\nfunction g(u, p, t)\n    ceR = @view u[1, :, :]\n    cdR = @view u[2, :, :]\n    ceI = @view u[3, :, :]\n    cdI = @view u[4, :, :]\n    p[1] * mean((cdR .^ 2 + cdI .^ 2) ./ (ceR .^ 2 + cdR .^ 2 + ceI .^ 2 + cdI .^ 2))\nend\n\nfunction loss(p_nn; alg = EM(), sensealg = BacksolveAdjoint(autojacvec = ReverseDiffVJP()))\n    pars = ComponentArray(p_nn = p_nn,\n        myparameters = [myparameters.Δ, myparameters.Ωmax, myparameters.κ])\n    u0 = prepare_initial(myparameters.dt, myparameters.numtraj)\n\n    function prob_func(prob, i, repeat)\n        # prepare initial state and applied control pulse\n        u0tmp = deepcopy(vec(u0[:, i]))\n        W = sqrt(myparameters.dt) * randn(typeof(myparameters.dt), size(myparameters.ts)) #for 1 trajectory\n        W1 = cumsum([zero(myparameters.dt); W[1:(end - 1)]], dims = 1)\n        NG = CreateGrid(myparameters.ts, W1)\n\n        remake(prob,\n            p = pars,\n            u0 = u0tmp,\n            callback = callback,\n            noise = NG)\n    end\n\n    ensembleprob = EnsembleProblem(prob,\n        prob_func = prob_func,\n        safetycopy = true)\n\n    _sol = solve(ensembleprob, alg, EnsembleThreads(),\n        sensealg = sensealg,\n        saveat = myparameters.tinterval,\n        dt = myparameters.dt,\n        adaptive = false,\n        trajectories = myparameters.numtraj, batch_size = myparameters.numtraj)\n    A = convert(Array, _sol)\n\n    l = g(A, [myparameters.C1], nothing)\n    # returns loss value\n    return l\nend\n\n#########################################\n# visualization -- run for new batch\nfunction visualize(p_nn; alg = EM())\n    u0 = prepare_initial(myparameters.dt, myparameters.numtrajplot)\n    pars = ComponentArray(p_nn = p_nn,\n        myparameters = [myparameters.Δ, myparameters.Ωmax, myparameters.κ])\n\n    function prob_func(prob, i, repeat)\n        # prepare initial state and applied control pulse\n        u0tmp = deepcopy(vec(u0[:, i]))\n        W = sqrt(myparameters.dt) * randn(typeof(myparameters.dt), size(myparameters.ts)) #for 1 trajectory\n        W1 = cumsum([zero(myparameters.dt); W[1:(end - 1)]], dims = 1)\n        NG = CreateGrid(myparameters.ts, W1)\n\n        remake(prob,\n            p = pars,\n            u0 = u0tmp,\n            callback = callback,\n            noise = NG)\n    end\n\n    ensembleprob = EnsembleProblem(prob,\n        prob_func = prob_func,\n        safetycopy = true)\n\n    u = solve(ensembleprob, alg, EnsembleThreads(),\n        saveat = myparameters.tinterval,\n        dt = myparameters.dt,\n        adaptive = false, #abstol=1e-6, reltol=1e-6,\n        trajectories = myparameters.numtrajplot,\n        batch_size = myparameters.numtrajplot)\n\n    ceR = @view u[1, :, :]\n    cdR = @view u[2, :, :]\n    ceI = @view u[3, :, :]\n    cdI = @view u[4, :, :]\n    infidelity = @. (cdR^2 + cdI^2) / (ceR^2 + cdR^2 + ceI^2 + cdI^2)\n    meaninfidelity = mean(infidelity)\n    loss = myparameters.C1 * meaninfidelity\n\n    @info \"Loss: \" loss\n\n    fidelity = @. (ceR^2 + ceI^2) / (ceR^2 + cdR^2 + ceI^2 + cdI^2)\n\n    mf = mean(fidelity, dims = 2)[:]\n    sf = std(fidelity, dims = 2)[:]\n\n    pl1 = plot(0:(myparameters.Nintervals), mf,\n        ribbon = sf,\n        ylim = (0, 1), xlim = (0, myparameters.Nintervals),\n        c = 1, lw = 1.5, xlabel = \"steps i\", ylabel = \"Fidelity\", legend = false)\n\n    pl = plot(pl1, legend = false, size = (400, 360))\n    return pl, loss\nend\n\n# burn-in loss\nl = loss(p_nn)\n# callback to visualize training\nvisualization_callback = function (p, l; doplot = false)\n    println(l)\n\n    if doplot\n        pl, _ = visualize(p)\n        display(pl)\n    end\n\n    return false\nend\n\n# Display the ODE with the initial parameter values.\nvisualization_callback(p_nn, l; doplot = true)\n\n###################################\n# training loop\n@info \"Start Training..\"\n\n# optimize the parameters for a few epochs with ADAM on time span\n# Setup and run the optimization\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\n\noptprob = Optimization.OptimizationProblem(optf, p_nn)\nres = Optimization.solve(optprob, OptimizationOptimisers.Adam(myparameters.lr),\n    callback = visualization_callback,\n    maxiters = 100)\n\n# plot optimized control\nvisualization_callback(res.u, loss(res.u); doplot = true)","category":"page"},{"location":"examples/sde/SDE_control/#Step-by-step-description","page":"Controlling Stochastic Differential Equations","title":"Step-by-step description","text":"","category":"section"},{"location":"examples/sde/SDE_control/#Load-packages","page":"Controlling Stochastic Differential Equations","title":"Load packages","text":"","category":"section"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"using DiffEqFlux\nusing SciMLSensitivity\nusing Optimization, OptimizationOptimisers, Zygote\nusing StochasticDiffEq, DiffEqCallbacks, DiffEqNoiseProcess\nusing Statistics, LinearAlgebra\nusing Lux, Random, ComponentArrays\nusing Plots","category":"page"},{"location":"examples/sde/SDE_control/#Parameters","page":"Controlling Stochastic Differential Equations","title":"Parameters","text":"","category":"section"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We define the parameters of the qubit and hyperparameters of the training process.","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"lr = 0.01f0\nepochs = 100\n\nnumtraj = 16 # number of trajectories in parallel simulations for training\nnumtrajplot = 32 # .. for plotting\n\nrng = Random.default_rng()\n\n# time range for the solver\ndt = 0.0005f0\ntinterval = 0.05f0\ntstart = 0.0f0\nNintervals = 20 # total number of intervals, total time = t_interval*Nintervals\ntspan = (tstart, tinterval * Nintervals)\nts = Array(tstart:dt:(Nintervals * tinterval + dt)) # time array for noise grid\n\n# Hamiltonian parameters\nΔ = 20.0f0\nΩmax = 10.0f0 # control parameter (maximum amplitude)\nκ = 0.3f0\n\n# loss hyperparameters\nC1 = Float32(1.0)  # evolution state fidelity\n\nstruct Parameters{flType, intType, tType}\n    lr::flType\n    epochs::intType\n    numtraj::intType\n    numtrajplot::intType\n    dt::flType\n    tinterval::flType\n    tspan::tType\n    Nintervals::intType\n    ts::Vector{flType}\n    Δ::flType\n    Ωmax::flType\n    κ::flType\n    C1::flType\nend\n\nmyparameters = Parameters{typeof(dt), typeof(numtraj), typeof(tspan)}(lr, epochs, numtraj,\n    numtrajplot, dt,\n    tinterval, tspan,\n    Nintervals, ts,\n    Δ, Ωmax, κ, C1)","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"In plain terms, the quantities that were defined are:","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"lr = learning rate of the optimizer\nepochs = number of epochs in the training process\nnumtraj = number of simulated trajectories in the training process\nnumtrajplot = number of simulated trajectories to visualize the performance\ndt = time step for solver (initial dt if adaptive)\ntinterval = time spacing between checkpoints\ntspan = time span\nNintervals = number of checkpoints\nts = discretization of the entire time interval, used for NoiseGrid\nΔ = detuning between the qubit and the laser\nΩmax = maximum frequency of the control laser\nκ = decay rate\nC1 = loss function hyperparameter","category":"page"},{"location":"examples/sde/SDE_control/#Controller","page":"Controlling Stochastic Differential Equations","title":"Controller","text":"","category":"section"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We use a neural network to control the parameter Ω(t). Alternatively, one could also, e.g., use tensor layers, Flux.jl, or Lux.jl.","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"# state-aware\nnn = Lux.Chain(Lux.Dense(4, 32, relu),\n    Lux.Dense(32, 1, tanh))\n\np_nn, st = Lux.setup(rng, nn)\np_nn = ComponentArray(p_nn)","category":"page"},{"location":"examples/sde/SDE_control/#Initial-state","page":"Controlling Stochastic Differential Equations","title":"Initial state","text":"","category":"section"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We prepare n_par initial states, uniformly distributed over the Bloch sphere. To avoid complex numbers in our simulations, we split the state of the qubit","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"  ψ(t) = c_e(t) (10) + c_d(t) (01)","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"into its real and imaginary part.","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"# initial state anywhere on the Bloch sphere\nfunction prepare_initial(dt, n_par)\n    # shape 4 x n_par\n    # input number of parallel realizations and dt for type inference\n    # random position on the Bloch sphere\n    theta = acos.(2 * rand(typeof(dt), n_par) .- 1)  # uniform sampling for cos(theta) between -1 and 1\n    phi = rand(typeof(dt), n_par) * 2 * pi  # uniform sampling for phi between 0 and 2pi\n    # real and imaginary parts ceR, cdR, ceI, cdI\n    u0 = [\n        cos.(theta / 2),\n        sin.(theta / 2) .* cos.(phi),\n        false * theta,\n        sin.(theta / 2) .* sin.(phi),\n    ]\n    return vcat(transpose.(u0)...) # build matrix\nend\n\n# target state\n# ψtar = |e>\n\nu0 = prepare_initial(myparameters.dt, myparameters.numtraj)","category":"page"},{"location":"examples/sde/SDE_control/#Defining-the-SDE","page":"Controlling Stochastic Differential Equations","title":"Defining the SDE","text":"","category":"section"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We define the drift and diffusion term of the qubit. The SDE doesn't preserve the norm of the quantum state. To ensure the normalization of the state, we add a DiscreteCallback after each time step. Further, we use a NoiseGrid from the DiffEqNoiseProcess package, as one possibility to simulate a 1D Brownian motion. Note that the NN is placed directly into the drift function, thus the control parameter Ω is continuously updated.","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"# Define SDE\nfunction qubit_drift!(du, u, p, t)\n    # expansion coefficients |Ψ> = ce |e> + cd |d>\n    ceR, cdR, ceI, cdI = u # real and imaginary parts\n\n    # Δ: atomic frequency\n    # Ω: Rabi frequency for field in x direction\n    # κ: spontaneous emission\n    Δ, Ωmax, κ = p.myparameters\n    nn_weights = p.p_nn\n    Ω = (nn(u, nn_weights, st)[1] .* Ωmax)[1]\n\n    @inbounds begin\n        du[1] = 1 // 2 * (ceI * Δ - ceR * κ + cdI * Ω)\n        du[2] = -cdI * Δ / 2 + 1 * ceR * (cdI * ceI + cdR * ceR) * κ + ceI * Ω / 2\n        du[3] = 1 // 2 * (-ceR * Δ - ceI * κ - cdR * Ω)\n        du[4] = cdR * Δ / 2 + 1 * ceI * (cdI * ceI + cdR * ceR) * κ - ceR * Ω / 2\n    end\n    return nothing\nend\n\nfunction qubit_diffusion!(du, u, p, t)\n    ceR, cdR, ceI, cdI = u # real and imaginary parts\n\n    κ = p[end]\n\n    du .= false\n\n    @inbounds begin\n        #du[1] = zero(ceR)\n        du[2] += sqrt(κ) * ceR\n        #du[3] = zero(ceR)\n        du[4] += sqrt(κ) * ceI\n    end\n    return nothing\nend\n\n# normalization callback\ncondition(u, t, integrator) = true\nfunction affect!(integrator)\n    integrator.u .= integrator.u / norm(integrator.u)\nend\ncallback = DiscreteCallback(condition, affect!, save_positions = (false, false))\n\nCreateGrid(t, W1) = NoiseGrid(t, W1)\nZygote.@nograd CreateGrid #avoid taking grads of this function\n\n# set scalar random process\nW = sqrt(myparameters.dt) * randn(typeof(myparameters.dt), size(myparameters.ts)) #for 1 trajectory\nW1 = cumsum([zero(myparameters.dt); W[1:(end - 1)]], dims = 1)\nNG = CreateGrid(myparameters.ts, W1)\n\n# get control pulses\np_all = ComponentArray(p_nn = p_nn,\n    myparameters = [myparameters.Δ; myparameters.Ωmax; myparameters.κ])\n# define SDE problem\nprob = SDEProblem{true}(qubit_drift!, qubit_diffusion!, vec(u0[:, 1]), myparameters.tspan,\n    p_all,\n    callback = callback, noise = NG)","category":"page"},{"location":"examples/sde/SDE_control/#Compute-loss-function","page":"Controlling Stochastic Differential Equations","title":"Compute loss function","text":"","category":"section"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We'd like to prepare the excited state of the qubit. An appropriate choice for the loss function is the infidelity of the state ψ(t) with respect to the excited state. We create a parallelized EnsembleProblem, where the prob_func creates a new NoiseGrid for every trajectory and loops over the initial states. The number of parallel trajectories and the used batch size can be tuned by the kwargs trajectories=.. and batchsize=.. in the solve call. See also the parallel ensemble simulation docs for a description of the available ensemble algorithms. To optimize only the parameters of the neural network, we use pars = [p; myparameters.Δ; myparameters.Ωmax; myparameters.κ]","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"# compute loss\nfunction g(u, p, t)\n    ceR = @view u[1, :, :]\n    cdR = @view u[2, :, :]\n    ceI = @view u[3, :, :]\n    cdI = @view u[4, :, :]\n    p[1] * mean((cdR .^ 2 + cdI .^ 2) ./ (ceR .^ 2 + cdR .^ 2 + ceI .^ 2 + cdI .^ 2))\nend\n\nfunction loss(p_nn; alg = EM(), sensealg = BacksolveAdjoint(autojacvec = ReverseDiffVJP()))\n    pars = ComponentArray(p_nn = p_nn,\n        myparameters = [myparameters.Δ, myparameters.Ωmax,\n            myparameters.κ])\n    u0 = prepare_initial(myparameters.dt, myparameters.numtraj)\n\n    function prob_func(prob, i, repeat)\n        # prepare initial state and applied control pulse\n        u0tmp = deepcopy(vec(u0[:, i]))\n        W = sqrt(myparameters.dt) * randn(typeof(myparameters.dt), size(myparameters.ts)) #for 1 trajectory\n        W1 = cumsum([zero(myparameters.dt); W[1:(end - 1)]], dims = 1)\n        NG = CreateGrid(myparameters.ts, W1)\n\n        remake(prob,\n            p = pars,\n            u0 = u0tmp,\n            callback = callback,\n            noise = NG)\n    end\n\n    ensembleprob = EnsembleProblem(prob,\n        prob_func = prob_func,\n        safetycopy = true)\n\n    _sol = solve(ensembleprob, alg, EnsembleThreads(),\n        sensealg = sensealg,\n        saveat = myparameters.tinterval,\n        dt = myparameters.dt,\n        adaptive = false,\n        trajectories = myparameters.numtraj, batch_size = myparameters.numtraj)\n    A = convert(Array, _sol)\n\n    l = g(A, [myparameters.C1], nothing)\n    # returns loss value\n    return l\nend","category":"page"},{"location":"examples/sde/SDE_control/#Visualization","page":"Controlling Stochastic Differential Equations","title":"Visualization","text":"","category":"section"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"To visualize the performance of the controller, we plot the mean value and standard deviation of the fidelity of a bunch of trajectories (myparameters.numtrajplot) as a function of the time steps at which loss values are computed.","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"function visualize(p_nn; alg = EM())\n    u0 = prepare_initial(myparameters.dt, myparameters.numtrajplot)\n    pars = ComponentArray(p_nn = p_nn,\n        myparameters = [myparameters.Δ, myparameters.Ωmax,\n            myparameters.κ])\n\n    function prob_func(prob, i, repeat)\n        # prepare initial state and applied control pulse\n        u0tmp = deepcopy(vec(u0[:, i]))\n        W = sqrt(myparameters.dt) * randn(typeof(myparameters.dt), size(myparameters.ts)) #for 1 trajectory\n        W1 = cumsum([zero(myparameters.dt); W[1:(end - 1)]], dims = 1)\n        NG = CreateGrid(myparameters.ts, W1)\n\n        remake(prob,\n            p = pars,\n            u0 = u0tmp,\n            callback = callback,\n            noise = NG)\n    end\n\n    ensembleprob = EnsembleProblem(prob,\n        prob_func = prob_func,\n        safetycopy = true)\n\n    u = solve(ensembleprob, alg, EnsembleThreads(),\n        saveat = myparameters.tinterval,\n        dt = myparameters.dt,\n        adaptive = false, #abstol=1e-6, reltol=1e-6,\n        trajectories = myparameters.numtrajplot,\n        batch_size = myparameters.numtrajplot)\n\n    ceR = @view u[1, :, :]\n    cdR = @view u[2, :, :]\n    ceI = @view u[3, :, :]\n    cdI = @view u[4, :, :]\n    infidelity = @. (cdR^2 + cdI^2) / (ceR^2 + cdR^2 + ceI^2 + cdI^2)\n    meaninfidelity = mean(infidelity)\n    loss = myparameters.C1 * meaninfidelity\n\n    @info \"Loss: \" loss\n\n    fidelity = @. (ceR^2 + ceI^2) / (ceR^2 + cdR^2 + ceI^2 + cdI^2)\n\n    mf = mean(fidelity, dims = 2)[:]\n    sf = std(fidelity, dims = 2)[:]\n\n    pl1 = plot(0:(myparameters.Nintervals), mf,\n        ribbon = sf,\n        ylim = (0, 1), xlim = (0, myparameters.Nintervals),\n        c = 1, lw = 1.5, xlabel = \"steps i\", ylabel = \"Fidelity\", legend = false)\n\n    pl = plot(pl1, legend = false, size = (400, 360))\n    return pl, loss\nend\n# callback to visualize training\nvisualization_callback = function (p, l; doplot = false)\n    println(l)\n\n    if doplot\n        pl, _ = visualize(p)\n        display(pl)\n    end\n\n    return false\nend","category":"page"},{"location":"examples/sde/SDE_control/#Training","page":"Controlling Stochastic Differential Equations","title":"Training","text":"","category":"section"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We use the ADAM optimizer to optimize the parameters of the neural network. In each epoch, we draw new initial quantum states, compute the forward evolution, and, subsequently, the gradients of the loss function with respect to the parameters of the neural network. sensealg allows one to switch between the different sensitivity modes. InterpolatingAdjoint and BacksolveAdjoint are the two possible continuous adjoint sensitivity methods. The necessary correction between Ito and Stratonovich integrals is computed under the hood in the SciMLSensitivity package.","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"# optimize the parameters for a few epochs with ADAM on time span\n# Setup and run the optimization\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\n\noptprob = Optimization.OptimizationProblem(optf, p_nn)\nres = Optimization.solve(optprob, OptimizationOptimisers.Adam(myparameters.lr),\n    callback = visualization_callback,\n    maxiters = 100)\n\n# plot optimized control\nvisualization_callback(res.u, loss(res.u); doplot = true)","category":"page"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"(Image: Evolution of the fidelity as a function of time)","category":"page"},{"location":"examples/sde/SDE_control/#References","page":"Controlling Stochastic Differential Equations","title":"References","text":"","category":"section"},{"location":"examples/sde/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"[1] Schäfer, Frank, Pavel Sekatski, Martin Koppenhöfer, Christoph Bruder, and Michal Kloc. \"Control of stochastic quantum dynamics by differentiable programming.\" Machine Learning: Science and Technology 2, no. 3 (2021): 035004.","category":"page"},{"location":"tutorials/adjoint_continuous_functional/#continuous_loss","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"","category":"section"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"The automatic differentiation tutorial demonstrated how to use AD packages like ForwardDiff.jl and Zygote.jl to compute derivatives of differential equation solutions with respect to initial conditions and parameters. The subsequent direct sensitivity analysis tutorial showed how to directly use the SciMLSensitivity.jl internals to define and solve the augmented differential equation systems which are used in the automatic differentiation process.","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"While these internal functions give more flexibility, the previous demonstration focused on a case which was possible via automatic differentiation: discrete cost functionals. What is meant by discrete cost functionals is differentiation of a cost which uses a finite number of time points. In the automatic differentiation case, these finite time points are the points returned by solve, i.e. those chosen by the saveat option in the solve call. In the direct adjoint sensitivity tooling, these were the time points chosen by the ts vector.","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"However, there is an expanded set of cost functionals supported by SciMLSensitivity.jl, continuous cost functionals, which are not possible through automatic differentiation interfaces. In an abstract sense, a continuous cost functional is a total cost G defined as the integral of the instantaneous cost g at all time points. In other words, the total cost is defined as:","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"G(up)=G(u(cdotp))=int_t_0^Tg(u(tp)p)dt","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"Notice that this cost function cannot accurately be computed using only estimates of u at discrete time points. The purpose of this tutorial is to demonstrate how such cost functionals can be easily evaluated using the direct sensitivity analysis interfaces.","category":"page"},{"location":"tutorials/adjoint_continuous_functional/#Example:-Continuous-Functionals-with-Forward-Sensitivity-Analysis-via-Interpolation","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Example: Continuous Functionals with Forward Sensitivity Analysis via Interpolation","text":"","category":"section"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"Evaluating continuous cost functionals with forward sensitivity analysis is rather straightforward, since one can simply use the fact that the solution from ODEForwardSensitivityProblem is continuous when dense=true. For example,","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"using OrdinaryDiffEq, SciMLSensitivity\n\nfunction f(du, u, p, t)\n    du[1] = dx = p[1] * u[1] - p[2] * u[1] * u[2]\n    du[2] = dy = -p[3] * u[2] + u[1] * u[2]\nend\n\np = [1.5, 1.0, 3.0]\nprob = ODEForwardSensitivityProblem(f, [1.0; 1.0], (0.0, 10.0), p)\nsol = solve(prob, DP8())","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"gives a continuous solution sol(t) with the derivative at each time point. This can then be used to define a continuous cost function via Integrals.jl, though the derivative would need to be manually defined using the extra sensitivity terms.","category":"page"},{"location":"tutorials/adjoint_continuous_functional/#Example:-Continuous-Adjoints-on-an-Energy-Functional","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Example: Continuous Adjoints on an Energy Functional","text":"","category":"section"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"Continuous adjoints on a continuous functional are more automatic than forward mode. In this case, we'd like to calculate the adjoint sensitivity of the scalar energy functional:","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"G(up)=int_0^Tfracsum_i=1^nu_i^2(t)2dt","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"which is:","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"g(u, p, t) = (sum(u) .^ 2) ./ 2","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"Notice that the gradient of this function with respect to the state u is:","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"function dg(out, u, p, t)\n    out[1] = u[1] + u[2]\n    out[2] = u[1] + u[2]\nend","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"To get the adjoint sensitivities, we call:","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"prob = ODEProblem(f, [1.0; 1.0], (0.0, 10.0), p)\nsol = solve(prob, DP8())\nres = adjoint_sensitivities(sol, Vern9(), dgdu_continuous = dg, g = g, abstol = 1e-8,\n    reltol = 1e-8)","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"Notice that we can check this against autodifferentiation and numerical differentiation as follows:","category":"page"},{"location":"tutorials/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"using QuadGK, ForwardDiff, Calculus\nfunction G(p)\n    tmp_prob = remake(prob, p = p)\n    sol = solve(tmp_prob, Vern9(), abstol = 1e-14, reltol = 1e-14)\n    res, err = quadgk((t) -> (sum(sol(t)) .^ 2) ./ 2, 0.0, 10.0, atol = 1e-14, rtol = 1e-10)\n    res\nend\nres2 = ForwardDiff.gradient(G, [1.5, 1.0, 3.0])\nres3 = Calculus.gradient(G, [1.5, 1.0, 3.0])","category":"page"},{"location":"tutorials/chaotic_ode/#shadowing_methods","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"","category":"section"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"Let us define the instantaneous objective g(up) which depends on the state u and the parameter p of the differential equation. Then, if the objective is a long-time average quantity","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"langle g rangle_ = lim_T rightarrow  langle g rangle_T","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"where","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"langle g rangle_T = frac1T int_0^T g(up) textdt","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"under the assumption of ergodicity, langle g rangle_ only depends on p.","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"In the case of chaotic systems, the trajectories diverge with O(1) error. This can be seen, for instance, when solving the Lorenz system at 1e-14 tolerances with 9th order integrators and a small machine-epsilon perturbation:","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"using OrdinaryDiffEq, SciMLSensitivity, Zygote\n\nfunction lorenz!(du, u, p, t)\n    du[1] = 10 * (u[2] - u[1])\n    du[2] = u[1] * (p[1] - u[3]) - u[2]\n    du[3] = u[1] * u[2] - (8 // 3) * u[3]\nend\n\np = [28.0]\ntspan = (0.0, 100.0)\nu0 = [1.0, 0.0, 0.0]\nprob = ODEProblem(lorenz!, u0, tspan, p)\nsol = solve(prob, Vern9(), abstol = 1e-14, reltol = 1e-14)\nsol2 = solve(prob, Vern9(), abstol = 1e-14 + eps(Float64), reltol = 1e-14)","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"(Image: Chaotic behavior of the Lorenz system)","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"More formally, such chaotic behavior can be analyzed using tools from uncertainty quantification. This effect of diverging trajectories is known as the butterfly effect, and can be formulated as \"most (small) perturbations on initial conditions or parameters lead to new trajectories diverging exponentially fast from the original trajectory\".","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"The latter statement can be roughly translated to the level of sensitivity calculation as follows: \"For most initial conditions, the (homogeneous) tangent solutions grow exponentially fast.\"","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"To compute derivatives of an objective langle g rangle_ with respect to the parameters p of a chaotic system, one thus encounters that “traditional” forward and adjoint sensitivity methods diverge because the tangent space diverges with a rate given by the Lyapunov exponent. Taking the average of these derivative can then also fail, i.e., one finds that the average derivative is not the derivative of the average.","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"Although numerically computed chaotic trajectories diverge from the true/original trajectory, the shadowing theorem guarantees that there exists an errorless trajectory with a slightly different initial condition that stays near (“shadows”) the numerically computed one, see, e.g, the blog post or the non-intrusive least squares shadowing paper for more details. Essentially, the idea is to replace the ill-conditioned ODE by a well-conditioned optimization problem. Shadowing methods use the shadowing theorem within a renormalization procedure to distill the long-time effect from the joint observation of the long-time and the butterfly effect. This allows us to accurately compute derivatives w.r.t. the long-time average quantities.","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"The following sensealg choices exist","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"ForwardLSS(;LSSregularizer=TimeDilation(10.0,0.0,0.0),g=nothing,ADKwargs...): An implementation of the forward least square shadowing method. For LSSregularizer, one can choose between two different windowing options, TimeDilation (default) with weight 10.0 and CosWindowing, and Cos2Windowing.\nAdjointLSS(;LSSRegularizer=TimeDilation(10.0, 0.0, 0.0),g=nothing,ADKwargs...): An implementation of the adjoint-mode least square shadowing method. 10.0 controls the weight of the time dilation term in AdjointLSS.\nNILSS(nseg,nstep;nus=nothing,rng=Xorshifts.Xoroshiro128Plus(rand(UInt64)),g=nothing,ADKwargs...): An implementation of the non-intrusive least squares shadowing (NILSS) method. Here, nseg is the number of segments, nstep is the number of steps per segment, and nus is the number of unstable Lyapunov exponents.\nNILSAS(nseg,nstep,M=nothing;rng =Xorshifts.Xoroshiro128Plus(rand(UInt64)), adjoint_sensealg=BacksolveAdjoint(autojacvec=ReverseDiffVJP()),g=nothing,ADKwargs...): An implementation of the non-intrusive least squares adjoint shadowing (NILSAS) method. nseg is the number of segments. nstep is the number of steps per segment, M >= nus + 1 has to be provided, where nus is the number of unstable covariant Lyapunov vectors.","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"Recommendation: Since the computational and memory costs of NILSS() scale with the number of positive (unstable) Lyapunov, it is typically less expensive than ForwardLSS(). AdjointLSS() and NILSAS() are favorable for a large number of system parameters.","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"As an example, for the Lorenz system with g(u,p,t) = u[3], i.e., the z coordinate, as the instantaneous objective, we can use the direct interface by passing ForwardLSS as the sensealg:","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"function lorenz!(du, u, p, t)\n    du[1] = p[1] * (u[2] - u[1])\n    du[2] = u[1] * (p[2] - u[3]) - u[2]\n    du[3] = u[1] * u[2] - p[3] * u[3]\nend\n\np = [10.0, 28.0, 8 / 3]\n\ntspan_init = (0.0, 30.0)\ntspan_attractor = (30.0, 50.0)\nu0 = rand(3)\nprob_init = ODEProblem(lorenz!, u0, tspan_init, p)\nsol_init = solve(prob_init, Tsit5())\nprob_attractor = ODEProblem(lorenz!, sol_init[end], tspan_attractor, p)\n\ng(u, p, t) = u[end]\n\nfunction G(p)\n    _prob = remake(prob_attractor, p = p)\n    _sol = solve(_prob, Vern9(), abstol = 1e-14, reltol = 1e-14, saveat = 0.01,\n        sensealg = ForwardLSS(g = g))\n    sum(getindex.(_sol.u, 3))\nend\ndp1 = Zygote.gradient(p -> G(p), p)","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"Alternatively, we can define the ForwardLSSProblem and solve it via shadow_forward as follows:","category":"page"},{"location":"tutorials/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"sol_attractor = solve(prob_attractor, Vern9(), abstol = 1e-14, reltol = 1e-14)\nlss_problem = ForwardLSSProblem(sol_attractor, ForwardLSS(g = g))\nresfw = shadow_forward(lss_problem)","category":"page"},{"location":"sensitivity_math/#sensitivity_math","page":"Sensitivity Math Details","title":"Mathematics of Sensitivity Analysis","text":"","category":"section"},{"location":"sensitivity_math/#Forward-Sensitivity-Analysis","page":"Sensitivity Math Details","title":"Forward Sensitivity Analysis","text":"","category":"section"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"The local sensitivity is computed using the sensitivity ODE:","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"fracddtfracpartial upartial p_j=fracpartial fpartial ufracpartial upartial p_j+fracpartial fpartial p_j=Jcdot S_j+F_j","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"where","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"J=left(beginarraycccc\nfracpartial f_1partial u_1  fracpartial f_1partial u_2  cdots  fracpartial f_1partial u_k\nfracpartial f_2partial u_1  fracpartial f_2partial u_2  cdots  fracpartial f_2partial u_k\ncdots  cdots  cdots  cdots\nfracpartial f_kpartial u_1  fracpartial f_kpartial u_2  cdots  fracpartial f_kpartial u_k\nendarrayright)","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"is the Jacobian of the system,","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"F_j=left(beginarrayc\nfracpartial f_1partial p_j\nfracpartial f_2partial p_j\nvdots\nfracpartial f_kpartial p_j\nendarrayright)","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"are the parameter derivatives, and","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"S_j=left(beginarrayc\nfracpartial u_1partial p_j\nfracpartial u_2partial p_j\nvdots\nfracpartial u_kpartial p_j\nendarrayright)","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"is the vector of sensitivities. Since this ODE is dependent on the values of the independent variables themselves, this ODE is computed simultaneously with the actual ODE system.","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"Note that the Jacobian-vector product","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"fracpartial fpartial ufracpartial upartial p_j","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"can be computed without forming the Jacobian. With finite differences, this through using the following formula for the directional derivative","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"Jv approx fracf(x+v epsilon) - f(x)epsilon","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"or, alternatively and without truncation error, by using a dual number with a single partial dimension, d = x + v epsilon we get that","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"f(d) = f(x) + Jv epsilon","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"as a fast way to calculate Jv. Thus, except when a sufficiently good function for J is given by the user, the Jacobian is never formed. For more details, consult the MIT 18.337 lecture notes on forward mode AD.","category":"page"},{"location":"sensitivity_math/#Adjoint-Sensitivity-Analysis","page":"Sensitivity Math Details","title":"Adjoint Sensitivity Analysis","text":"","category":"section"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"This adjoint requires the definition of some scalar functional g(up) where u(tp) is the (numerical) solution to the differential equation ddt u(tp)=f(tup) with tin 0T and u(t_0p)=u_0. Adjoint sensitivity analysis finds the gradient of","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"G(up)=G(u(cdotp))=int_t_0^Tg(u(tp)p)dt","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"some integral of the solution. It does so by solving the adjoint problem","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"fracdlambda^stardt=g_u(u(tp)p)-lambda^star(t)f_u(tu(tp)p)thinspacethinspacethinspacelambda^star(T)=0","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"where f_u is the Jacobian of the system with respect to the state u while f_p is the Jacobian with respect to the parameters. The adjoint problem's solution gives the sensitivities through the integral:","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"fracdGdp=int_t_0^Tlambda^star(t)f_p(t)+g_p(t)dt+lambda^star(t_0)u_p(t_0)","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"Notice that since the adjoints require the Jacobian of the system at the state, it requires the ability to evaluate the state at any point in time. Thus it requires the continuous forward solution in order to solve the adjoint solution, and the adjoint solution is required to be continuous in order to calculate the resulting integral.","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"There is one extra detail to consider. In many cases, we would like to calculate the adjoint sensitivity of some discontinuous functional of the solution. One canonical function is the L2 loss against some data points, that is:","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"L(up)=sum_i=1^nVerttildeu(t_i)-u(t_ip)Vert^2","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"In this case, we can reinterpret our summation as the distribution integral:","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"G(up)=int_0^Tsum_i=1^nVerttildeu(t_i)-u(t_ip)Vert^2delta(t_i-t)dt","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"where δ is the Dirac distribution. In this case, the integral is continuous except at finitely many points. Thus it can be calculated between each t_i. At a given t_i, given that the t_i are unique, we have that","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"g_u(t_i)=2left(tildeu(t_i)-u(t_ip)right)","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"Thus the adjoint solution lambda^star(t) is given by integrating between the integrals and applying the jump function g_u at every data point t_i.","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"We note that","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"lambda^star(t)f_u(t)","category":"page"},{"location":"sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"is a vector-transpose Jacobian product, also known as a vjp, which can be efficiently computed using the pullback of backpropagation on the user function f with a forward pass at u with a pullback vector lambda^star. For more information, consult the MIT 18.337 lecture notes on reverse mode AD.","category":"page"},{"location":"examples/neural_ode/minibatch/#Training-a-Neural-Ordinary-Differential-Equation-with-Mini-Batching","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"","category":"section"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"using DifferentialEquations, Flux, Random, Plots\nusing IterTools: ncycle\n\nrng = Random.default_rng()\n\nfunction newtons_cooling(du, u, p, t)\n    temp = u[1]\n    k, temp_m = p\n    du[1] = dT = -k * (temp - temp_m)\nend\n\nfunction true_sol(du, u, p, t)\n    true_p = [log(2) / 8.0, 100.0]\n    newtons_cooling(du, u, true_p, t)\nend\n\nann = Chain(Dense(1, 8, tanh), Dense(8, 1, tanh))\nθ, re = Flux.destructure(ann)\n\nfunction dudt_(u, p, t)\n    re(p)(u)[1] .* u\nend\n\nfunction predict_adjoint(time_batch)\n    _prob = remake(prob, u0 = u0, p = θ)\n    Array(solve(_prob, Tsit5(), saveat = time_batch))\nend\n\nfunction loss_adjoint(batch, time_batch)\n    pred = predict_adjoint(time_batch)\n    sum(abs2, batch - pred)#, pred\nend\n\nu0 = Float32[200.0]\ndatasize = 30\ntspan = (0.0f0, 3.0f0)\n\nt = range(tspan[1], tspan[2], length = datasize)\ntrue_prob = ODEProblem(true_sol, u0, tspan)\node_data = Array(solve(true_prob, Tsit5(), saveat = t))\n\nprob = ODEProblem{false}(dudt_, u0, tspan, θ)\n\nk = 10\ntrain_loader = Flux.Data.DataLoader((ode_data, t), batchsize = k)\n\nfor (x, y) in train_loader\n    @show x\n    @show y\nend\n\nnumEpochs = 300\nlosses = []\nfunction cb()\n    begin\n        l = loss_adjoint(ode_data, t)\n        push!(losses, l)\n        @show l\n        pred = predict_adjoint(t)\n        pl = scatter(t, ode_data[1, :], label = \"data\", color = :black, ylim = (150, 200))\n        scatter!(pl, t, pred[1, :], label = \"prediction\", color = :darkgreen)\n        display(plot(pl))\n        false\n    end\nend\n\nopt = ADAM(0.05)\nFlux.train!(loss_adjoint, Flux.params(θ), ncycle(train_loader, numEpochs), opt,\n    cb = Flux.throttle(cb, 10))\n\n#Now lets see how well it generalizes to new initial conditions \n\nstarting_temp = collect(10:30:250)\ntrue_prob_func(u0) = ODEProblem(true_sol, [u0], tspan)\ncolor_cycle = palette(:tab10)\npl = plot()\nfor (j, temp) in enumerate(starting_temp)\n    ode_test_sol = solve(ODEProblem(true_sol, [temp], (0.0f0, 10.0f0)), Tsit5(),\n        saveat = 0.0:0.5:10.0)\n    ode_nn_sol = solve(ODEProblem{false}(dudt_, [temp], (0.0f0, 10.0f0), θ))\n    scatter!(pl, ode_test_sol, var = (0, 1), label = \"\", color = color_cycle[j])\n    plot!(pl, ode_nn_sol, var = (0, 1), label = \"\", color = color_cycle[j], lw = 2.0)\nend\ndisplay(pl)\ntitle!(\"Neural ODE for Newton's Law of Cooling: Test Data\")\nxlabel!(\"Time\")\nylabel!(\"Temp\")","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"When training a neural network, we need to find the gradient with respect to our data set. There are three main ways to partition our data when using a training algorithm like gradient descent: stochastic, batching and mini-batching. Stochastic gradient descent trains on a single random data point each epoch. This allows for the neural network to better converge to the global minimum even on noisy data, but is computationally inefficient. Batch gradient descent trains on the whole data set each epoch and while computationally efficient is prone to converging to local minima. Mini-batching combines both of these advantages and by training on a small random \"mini-batch\" of the data each epoch can converge to the global minimum while remaining more computationally efficient than stochastic descent. Typically, we do this by randomly selecting subsets of the data each epoch and use this subset to train on. We can also pre-batch the data by creating an iterator holding these randomly selected batches before beginning to train. The proper size for the batch can be determined experimentally. Let us see how to do this with Julia.","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"For this example, we will use a very simple ordinary differential equation, newtons law of cooling. We can represent this in Julia like so.","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"using DifferentialEquations, Flux, Random, Plots\nusing IterTools: ncycle\n\nrng = Random.default_rng()\nfunction newtons_cooling(du, u, p, t)\n    temp = u[1]\n    k, temp_m = p\n    du[1] = dT = -k * (temp - temp_m)\nend\n\nfunction true_sol(du, u, p, t)\n    true_p = [log(2) / 8.0, 100.0]\n    newtons_cooling(du, u, true_p, t)\nend","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"Now we define a neural-network using a linear approximation with 1 hidden layer of 8 neurons.","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"ann = Chain(Dense(1, 8, tanh), Dense(8, 1, tanh))\nθ, re = Flux.destructure(ann)\n\nfunction dudt_(u, p, t)\n    re(p)(u)[1] .* u\nend","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"From here we build a loss function around it.","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"function predict_adjoint(time_batch)\n    _prob = remake(prob, u0 = u0, p = θ)\n    Array(solve(_prob, Tsit5(), saveat = time_batch))\nend\n\nfunction loss_adjoint(batch, time_batch)\n    pred = predict_adjoint(time_batch)\n    sum(abs2, batch - pred)#, pred\nend","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"To add support for batches of size k we use Flux.Data.DataLoader. To use this we pass in the ode_data and t as the 'x' and 'y' data to batch respectively. The parameter batchsize controls the size of our batches. We check our implementation by iterating over the batched data.","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"u0 = Float32[200.0]\ndatasize = 30\ntspan = (0.0f0, 3.0f0)\n\nt = range(tspan[1], tspan[2], length = datasize)\ntrue_prob = ODEProblem(true_sol, u0, tspan)\node_data = Array(solve(true_prob, Tsit5(), saveat = t))\n\nprob = ODEProblem{false}(dudt_, u0, tspan, θ)\n\nk = 10\ntrain_loader = Flux.Data.DataLoader((ode_data, t), batchsize = k)\n\nfor (x, y) in train_loader\n    @show x\n    @show y\nend","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"Now we train the neural network with a user-defined call back function to display loss and the graphs with a maximum of 300 epochs.","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"numEpochs = 300\nlosses = []\nfunction cb()\n    begin\n        l = loss_adjoint(ode_data, t)\n        push!(losses, l)\n        @show l\n        pred = predict_adjoint(t)\n        pl = scatter(t, ode_data[1, :], label = \"data\", color = :black, ylim = (150, 200))\n        scatter!(pl, t, pred[1, :], label = \"prediction\", color = :darkgreen)\n        display(plot(pl))\n        false\n    end\nend\n\nopt = ADAM(0.05)\nFlux.train!(loss_adjoint, Flux.params(θ), ncycle(train_loader, numEpochs), opt,\n    cb = Flux.throttle(cb, 10))","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"Finally, we can see how well our trained network will generalize to new initial conditions.","category":"page"},{"location":"examples/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"starting_temp = collect(10:30:250)\ntrue_prob_func(u0) = ODEProblem(true_sol, [u0], tspan)\ncolor_cycle = palette(:tab10)\npl = plot()\nfor (j, temp) in enumerate(starting_temp)\n    ode_test_sol = solve(ODEProblem(true_sol, [temp], (0.0f0, 10.0f0)), Tsit5(),\n        saveat = 0.0:0.5:10.0)\n    ode_nn_sol = solve(ODEProblem{false}(dudt_, [temp], (0.0f0, 10.0f0), θ))\n    scatter!(pl, ode_test_sol, var = (0, 1), label = \"\", color = color_cycle[j])\n    plot!(pl, ode_nn_sol, var = (0, 1), label = \"\", color = color_cycle[j], lw = 2.0)\nend\ndisplay(pl)\ntitle!(\"Neural ODE for Newton's Law of Cooling: Test Data\")\nxlabel!(\"Time\")\nylabel!(\"Temp\")","category":"page"},{"location":"manual/differential_equation_sensitivities/#sensitivity_diffeq","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"SciMLSensitivity.jl's high-level interface allows for specifying a sensitivity algorithm (sensealg) to control the method by which solve is differentiated in an automatic differentiation (AD) context by a compatible AD library. The underlying algorithms then use the direct interface methods, like ODEForwardSensitivityProblem and adjoint_sensitivities, to compute the derivatives without requiring the user to do any of the setup.","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Current AD libraries whose calls are captured by the sensitivity system are:","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Zygote.jl\nDiffractor.jl","category":"page"},{"location":"manual/differential_equation_sensitivities/#Using-and-Controlling-Sensitivity-Algorithms-within-AD","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Using and Controlling Sensitivity Algorithms within AD","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Take for example this simple differential equation solve on Lotka-Volterra:","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"using SciMLSensitivity, OrdinaryDiffEq, Zygote\n\nfunction fiip(du, u, p, t)\n    du[1] = dx = p[1] * u[1] - p[2] * u[1] * u[2]\n    du[2] = dy = -p[3] * u[2] + p[4] * u[1] * u[2]\nend\np = [1.5, 1.0, 3.0, 1.0];\nu0 = [1.0; 1.0];\nprob = ODEProblem(fiip, u0, (0.0, 10.0), p)\nsol = solve(prob, Tsit5())\nloss(u0, p) = sum(solve(prob, Tsit5(), u0 = u0, p = p, saveat = 0.1))\ndu0, dp = Zygote.gradient(loss, u0, p)","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"This will compute the gradient of the loss function \"sum of the values of the solution to the ODE at timepoints dt=0.1\" using an adjoint method, where du0 is the derivative of the loss function with respect to the initial condition and dp is the derivative of the loss function with respect to the parameters.","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Because the gradient is calculated by Zygote.gradient and Zygote.jl is one of the compatible AD libraries, this derivative calculation will be captured by the sensealg system, and one of SciMLSensitivity.jl's adjoint overloads will be used to compute the derivative. By default, if the sensealg keyword argument is not defined, then a smart polyalgorithm is used to automatically determine the most appropriate method for a given equation.","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Likewise, the sensealg argument can be given to directly control the method by which the derivative is computed. For example:","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"function loss(u0, p)\n    sum(solve(prob, Tsit5(), u0 = u0, p = p, saveat = 0.1, sensealg = ForwardSensitivity()))\nend\ndu0, dp = Zygote.gradient(loss, u0, p)","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"would do reverse-mode automatic differentiation of the loss function, but when reversing over the ODE solve, it would do forward sensitivity analysis to compute the required pullbacks, effectively creating an algorithm that mixes forward and reverse differentiation.","category":"page"},{"location":"manual/differential_equation_sensitivities/#Choosing-a-Sensitivity-Algorithm","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Choosing a Sensitivity Algorithm","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"There are two classes of algorithms: the continuous sensitivity analysis methods, and the discrete sensitivity analysis methods (direct automatic differentiation). Generally:","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Continuous sensitivity analysis are more efficient while the discrete sensitivity analysis is more stable (full discussion is in the appendix of that paper)\nContinuous sensitivity analysis methods only support a subset of equations, which currently includes:\nODEProblem (with mass matrices for differential-algebraic equations (DAEs)\nSDEProblem\nSteadyStateProblem / NonlinearProblem\nDiscrete sensitivity analysis methods only support a subset of algorithms, namely, the pure Julia solvers which are written generically.","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"For an analysis of which methods will be most efficient for computing the solution derivatives for a given problem, consult our analysis in this arXiv paper. A general rule of thumb is:","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"ForwardDiffSensitivity is the fastest for differential equations with small numbers of parameters (<100) and can be used on any differential equation solver that is native Julia. If the chosen ODE solver is incompatible with direct automatic differentiation, ForwardSensitivty may be used instead.\nAdjoint sensitivity analysis is the fastest when the number of parameters is sufficiently large. There are three configurations of note. Using QuadratureAdjoint is the fastest but uses the most memory, BacksolveAdjoint uses the least memory but on very stiff problems it may be unstable and requires many checkpoints, while InterpolatingAdjoint is in the middle, allowing checkpointing to control total memory use.\nThe methods which use direct automatic differentiation (ReverseDiffAdjoint, TrackerAdjoint, ForwardDiffSensitivity, and ZygoteAdjoint) support the full range of DifferentialEquations.jl features (SDEs, DDEs, events, etc.), but only work on native Julia solvers.\nFor non-ODEs with large numbers of parameters, TrackerAdjoint in out-of-place form may be the best performer on GPUs, and ReverseDiffAdjoint\nTrackerAdjoint is able to use a TrackedArray form with out-of-place functions du = f(u,p,t) but requires an Array{TrackedReal} form for f(du,u,p,t) mutating du. The latter has much more overhead, and should be avoided if possible. When solving non-ODEs with lots of parameters, using TrackerAdjoint with an out-of-place definition may currently be the best option.","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"note: Note\nCompatibility with direct automatic differentiation algorithms (ForwardDiffSensitivity, ReverseDiffAdjoint, etc.) can be queried using the SciMLBase.isautodifferentiable(::SciMLAlgorithm) trait function.","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"If the chosen algorithm is a continuous sensitivity analysis algorithm, then an autojacvec argument can be given for choosing how the Jacobian-vector product (J*v) or vector-Jacobian product (J'*v) calculation is computed. For the forward sensitivity methods, autojacvec=true is the most efficient, though autojacvec=false is slightly less accurate but very close in efficiency. For adjoint methods, it's more complicated and dependent on the way that the user's f function is implemented:","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"EnzymeVJP() is the most efficient if it's applicable on your equation.\nIf your function has no branching (no if statements) but uses mutation, ReverseDiffVJP(true) will be the most efficient after Enzyme. Otherwise, ReverseDiffVJP(), but you may wish to proceed with eliminating mutation as without compilation enabled this can be slow.\nIf you are on the CPU or GPU and your function is very vectorized and has no mutation, choose ZygoteVJP().\nElse fallback to TrackerVJP() if Zygote does not support the function.","category":"page"},{"location":"manual/differential_equation_sensitivities/#Special-Notes-on-Non-ODE-Differential-Equation-Problems","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Special Notes on Non-ODE Differential Equation Problems","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"While all of the choices are compatible with ordinary differential equations, specific notices apply to other forms:","category":"page"},{"location":"manual/differential_equation_sensitivities/#Differential-Algebraic-Equations","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Differential-Algebraic Equations","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"We note that while all 3 are compatible with index-1 DAEs via the derivation in the universal differential equations paper (note the reinitialization), we do not recommend BacksolveAdjoint on DAEs because the stiffness inherent in these problems tends to cause major difficulties with the accuracy of the backwards solution due to reinitialization of the algebraic variables.","category":"page"},{"location":"manual/differential_equation_sensitivities/#Stochastic-Differential-Equations","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Stochastic Differential Equations","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"We note that all of the adjoints except QuadratureAdjoint are applicable to stochastic differential equations.","category":"page"},{"location":"manual/differential_equation_sensitivities/#Delay-Differential-Equations","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Delay Differential Equations","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"We note that only the discretize-then-optimize methods are applicable to delay differential equations. Constant lag and variable lag delay differential equation parameters can be estimated, but the lag times themselves are unable to be estimated through these automatic differentiation techniques.","category":"page"},{"location":"manual/differential_equation_sensitivities/#Hybrid-Equations-(Equations-with-events/callbacks)-and-Jump-Equations","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Hybrid Equations (Equations with events/callbacks) and Jump Equations","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"ForwardDiffSensitivity can differentiate code with callbacks when convert_tspan=true. ForwardSensitivity is incompatible with hybrid equations. The shadowing methods are incompatible with callbacks. All methods based on discrete adjoint sensitivity analysis via automatic differentiation, like ReverseDiffAdjoint, TrackerAdjoint, or QuadratureAdjoint are fully compatible with events. This applies to ODEs, SDEs, DAEs, and DDEs. The continuous adjoint sensitivities BacksolveAdjoint, InterpolatingAdjoint, and QuadratureAdjoint are compatible with events for ODEs. BacksolveAdjoint and InterpolatingAdjoint can also handle events for SDEs. Use BacksolveAdjoint if the event terminates the time evolution and several states are saved. Currently, the continuous adjoint sensitivities do not support multiple events per time point.","category":"page"},{"location":"manual/differential_equation_sensitivities/#Manual-VJPs","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Manual VJPs","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Note that when defining your differential equation, the vjp can be manually overwritten by providing the AbstractSciMLFunction definition with  a vjp(u,p,t) that returns a tuple f(u,p,t),v->J*v in the form of ChainRules.jl. When this is done, the choice of ZygoteVJP will utilize your VJP function during the internal steps of the adjoint. This is useful for models where automatic differentiation may have trouble producing optimal code. This can be paired with ModelingToolkit.jl for producing hyper-optimized, sparse, and parallel VJP functions utilizing the automated symbolic conversions.","category":"page"},{"location":"manual/differential_equation_sensitivities/#Sensitivity-Algorithms","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"The following algorithm choices exist for sensealg. See the sensitivity mathematics page for more details on the definition of the methods.","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"ForwardSensitivity\nForwardDiffSensitivity\nBacksolveAdjoint\nInterpolatingAdjoint\nQuadratureAdjoint\nReverseDiffAdjoint\nTrackerAdjoint\nZygoteAdjoint\nForwardLSS\nAdjointLSS\nNILSS\nNILSAS","category":"page"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.ForwardSensitivity","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.ForwardSensitivity","text":"ForwardSensitivity{CS, AD, FDT} <: AbstractForwardSensitivityAlgorithm{CS, AD, FDT}\n\nAn implementation of continuous forward sensitivity analysis for propagating derivatives by solving the extended ODE. When used within adjoint differentiation (i.e. via Zygote), this will cause forward differentiation of the solve call within the reverse-mode automatic differentiation environment.\n\nConstructor\n\nForwardSensitivity(;\n                   chunk_size = 0, autodiff = true,\n                   diff_type = Val{:central},\n                   autojacvec = autodiff,\n                   autojacmat = false)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation in the internal sensitivity algorithm computations. Default is true.\nchunk_size: Chunk size for forward mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\nautojacvec: Calculate the Jacobian-vector product via automatic differentiation with special seeding.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\n\nFurther details:\n\nIf autodiff=true and autojacvec=true, then the one chunk J*v forward-mode directional derivative calculation trick is used to compute the product without constructing the Jacobian (via ForwardDiff.jl).\nIf autodiff=false and autojacvec=true, then the numerical direction derivative trick (f(x+epsilon*v)-f(x))/epsilon is used to compute J*v without constructing the Jacobian.\nIf autodiff=true and autojacvec=false, then the Jacobian is constructed via chunked forward-mode automatic differentiation (via ForwardDiff.jl).\nIf autodiff=false and autojacvec=false, then the Jacobian is constructed via finite differences via FiniteDiff.jl.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems without callbacks (events).\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.ForwardDiffSensitivity","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.ForwardDiffSensitivity","text":"ForwardDiffSensitivity{CS, CTS} <: AbstractForwardSensitivityAlgorithm{CS, Nothing, Nothing}\n\nAn implementation of discrete forward sensitivity analysis through ForwardDiff.jl. When used within adjoint differentiation (i.e. via Zygote), this will cause forward differentiation of the solve call within the reverse-mode automatic differentiation environment.\n\nConstructor\n\nForwardDiffSensitivity(; chunk_size = 0, convert_tspan = nothing)\n\nKeyword Arguments\n\nchunk_size: the chunk size used by ForwardDiff for computing the Jacobian, i.e. the number of simultaneous columns computed.\nconvert_tspan: whether to convert time to also be Dual valued. By default this is nothing which will only convert if callbacks are found. Conversion is required in order to accurately differentiate callbacks (hybrid equations).\n\nSciMLProblem Support\n\nThis sensealg supports any SciMLProblems, provided that the solver algorithms is SciMLBase.isautodifferentiable. Note that ForwardDiffSensitivity can accurately differentiate code with callbacks only when convert_tspan=true.\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.BacksolveAdjoint","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.BacksolveAdjoint","text":"BacksolveAdjoint{CS, AD, FDT, VJP} <: AbstractAdjointSensitivityAlgorithm{CS, AD, FDT}\n\nAn implementation of adjoint sensitivity analysis using a backwards solution of the ODE. By default, this algorithm will use the values from the forward pass to perturb the backwards solution to the correct spot, allowing reduced memory (O(1) memory). Checkpointing stabilization is included for additional numerical stability over the naive implementation.\n\nConstructor\n\nBacksolveAdjoint(; chunk_size = 0, autodiff = true,\n                 diff_type = Val{:central},\n                 autojacvec = nothing,\n                 checkpointing = true, noisemixing = false)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nautojacvec: Calculate the vector-Jacobian product (J'*v) via automatic differentiation with special seeding. The total set of choices are:\nnothing: uses an automatic algorithm to automatically choose the vjp. This is the default and recommended for most users.\nfalse: the Jacobian is constructed via FiniteDiff.jl\ntrue: the Jacobian is constructed via ForwardDiff.jl\nTrackerVJP: Uses Tracker.jl for the vjp.\nZygoteVJP: Uses Zygote.jl for the vjp.\nEnzymeVJP: Uses Enzyme.jl for the vjp.\nReverseDiffVJP(compile=false): Uses ReverseDiff.jl for the vjp. compile is a boolean for whether to precompile the tape, which should only be done if there are no branches (if or while statements) in the f function.\ncheckpointing: whether checkpointing is enabled for the reverse pass. Defaults to true.\nnoisemixing: Handle noise processes that are not of the form du[i] = f(u[i]). For example, to compute the sensitivities of an SDE with diagonal diffusion\nfunction g_mixing!(du, u, p, t)\n    du[1] = p[3] * u[1] + p[4] * u[2]\n    du[2] = p[3] * u[1] + p[4] * u[2]\n    nothing\nend\ncorrectly, noisemixing=true must be enabled. The default is false.\n\nFor more details on the vjp choices, please consult the sensitivity algorithms documentation page or the docstrings of the vjp types.\n\nApplicability of Backsolve and Caution\n\nWhen BacksolveAdjoint is applicable, it is a fast method, and requires the least memory. However, one must be cautious because not all ODEs are stable under backwards integration by the majority of ODE solvers. An example of such an equation is the Lorenz equation. Notice that if one solves the Lorenz equation forward and then in reverse with any adaptive time step and non-reversible integrator, then the backwards solution diverges from the forward solution. As a quick demonstration:\n\nusing Sundials\nfunction lorenz(du, u, p, t)\n    du[1] = 10.0 * (u[2] - u[1])\n    du[2] = u[1] * (28.0 - u[3]) - u[2]\n    du[3] = u[1] * u[2] - (8 / 3) * u[3]\nend\nu0 = [1.0; 0.0; 0.0]\ntspan = (0.0, 100.0)\nprob = ODEProblem(lorenz, u0, tspan)\nsol = solve(prob, Tsit5(), reltol = 1e-12, abstol = 1e-12)\nprob2 = ODEProblem(lorenz, sol[end], (100.0, 0.0))\nsol = solve(prob, Tsit5(), reltol = 1e-12, abstol = 1e-12)\n@show sol[end] - u0 #[-3.22091, -1.49394, 21.3435]\n\nThus, one should check the stability of the backsolve on their type of problem before enabling this method. Additionally, using checkpointing with backsolve can be a low memory way to stabilize it.\n\nFor more details on this topic, see Stiff Neural Ordinary Differential Equations.\n\nCheckpointing\n\nTo improve the numerical stability of the reverse pass, BacksolveAdjoint includes a checkpointing feature. If sol.u is a time series, then whenever a time sol.t is hit while reversing, a callback will replace the reversing ODE portion with sol.u[i]. This nudges the solution back onto the appropriate trajectory and reduces the numerical caused by drift.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems, SDEProblems, and RODEProblems. This sensealg supports callback functions (events).\n\nReferences\n\nODE: Rackauckas, C. and Ma, Y. and Martensen, J. and Warner, C. and Zubov, K. and Supekar, R. and Skinner, D. and Ramadhana, A. and Edelman, A., Universal Differential Equations for Scientific Machine Learning,\tarXiv:2001.04385\n\nHindmarsh, A. C. and Brown, P. N. and Grant, K. E. and Lee, S. L. and Serban, R. and Shumaker, D. E. and Woodward, C. S., SUNDIALS: Suite of nonlinear and differential/algebraic equation solvers, ACM Transactions on Mathematical Software (TOMS), 31, pp:363–396 (2005)\n\nChen, R.T.Q. and Rubanova, Y. and Bettencourt, J. and Duvenaud, D. K., Neural ordinary differential equations. In Advances in neural information processing systems, pp. 6571–6583 (2018)\n\nPontryagin, L. S. and Mishchenko, E.F. and Boltyanskii, V.G. and Gamkrelidze, R.V. The mathematical theory of optimal processes. Routledge, (1962)\n\nRackauckas, C. and Ma, Y. and Dixit, V. and Guo, X. and Innes, M. and Revels, J. and Nyberg, J. and Ivaturi, V., A comparison of automatic differentiation and continuous sensitivity analysis for derivatives of differential equation solutions, arXiv:1812.01892\n\nDAE: Cao, Y. and Li, S. and Petzold, L. and Serban, R., Adjoint sensitivity analysis for differential-algebraic equations: The adjoint DAE system and its numerical solution, SIAM journal on scientific computing 24 pp: 1076-1089 (2003)\n\nSDE: Gobet, E. and Munos, R., Sensitivity Analysis Using Ito-Malliavin Calculus and Martingales, and Application to Stochastic Optimal Control, SIAM Journal on control and optimization, 43, pp. 1676-1713 (2005)\n\nLi, X. and Wong, T.-K. L.and Chen, R. T. Q. and Duvenaud, D., Scalable Gradients for Stochastic Differential Equations, PMLR 108, pp. 3870-3882 (2020), http://proceedings.mlr.press/v108/li20i.html\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.InterpolatingAdjoint","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.InterpolatingAdjoint","text":"InterpolatingAdjoint{CS, AD, FDT, VJP} <: AbstractAdjointSensitivityAlgorithm{CS, AD, FDT}\n\nAn implementation of adjoint sensitivity analysis which uses the interpolation of the forward solution for the reverse solve vector-Jacobian products. By default it requires, a dense solution of the forward pass and will internally ignore saving arguments during the gradient calculation. When checkpointing is enabled, it will only require the memory to interpolate between checkpoints.\n\nConstructor\n\nInterpolatingAdjoint(; chunk_size = 0, autodiff = true,\n                     diff_type = Val{:central},\n                     autojacvec = nothing,\n                     checkpointing = false, noisemixing = false)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nautojacvec: Calculate the vector-Jacobian product (J'*v) via automatic differentiation with special seeding. The total set of choices are:\nnothing: uses an automatic algorithm to automatically choose the vjp. This is the default and recommended for most users.                                                                                                                                        \nfalse: the Jacobian is constructed via FiniteDiff.jl\ntrue: the Jacobian is constructed via ForwardDiff.jl\nTrackerVJP: Uses Tracker.jl for the vjp.\nZygoteVJP: Uses Zygote.jl for the vjp.\nEnzymeVJP: Uses Enzyme.jl for the vjp.\nReverseDiffVJP(compile=false): Uses ReverseDiff.jl for the vjp. compile is a boolean for whether to precompile the tape, which should only be done if there are no branches (if or while statements) in the f function.\ncheckpointing: whether checkpointing is enabled for the reverse pass. Defaults to false.\nnoisemixing: Handle noise processes that are not of the form du[i] = f(u[i]). For example, to compute the sensitivities of an SDE with diagonal diffusion\nfunction g_mixing!(du, u, p, t)\n    du[1] = p[3] * u[1] + p[4] * u[2]\n    du[2] = p[3] * u[1] + p[4] * u[2]\n    nothing\nend\ncorrectly, noisemixing=true must be enabled. The default is false.\n\nFor more details on the vjp choices, please consult the sensitivity algorithms documentation page or the docstrings of the vjp types.\n\nCheckpointing\n\nTo reduce the memory usage of the reverse pass, InterpolatingAdjoint includes a checkpointing feature. If sol is dense, checkpointing is ignored and the continuous solution is used for calculating u(t) at arbitrary time points. If checkpointing=true and sol is not dense, then dense intervals between sol.t[i] and sol.t[i+1] are reconstructed on-demand for calculating u(t) at arbitrary time points. This reduces the total memory requirement to only the cost of holding the dense solution over the largest time interval (in terms of number of required steps). The total compute cost is no more than double the original forward compute cost.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems, SDEProblems, and RODEProblems. This sensealg supports callbacks (events).\n\nReferences\n\nRackauckas, C. and Ma, Y. and Martensen, J. and Warner, C. and Zubov, K. and Supekar, R. and Skinner, D. and Ramadhana, A. and Edelman, A., Universal Differential Equations for Scientific Machine Learning,\tarXiv:2001.04385\n\nHindmarsh, A. C. and Brown, P. N. and Grant, K. E. and Lee, S. L. and Serban, R. and Shumaker, D. E. and Woodward, C. S., SUNDIALS: Suite of nonlinear and differential/algebraic equation solvers, ACM Transactions on Mathematical Software (TOMS), 31, pp:363–396 (2005)\n\nRackauckas, C. and Ma, Y. and Dixit, V. and Guo, X. and Innes, M. and Revels, J. and Nyberg, J. and Ivaturi, V., A comparison of automatic differentiation and continuous sensitivity analysis for derivatives of differential equation solutions, arXiv:1812.01892\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.QuadratureAdjoint","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.QuadratureAdjoint","text":"QuadratureAdjoint{CS, AD, FDT, VJP} <: AbstractAdjointSensitivityAlgorithm{CS, AD, FDT}\n\nAn implementation of adjoint sensitivity analysis which develops a full continuous solution of the reverse solve in order to perform a post-ODE quadrature. This method requires the dense solution and will ignore saving arguments during the gradient calculation. The tolerances in the constructor control the inner quadrature.\n\nThis method is O(n^3 + p) for stiff / implicit equations (as opposed to the O((n+p)^3) scaling of BacksolveAdjoint and InterpolatingAdjoint), and thus is much more compute efficient. However, it requires holding a dense reverse pass and is thus memory intensive.\n\nConstructor\n\nQuadratureAdjoint(; chunk_size = 0, autodiff = true,\n                  diff_type = Val{:central},\n                  autojacvec = nothing, abstol = 1e-6,\n                  reltol = 1e-3)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nautojacvec: Calculate the vector-Jacobian product (J'*v) via automatic differentiation with special seeding. The total set of choices are:\nnothing: uses an automatic algorithm to automatically choose the vjp. This is the default and recommended for most users.\nfalse: the Jacobian is constructed via FiniteDiff.jl\ntrue: the Jacobian is constructed via ForwardDiff.jl\nTrackerVJP: Uses Tracker.jl for the vjp.\nZygoteVJP: Uses Zygote.jl for the vjp.\nEnzymeVJP: Uses Enzyme.jl for the vjp.\nReverseDiffVJP(compile=false): Uses ReverseDiff.jl for the vjp. compile is a boolean for whether to precompile the tape, which should only be done if there are no branches (if or while statements) in the f function.\nabstol: absolute tolerance for the quadrature calculation\nreltol: relative tolerance for the quadrature calculation\n\nFor more details on the vjp choices, please consult the sensitivity algorithms documentation page or the docstrings of the vjp types.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems. This sensealg supports events (callbacks).\n\nReferences\n\nRackauckas, C. and Ma, Y. and Martensen, J. and Warner, C. and Zubov, K. and Supekar, R. and Skinner, D. and Ramadhana, A. and Edelman, A., Universal Differential Equations for Scientific Machine Learning,\tarXiv:2001.04385\n\nHindmarsh, A. C. and Brown, P. N. and Grant, K. E. and Lee, S. L. and Serban, R. and Shumaker, D. E. and Woodward, C. S., SUNDIALS: Suite of nonlinear and differential/algebraic equation solvers, ACM Transactions on Mathematical Software (TOMS), 31, pp:363–396 (2005)\n\nRackauckas, C. and Ma, Y. and Dixit, V. and Guo, X. and Innes, M. and Revels, J. and Nyberg, J. and Ivaturi, V., A comparison of automatic differentiation and continuous sensitivity analysis for derivatives of differential equation solutions, arXiv:1812.01892\n\nKim, S., Ji, W., Deng, S., Ma, Y., & Rackauckas, C. (2021). Stiff neural ordinary differential equations. Chaos: An Interdisciplinary Journal of Nonlinear Science, 31(9), 093122.\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.ReverseDiffAdjoint","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.ReverseDiffAdjoint","text":"ReverseDiffAdjoint <: AbstractAdjointSensitivityAlgorithm{nothing, true, nothing}\n\nAn implementation of discrete adjoint sensitivity analysis using the ReverseDiff.jl tracing-based AD. Supports in-place functions through an Array of Structs formulation, and supports out of place through struct of arrays.\n\nConstructor\n\nReverseDiffAdjoint()\n\nSciMLProblem Support\n\nThis sensealg supports any DEProblem if the algorithm is SciMLBase.isautodifferentiable. Requires that the state variables are CPU-based Array types.\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.TrackerAdjoint","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.TrackerAdjoint","text":"TrackerAdjoint <: AbstractAdjointSensitivityAlgorithm{nothing, true, nothing}\n\nAn implementation of discrete adjoint sensitivity analysis using the Tracker.jl tracing-based AD. Supports in-place functions through an Array of Structs formulation, and supports out of place through struct of arrays.\n\nConstructor\n\nTrackerAdjoint()\n\nSciMLProblem Support\n\nThis sensealg supports any DEProblem if the algorithm is SciMLBase.isautodifferentiable Compatible with a limited subset of AbstractArray types for u0, including CuArrays.\n\nwarn: Warn\nTrackerAdjoint is incompatible with Stiff ODE solvers using forward-mode automatic differentiation for the Jacobians. Thus, for example, TRBDF2() will error. Instead, use autodiff=false, i.e. TRBDF2(autodiff=false). This will only remove the forward-mode automatic differentiation of the Jacobian construction, not the reverse-mode AD usage, and thus performance will still be nearly the same, though Jacobian accuracy may suffer which could cause more steps to be required.\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.ZygoteAdjoint","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.ZygoteAdjoint","text":"ZygoteAdjoint <: AbstractAdjointSensitivityAlgorithm{nothing,true,nothing}\n\nAn implementation of discrete adjoint sensitivity analysis using the Zygote.jl source-to-source AD directly on the differential equation solver.\n\nConstructor\n\nZygoteAdjoint()\n\nSciMLProblem Support\n\nCurrently fails on almost every solver.\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.ForwardLSS","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.ForwardLSS","text":"ForwardLSS{CS, AD, FDT, RType, gType} <: AbstractShadowingSensitivityAlgorithm{CS, AD, FDT}\n\nAn implementation of the discrete, forward-mode least squares shadowing (LSS) method. LSS replaces the ill-conditioned initial value problem (ODEProblem) for chaotic systems by a well-conditioned least-squares problem. This allows for computing sensitivities of long-time averaged quantities with respect to the parameters of the ODEProblem. The computational cost of LSS scales as (number of states x number of time steps). Converges to the correct sensitivity at a rate of T^(-1/2), where T is the time of the trajectory. See NILSS() and NILSAS() for a more efficient non-intrusive formulation.\n\nConstructor\n\nForwardLSS(;\n           chunk_size = 0, autodiff = true,\n           diff_type = Val{:central},\n           LSSregularizer = TimeDilation(10.0, 0.0, 0.0),\n           g = nothing)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nLSSregularizer: Using LSSregularizer, one can choose between three different regularization routines. The default choice is TimeDilation(10.0,0.0,0.0).\nCosWindowing(): cos windowing of the time grid, i.e. the time grid (saved time steps) is transformed using a cosine.\nCos2Windowing(): cos^2 windowing of the time grid.\nTimeDilation(alpha::Number,t0skip::Number,t1skip::Number): Corresponds to a time dilation. alpha controls the weight. t0skip and t1skip indicate the times truncated at the beginning and end of the trajectory, respectively.\ng: instantaneous objective function of the long-time averaged objective.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems. This sensealg does not support events (callbacks). This sensealg assumes that the objective is a long-time averaged quantity and ergodic, i.e. the time evolution of the system behaves qualitatively the same over infinite time independent of the specified initial conditions, such that only the sensitivity with respect to the parameters is of interest.\n\nReferences\n\nWang, Q., Hu, R., and Blonigan, P. Least squares shadowing sensitivity analysis of chaotic limit cycle oscillations. Journal of Computational Physics, 267, 210-224 (2014).\n\nWang, Q., Convergence of the Least Squares Shadowing Method for Computing Derivative of Ergodic Averages, SIAM Journal on Numerical Analysis, 52, 156–170 (2014).\n\nBlonigan, P., Gomez, S., Wang, Q., Least Squares Shadowing for sensitivity analysis of turbulent fluid flows, in: 52nd Aerospace Sciences Meeting, 1–24 (2014).\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.AdjointLSS","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.AdjointLSS","text":"AdjointLSS{CS, AD, FDT, RType, gType} <: AbstractShadowingSensitivityAlgorithm{CS, AD, FDT}\n\nAn implementation of the discrete, adjoint-mode least square shadowing method. LSS replaces the ill-conditioned initial value problem (ODEProblem) for chaotic systems by a well-conditioned least-squares problem. This allows for computing sensitivities of long-time averaged quantities with respect to the parameters of the ODEProblem. The computational cost of LSS scales as (number of states x number of time steps). Converges to the correct sensitivity at a rate of T^(-1/2), where T is the time of the trajectory. See NILSS() and NILSAS() for a more efficient non-intrusive formulation.\n\nConstructor\n\nAdjointLSS(;\n           chunk_size = 0, autodiff = true,\n           diff_type = Val{:central},\n           LSSRegularizer = TimeDilation(10.0, 0.0, 0.0),\n           g = nothing)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nLSSregularizer: Using LSSregularizer, one can choose between different regularization routines. The default choice is TimeDilation(10.0,0.0,0.0).\nTimeDilation(alpha::Number,t0skip::Number,t1skip::Number): Corresponds to a time dilation. alpha controls the weight. t0skip and t1skip indicate the times truncated at the beginning and end of the trajectory, respectively. The default value for t0skip and t1skip is zero(alpha).\ng: instantaneous objective function of the long-time averaged objective.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems. This sensealg does not support events (callbacks). This sensealg assumes that the objective is a long-time averaged quantity and ergodic, i.e. the time evolution of the system behaves qualitatively the same over infinite time independent of the specified initial conditions, such that only the sensitivity with respect to the parameters is of interest.\n\nReferences\n\nWang, Q., Hu, R., and Blonigan, P. Least squares shadowing sensitivity analysis of chaotic limit cycle oscillations. Journal of Computational Physics, 267, 210-224 (2014).\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.NILSS","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.NILSS","text":"struct NILSS{CS,AD,FDT,RNG,nType,gType} <: AbstractShadowingSensitivityAlgorithm{CS,AD,FDT}\n\nAn implementation of the forward-mode, continuous non-intrusive least squares shadowing method. NILSS allows for computing sensitivities of long-time averaged quantities with respect to the parameters of an ODEProblem by constraining the computation to the unstable subspace. NILSS employs the continuous-time ForwardSensitivity method as tangent solver. To avoid an exponential blow-up of the (homogeneous and inhomogeneous) tangent solutions, the trajectory should be divided into sufficiently small segments, where the tangent solutions are rescaled on the interfaces. The computational and memory cost of NILSS scale with the number of unstable (positive) Lyapunov exponents (instead of the number of states, as in the LSS method). NILSS avoids the explicit construction of the Jacobian at each time step, and thus should generally be preferred (for large system sizes) over ForwardLSS.\n\nConstructor\n\nNILSS(nseg, nstep; nus = nothing,\n      rng = Xorshifts.Xoroshiro128Plus(rand(UInt64)),\n      chunk_size = 0, autodiff = true,\n      diff_type = Val{:central},\n      autojacvec = autodiff,\n      g = nothing)\n\nArguments\n\nnseg: Number of segments on full time interval on the attractor.\nnstep: number of steps on each segment.\n\nKeyword Arguments\n\nnus: Dimension of the unstable subspace. Default is nothing. nus must be smaller or equal to the state dimension (length(u0)). With the default choice, nus = length(u0) - 1 will be set at compile time.\nrng: (Pseudo) random number generator. Used for initializing the homogeneous tangent states (w). Default is Xorshifts.Xoroshiro128Plus(rand(UInt64)).\nautodiff: Use automatic differentiation in the internal sensitivity algorithm computations. Default is true.\nchunk_size: Chunk size for forward mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\nautojacvec: Calculate the Jacobian-vector product via automatic differentiation with special seeding.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\ng: instantaneous objective function of the long-time averaged objective.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems. This sensealg does not support events (callbacks). This sensealg assumes that the objective is a long-time averaged quantity and ergodic, i.e. the time evolution of the system behaves qualitatively the same over infinite time independent of the specified initial conditions, such that only the sensitivity with respect to the parameters is of interest.\n\nReferences\n\nNi, A., Blonigan, P. J., Chater, M., Wang, Q., Zhang, Z., Sensitivity analy- sis on chaotic dynamical system by Non-Intrusive Least Square Shadowing (NI-LSS), in: 46th AIAA Fluid Dynamics Conference, AIAA AVIATION Forum (AIAA 2016-4399), American Institute of Aeronautics and Astronautics, 1–16 (2016).\n\nNi, A., and Wang, Q. Sensitivity analysis on chaotic dynamical systems by Non-Intrusive Least Squares Shadowing (NILSS). Journal of Computational Physics 347, 56-77 (2017).\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.NILSAS","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.NILSAS","text":"NILSAS{CS, AD, FDT, RNG, SENSE, gType} <: AbstractShadowingSensitivityAlgorithm{CS, AD, FDT}\n\nAn implementation of the adjoint-mode, continuous non-intrusive adjoint least squares shadowing method. NILSAS allows for computing sensitivities of long-time averaged quantities with respect to the parameters of an ODEProblem by constraining the computation to the unstable subspace. NILSAS employs SciMLSensitivity.jl's continuous adjoint sensitivity methods on each segment to compute (homogeneous and inhomogeneous) adjoint solutions. To avoid an exponential blow-up of the adjoint solutions, the trajectory should be divided into sufficiently small segments, where the adjoint solutions are rescaled on the interfaces. The computational and memory cost of NILSAS scale with the number of unstable, adjoint Lyapunov exponents (instead of the number of states as in the LSS method). NILSAS avoids the explicit construction of the Jacobian at each time step, and thus should generally be preferred (for large system sizes) over AdjointLSS. NILSAS is favorable over NILSS for many parameters because NILSAS computes the gradient with respect to multiple parameters with negligible additional cost.\n\nConstructor\n\nNILSAS(nseg, nstep, M = nothing; rng = Xorshifts.Xoroshiro128Plus(rand(UInt64)),\n       adjoint_sensealg = BacksolveAdjoint(autojacvec = ReverseDiffVJP()),\n       chunk_size = 0, autodiff = true,\n       diff_type = Val{:central},\n       g = nothing)\n\nArguments\n\nnseg: Number of segments on full time interval on the attractor.\nnstep: number of steps on each segment.\nM: number of homogeneous adjoint solutions. This number must be bigger or equal than the number of (positive, adjoint) Lyapunov exponents. Default is nothing.\n\nKeyword Arguments\n\nrng: (Pseudo) random number generator. Used for initializing the terminate conditions of the homogeneous adjoint states (w). Default is Xorshifts.Xoroshiro128Plus(rand(UInt64)).\nadjoint_sensealg: Continuous adjoint sensitivity method to compute homogeneous and inhomogeneous adjoint solutions on each segment. Default is BacksolveAdjoint(autojacvec=ReverseDiffVJP()).\nautojacvec: Calculate the vector-Jacobian product (J'*v) via automatic differentiation with special seeding. The default is true. The total set of choices are:\nfalse: the Jacobian is constructed via FiniteDiff.jl\ntrue: the Jacobian is constructed via ForwardDiff.jl\nTrackerVJP: Uses Tracker.jl for the vjp.\nZygoteVJP: Uses Zygote.jl for the vjp.\nEnzymeVJP: Uses Enzyme.jl for the vjp.\nReverseDiffVJP(compile=false): Uses ReverseDiff.jl for the vjp. compile is a boolean for whether to precompile the tape, which should only be done if there are no branches (if or while statements) in the f function.\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\ng: instantaneous objective function of the long-time averaged objective.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems. This sensealg does not support events (callbacks). This sensealg assumes that the objective is a long-time averaged quantity and ergodic, i.e. the time evolution of the system behaves qualitatively the same over infinite time independent of the specified initial conditions, such that only the sensitivity with respect to the parameters is of interest.\n\nReferences\n\nNi, A., and Talnikar, C., Adjoint sensitivity analysis on chaotic dynamical systems by Non-Intrusive Least Squares Adjoint Shadowing (NILSAS). Journal of Computational Physics 395, 690-709 (2019).\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#Vector-Jacobian-Product-(VJP)-Choices","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Vector-Jacobian Product (VJP) Choices","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"ZygoteVJP\nEnzymeVJP\nTrackerVJP\nReverseDiffVJP","category":"page"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.ZygoteVJP","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.ZygoteVJP","text":"ZygoteVJP <: VJPChoice\n\nUses Zygote.jl to compute vector-Jacobian products. Tends to be the fastest VJP method if the ODE/DAE/SDE/DDE is written with mostly vectorized  functions (like neural networks and other layers from Flux.jl) and the f function is given out-of-place. If the f function is in-place, then Zygote.Buffer arrays are used internally, which can greatly reduce the performance of the VJP method.\n\nConstructor\n\nZygoteVJP(; allow_nothing = false)\n\nKeyword arguments:\n\nallow_nothing: whether nothings should be implicitly converted to zeros. In Zygote, the derivative of a function with respect to p which does not use p in any possible calculation is given a derivative of nothing instead of zero. By default, this nothing is caught in order to throw an informative error message about a potentially unintentional misdefined function. However, if this was intentional, setting allow_nothing=true will remove the error message.\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.EnzymeVJP","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.EnzymeVJP","text":"EnzymeVJP <: VJPChoice\n\nUses Enzyme.jl to compute vector-Jacobian products. Is the fastest VJP whenever applicable, though Enzyme.jl currently has low coverage over the Julia programming language, for example restricting the user's defined f function to not do things like require garbage collection or calls to BLAS/LAPACK. However, mutation is supported, meaning that in-place f with fully mutating non-allocating code will work with Enzyme (provided no high-level calls to C like BLAS/LAPACK are used) and this will be the most efficient adjoint implementation.\n\nConstructor\n\nEnzymeVJP(; chunksize = 0)\n\nKeyword Arguments\n\nchunksize: the default chunk size for the temporary variables inside the vjp's right hand side definition. This is used for compatibility with ODE solves that default to using ForwardDiff.jl for the Jacobian of the stiff ODE solve, such as OrdinaryDiffEq.jl. This should be set to the maximum chunksize that can occur during an integration to preallocate the DualCaches for PreallocationTools.jl. It defaults to 0, using ForwardDiff.pickchunksize but could be decreased if this value is known to be lower to conserve memory.\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.TrackerVJP","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.TrackerVJP","text":"TrackerVJP <: VJPChoice\n\nUses Tracker.jl to compute the vector-Jacobian products. If f is in-place, then it uses a array of structs formulation to do scalarized reverse mode, while if f is out-of-place then it uses an array-based reverse mode.\n\nNot as efficient as ReverseDiffVJP, but supports GPUs when doing array-based reverse mode.\n\nConstructor\n\nTrackerVJP(; allow_nothing = false)\n\nKeyword arguments:\n\nallow_nothing: whether non-tracked values should be implicitly converted to zeros. In Tracker, the derivative of a function with respect to p which does not use p in any possible calculation is given an untracked return instead of zero. By default, this nothing Trackedness is caught in order to throw an informative error message about a potentially unintentional misdefined function. However, if this was intentional, setting allow_nothing=true will remove the error message.\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#SciMLSensitivity.ReverseDiffVJP","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"SciMLSensitivity.ReverseDiffVJP","text":"ReverseDiffVJP{compile} <: VJPChoice\n\nUses ReverseDiff.jl to compute the vector-Jacobian products. If f is in-place, then it uses a array of structs formulation to do scalarized reverse mode, while if f is out-of-place, then it uses an array-based reverse mode.\n\nUsually, the fastest when scalarized operations exist in the f function (like in scientific machine learning applications like Universal Differential Equations) and the boolean compilation is enabled (i.e. ReverseDiffVJP(true)), if EnzymeVJP fails on a given choice of f.\n\nDoes not support GPUs (CuArrays).\n\nConstructor\n\nReverseDiffVJP(compile = false)\n\nKeyword Arguments\n\ncompile: Whether to cache the compilation of the reverse tape. This heavily increases the performance of the method, but requires that the f function of the ODE/DAE/SDE/DDE has no branching.\n\n\n\n\n\n","category":"type"},{"location":"manual/differential_equation_sensitivities/#More-Details-on-Sensitivity-Algorithm-Choices","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"More Details on Sensitivity Algorithm Choices","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"The following section describes a bit more details to consider when choosing a sensitivity algorithm.","category":"page"},{"location":"manual/differential_equation_sensitivities/#Optimize-then-Discretize","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Optimize-then-Discretize","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"The original neural ODE paper popularized optimize-then-discretize with O(1) adjoints via backsolve. This is the methodology BacksolveAdjoint When training non-stiff neural ODEs, BacksolveAdjoint with ZygoteVJP is generally the fastest method. Additionally, this method does not require storing the values of any intermediate points and is thus the most memory efficient. However, BacksolveAdjoint is prone to instabilities whenever the Lipschitz constant is sufficiently large, like in stiff equations, PDE discretizations, and many other contexts, so it is not used by default. When training a neural ODE for machine learning applications, the user should try BacksolveAdjoint and see if it is sufficiently accurate on their problem. More details on this topic can be found in Stiff Neural Ordinary Differential Equations","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Note that DiffEqFlux's implementation of BacksolveAdjoint includes an extra feature BacksolveAdjoint(checkpointing=true) which mixes checkpointing with BacksolveAdjoint. What this method does is that, at saveat points, values from the forward pass are saved. Since the reverse solve should numerically be the same as the forward pass, issues with divergence of the reverse pass are mitigated by restarting the reverse pass at the saveat value from the forward pass. This reduces the divergence and can lead to better gradients at the cost of higher memory usage due to having to save some values of the forward pass. This can stabilize the adjoint in some applications, but for highly stiff applications the divergence can be too fast for this to work in practice.","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"To avoid the issues of backwards solving the ODE, InterpolatingAdjoint and QuadratureAdjoint utilize information from the forward pass. By default, these methods utilize the continuous solution provided by DifferentialEquations.jl in the calculations of the adjoint pass. QuadratureAdjoint uses this to build a continuous function for the solution of the adjoint equation and then performs an adaptive quadrature via Integrals.jl, while InterpolatingAdjoint appends the integrand to the ODE, so it's computed simultaneously to the Lagrange multiplier. When memory is not an issue, we find that the QuadratureAdjoint approach tends to be the most efficient as it has a significantly smaller adjoint differential equation and the quadrature converges very fast, but this form requires holding the full continuous solution of the adjoint which can be a significant burden for large parameter problems. The InterpolatingAdjoint is thus a compromise between memory efficiency and compute efficiency, and is in the same spirit as CVODES.","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"However, if the memory cost of the InterpolatingAdjoint is too high, checkpointing can be used via InterpolatingAdjoint(checkpointing=true). When this is used, the checkpoints default to sol.t of the forward pass (i.e. the saved timepoints usually set by saveat). Then in the adjoint, intervals of sol.t[i-1] to sol.t[i] are re-solved in order to obtain a short interpolation which can be utilized in the adjoints. This at most results in two full solves of the forward pass, but dramatically reduces the computational cost while being a low-memory format. This is the preferred method for highly stiff equations when memory is an issue, i.e. stiff PDEs or large neural DAEs.","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"For forward-mode, the ForwardSensitivty is the version that performs the optimize-then-discretize approach. In this case, autojacvec corresponds to the method for computing J*v within the forward sensitivity equations, which is either true or false for whether to use Jacobian-free forward-mode AD (via ForwardDiff.jl) or Jacobian-free numerical differentiation.","category":"page"},{"location":"manual/differential_equation_sensitivities/#Discretize-then-Optimize","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Discretize-then-Optimize","text":"","category":"section"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"In this approach, the discretization is done first and then optimization is done on the discretized system. While traditionally this can be done discrete sensitivity analysis, this can equivalently be done by automatic differentiation on the solver itself. ReverseDiffAdjoint performs reverse-mode automatic differentiation on the solver via ReverseDiff.jl, ZygoteAdjoint performs reverse-mode automatic differentiation on the solver via Zygote.jl, and TrackerAdjoint performs reverse-mode automatic differentiation on the solver via Tracker.jl. In addition, ForwardDiffSensitivty performs forward-mode automatic differentiation on the solver via ForwardDiff.jl.","category":"page"},{"location":"manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"We note that many studies have suggested that this approach produces more accurate gradients than the optimize-than-discretize approach","category":"page"},{"location":"tutorials/data_parallel/#Data-Parallel-Multithreaded,-Distributed,-and-Multi-GPU-Batching","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"","category":"section"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"SciMLSensitivity.jl allows for data-parallel batching optimally on one computer, across an entire compute cluster, and batching along GPUs by performing differentiation of SciML EnsembleProblems. This can be done by parallelizing within an ODE solve or between the ODE solves. The automatic differentiation tooling is compatible with the parallelism. The following examples demonstrate training over a few different modes of parallelism. These examples are not exhaustive.","category":"page"},{"location":"tutorials/data_parallel/#Within-ODE-Multithreaded-and-GPU-Batching","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Within-ODE Multithreaded and GPU Batching","text":"","category":"section"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"We end by noting that there is an alternative way of batching which can be more efficient in some cases, like neural ODEs. With neural networks, columns are treated independently (by the properties of matrix multiplication). Thus for example, with Chain we can define an ODE:","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"using Lux, DiffEqFlux, DifferentialEquations, CUDA, Random\nrng = Random.default_rng()\n\ndudt = Lux.Chain(Lux.Dense(2, 50, tanh), Lux.Dense(50, 2))\np, st = Lux.setup(rng, dudt)\nf(u, p, t) = dudt(u, p, st)[1]","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"and we can solve this ODE where the initial condition is a vector:","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"u0 = Float32[2.0; 0.0]\nprob = ODEProblem(f, u0, (0.0f0, 1.0f0), p)\nsolve(prob, Tsit5())","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"or we can solve this ODE where the initial condition is a matrix, where each column is an independent system:","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"u0 = Float32.([0 1 2\n    0 0 0])\nprob = ODEProblem(f, u0, (0.0f0, 1.0f0), p)\nsolve(prob, Tsit5())","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"On the CPU this will multithread across the system (due to BLAS) and on GPUs this will parallelize the operations across the GPU. To GPU this, you'd simply move the parameters and the initial condition to the GPU:","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"xs = Float32.([0 1 2\n    0 0 0])\nprob = ODEProblem(f, Lux.gpu(u0), (0.0f0, 1.0f0), Lux.gpu(p))\nsolve(prob, Tsit5())","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"This method of parallelism is optimal if all the operations are linear algebra operations, such as a neural ODE. Thus this method of parallelism is demonstrated in the MNIST tutorial.","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"However, this method of parallelism has many limitations. First of all, the ODE function is required to be written in a way that is independent across the columns. Not all ODEs are written like this, so one needs to be careful. But additionally, this method is ineffective if the ODE function has many serial operations, like u[1]*u[2] - u[3]. In such a case, this indexing behavior will dominate the runtime and cause the parallelism to sometimes even be detrimental.","category":"page"},{"location":"tutorials/data_parallel/#Out-of-ODE-Parallelism","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Out of ODE Parallelism","text":"","category":"section"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"Instead of parallelizing within an ODE solve, one can parallelize the solves to the ODE itself. While this will be less effective on very large ODEs, like big neural ODE image classifiers, this method be effective even if the ODE is small or the f function is not well-parallelized. This kind of parallelism is done via the DifferentialEquations.jl ensemble interface. The following examples showcase multithreaded, cluster, and (multi)GPU parallelism through this interface.","category":"page"},{"location":"tutorials/data_parallel/#Multithreaded-Batching-At-a-Glance","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Multithreaded Batching At a Glance","text":"","category":"section"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"The following is a full copy-paste example for the multithreading. Distributed and GPU minibatching are described below.","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"using DifferentialEquations, Optimization, OptimizationFlux\npa = [1.0]\nu0 = [3.0]\nθ = [u0; pa]\n\nfunction model1(θ, ensemble)\n    prob = ODEProblem((u, p, t) -> 1.01u .* p, [θ[1]], (0.0, 1.0), [θ[2]])\n\n    function prob_func(prob, i, repeat)\n        remake(prob, u0 = 0.5 .+ i / 100 .* prob.u0)\n    end\n\n    ensemble_prob = EnsembleProblem(prob, prob_func = prob_func)\n    sim = solve(ensemble_prob, Tsit5(), ensemble, saveat = 0.1, trajectories = 100)\nend\n\n# loss function\nloss_serial(θ) = sum(abs2, 1.0 .- Array(model1(θ, EnsembleSerial())))\nloss_threaded(θ) = sum(abs2, 1.0 .- Array(model1(θ, EnsembleThreads())))\n\ncallback = function (θ, l) # callback function to observe training\n    @show l\n    false\nend\n\nopt = ADAM(0.1)\nl1 = loss_serial(θ)\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_serial(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, θ)\n\nres_serial = Optimization.solve(optprob, opt; callback = callback, maxiters = 100)\n\noptf2 = Optimization.OptimizationFunction((x, p) -> loss_threaded(x), adtype)\noptprob2 = Optimization.OptimizationProblem(optf2, θ)\n\nres_threads = Optimization.solve(optprob2, opt; callback = callback, maxiters = 100)","category":"page"},{"location":"tutorials/data_parallel/#Multithreaded-Batching-In-Depth","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Multithreaded Batching In-Depth","text":"","category":"section"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"In order to make use of the ensemble interface, we need to build an EnsembleProblem. The prob_func is the function for determining the different DEProblems to solve. This is the place where we can randomly sample initial conditions or pull initial conditions from an array of batches in order to perform our study. To do this, we first define a prototype DEProblem. Here, we use the following ODEProblem as our base:","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"prob = ODEProblem((u, p, t) -> 1.01u .* p, [θ[1]], (0.0, 1.0), [θ[2]])","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"In the prob_func we define how to build a new problem based on the base problem. In this case, we want to change u0 by a constant, i.e. 0.5 .+ i/100 .* prob.u0 for different trajectories labelled by i. Thus we use the remake function from the problem interface to do so:","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"function prob_func(prob, i, repeat)\n    remake(prob, u0 = 0.5 .+ i / 100 .* prob.u0)\nend","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"We now build the EnsembleProblem with this basis:","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"ensemble_prob = EnsembleProblem(prob, prob_func = prob_func)","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"Now, to solve an ensemble problem, we need to choose an ensembling algorithm and choose the number of trajectories to solve. Here let's solve this in serial with 100 trajectories. Note that i will thus run from 1:100.","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"sim = solve(ensemble_prob, Tsit5(), EnsembleSerial(), saveat = 0.1, trajectories = 100)","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"and thus running in multithreading would be:","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"sim = solve(ensemble_prob, Tsit5(), EnsembleThreads(), saveat = 0.1, trajectories = 100)","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"This whole mechanism is differentiable, so we then put it in a training loop and it soars. Note that you need to make sure that Julia's multithreading is enabled, which you can do via:","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"Threads.nthreads()","category":"page"},{"location":"tutorials/data_parallel/#Distributed-Batching-Across-a-Cluster","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Distributed Batching Across a Cluster","text":"","category":"section"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"Changing to distributed computing is very simple as well. The setup is all the same, except you utilize EnsembleDistributed as the ensembler:","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"sim = solve(ensemble_prob, Tsit5(), EnsembleDistributed(), saveat = 0.1, trajectories = 100)","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"Note that for this to work, you need to ensure that your processes are already started. For more information on setting up processes and utilizing a compute cluster, see the official distributed documentation. The key feature to recognize is that, due to the message passing required for cluster compute, one must ensure that all the required functions are defined on the worker processes. The following is a full example of a distributed batching setup:","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"using Distributed\naddprocs(4)\n\n@everywhere begin\n    using DifferentialEquations, Optimization, OptimizationFlux\n    function f(u, p, t)\n        1.01u .* p\n    end\nend\n\npa = [1.0]\nu0 = [3.0]\nθ = [u0; pa]\n\nfunction model1(θ, ensemble)\n    prob = ODEProblem(f, [θ[1]], (0.0, 1.0), [θ[2]])\n\n    function prob_func(prob, i, repeat)\n        remake(prob, u0 = 0.5 .+ i / 100 .* prob.u0)\n    end\n\n    ensemble_prob = EnsembleProblem(prob, prob_func = prob_func)\n    sim = solve(ensemble_prob, Tsit5(), ensemble, saveat = 0.1, trajectories = 100)\nend\n\ncallback = function (θ, l) # callback function to observe training\n    @show l\n    false\nend\n\nopt = ADAM(0.1)\nloss_distributed(θ) = sum(abs2, 1.0 .- Array(model1(θ, EnsembleDistributed())))\nl1 = loss_distributed(θ)\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_distributed(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, θ)\n\nres_distributed = Optimization.solve(optprob, opt; callback = callback, maxiters = 100)","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"And note that only addprocs(4) needs to be changed in order to make this demo run across a cluster. For more information on adding processes to a cluster, check out ClusterManagers.jl.","category":"page"},{"location":"tutorials/data_parallel/#Minibatching-Across-GPUs-with-DiffEqGPU","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Minibatching Across GPUs with DiffEqGPU","text":"","category":"section"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"DiffEqGPU.jl allows for generating code parallelizes an ensemble on generated CUDA kernels. This method is efficient for sufficiently small (<100 ODE) problems, where the significant computational cost is due to the large number of batch trajectories that need to be solved. This kernel-building process adds a few restrictions to the function, such as requiring it has no boundschecking or allocations. The following is an example of minibatch ensemble parallelism across a GPU:","category":"page"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"using DifferentialEquations, Optimization, OptimizationFlux, DiffEqGPU\nfunction f(du, u, p, t)\n    @inbounds begin\n        du[1] = 1.01 * u[1] * p[1] * p[2]\n    end\nend\n\npa = [1.0]\nu0 = [3.0]\nθ = [u0; pa]\n\nfunction model1(θ, ensemble)\n    prob = ODEProblem(f, [θ[1]], (0.0, 1.0), [θ[2]])\n\n    function prob_func(prob, i, repeat)\n        remake(prob, u0 = 0.5 .+ i / 100 .* prob.u0)\n    end\n\n    ensemble_prob = EnsembleProblem(prob, prob_func = prob_func)\n    sim = solve(ensemble_prob, Tsit5(), ensemble, saveat = 0.1, trajectories = 100)\nend\n\ncallback = function (θ, l) # callback function to observe training\n    @show l\n    false\nend\n\nopt = ADAM(0.1)\nloss_gpu(θ) = sum(abs2, 1.0 .- Array(model1(θ, EnsembleGPUArray())))\nl1 = loss_gpu(θ)\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_gpu(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, θ)\n\nres_gpu = Optimization.solve(optprob, opt; callback = callback, maxiters = 100)","category":"page"},{"location":"tutorials/data_parallel/#Multi-GPU-Batching","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Multi-GPU Batching","text":"","category":"section"},{"location":"tutorials/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"DiffEqGPU supports batching across multiple GPUs. See its README for details on setting it up.","category":"page"},{"location":"getting_started/#auto_diff","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"warn: Warn\nThis tutorial assumes familiarity with DifferentialEquations.jl. If you are not familiar with DifferentialEquations.jl, please consult the DifferentialEquations.jl documentation.","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"SciMLSensitivity.jl is a tool for obtaining derivatives of equation solvers, such as differential equation solvers. These can be used in many ways, such as for analyzing the local sensitivities of a system or to compute the gradients of cost functions for model calibration and parameter estimation. In this tutorial, we will show how to make use of the tooling in SciMLSensitivity.jl to differentiate the ODE solvers.","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"note: Note\nSciMLSensitivity.jl applies to all equation solvers of the SciML ecosystem, such as linear solvers, nonlinear solvers, nonlinear optimization, and more. This tutorial focuses on differential equations, so please see the other tutorials focused on these other SciMLProblem types as necessary. While the interface works similarly for all problem types, these tutorials will showcase the aspects that are special to a given problem.","category":"page"},{"location":"getting_started/#Setup","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Setup","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"Let's first define a differential equation we wish to solve. We will choose the Lotka-Volterra equation. This is done via DifferentialEquations.jl using:","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"using DifferentialEquations\n\nfunction lotka_volterra!(du, u, p, t)\n    du[1] = dx = p[1] * u[1] - p[2] * u[1] * u[2]\n    du[2] = dy = -p[3] * u[2] + p[4] * u[1] * u[2]\nend\np = [1.5, 1.0, 3.0, 1.0];\nu0 = [1.0; 1.0];\nprob = ODEProblem(lotka_volterra!, u0, (0.0, 10.0), p)\nsol = solve(prob, Tsit5(), reltol = 1e-6, abstol = 1e-6)","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"Now let's differentiate the solution to this ODE using a few different automatic differentiation methods.","category":"page"},{"location":"getting_started/#Forward-Mode-Automatic-Differentiation-with-ForwardDiff.jl","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Forward-Mode Automatic Differentiation with ForwardDiff.jl","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"Let's say we need the derivative of the solution with respect to the initial condition u0 and its parameters p. One of the simplest ways to do this is via ForwardDiff.jl. All one needs to do is to use the ForwardDiff.jl library to differentiate some function f which uses a differential equation solve inside of it. For example, let's say we want the derivative of the first component of the ODE solution with respect to these quantities at evenly spaced time points of dt = 1. We can compute this via:","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"using ForwardDiff\n\nfunction f(x)\n    _prob = remake(prob, u0 = x[1:2], p = x[3:end])\n    solve(_prob, Tsit5(), reltol = 1e-6, abstol = 1e-6, saveat = 1)[1, :]\nend\nx = [u0; p]\ndx = ForwardDiff.jacobian(f, x)","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"Let's dig into what this is saying a bit. x is a vector which concatenates the initial condition and parameters, meaning that the first 2 values are the initial conditions and the last 4 are the parameters. We use the remake function to build a function f(x) which uses these new initial conditions and parameters to solve the differential equation and return the time series of the first component.","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"Then ForwardDiff.jacobian(f,x) computes the Jacobian of f with respect to x. The output dx[i,j] corresponds to the derivative of the solution of the first component at time t=j-1 with respect to x[i]. For example, dx[3,2] is the derivative of the first component of the solution at time t=1 with respect to p[1].","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"note: Note\nSince the global error is 1-2 orders of magnitude higher than the local error, we use accuracies of 1e-6 (instead of the default 1e-3) to get reasonable sensitivities","category":"page"},{"location":"getting_started/#Reverse-Mode-Automatic-Differentiation","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Reverse-Mode Automatic Differentiation","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"The solve function is automatically compatible with AD systems like Zygote.jl and thus there is no machinery that is necessary to use other than to put solve inside a function that is differentiated by Zygote. For example, the following computes the solution to an ODE and computes the gradient of a loss function (the sum of the ODE's output at each timepoint with dt=0.1) via the adjoint method:","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"using Zygote, SciMLSensitivity\n\nfunction sum_of_solution(u0, p)\n    _prob = remake(prob, u0 = u0, p = p)\n    sum(solve(_prob, Tsit5(), reltol = 1e-6, abstol = 1e-6, saveat = 0.1))\nend\ndu01, dp1 = Zygote.gradient(sum_of_solution, u0, p)","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"Zygote.jl's automatic differentiation system is overloaded to allow SciMLSensitivity.jl to redefine the way the derivatives are computed, allowing trade-offs between numerical stability, memory, and compute performance, similar to how ODE solver algorithms are chosen.","category":"page"},{"location":"getting_started/#Choosing-Sensitivity-Algorithms","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Choosing Sensitivity Algorithms","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"The algorithms for differentiation calculation are called AbstractSensitivityAlgorithms, or sensealgs for short. These are chosen by passing the sensealg keyword argument into solve. Let's demonstrate this by choosing the QuadratureAdjoint sensealg for the differentiation of this system:","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"function sum_of_solution(u0, p)\n    _prob = remake(prob, u0 = u0, p = p)\n    sum(solve(_prob, Tsit5(), reltol = 1e-6, abstol = 1e-6, saveat = 0.1,\n        sensealg = QuadratureAdjoint()))\nend\ndu01, dp1 = Zygote.gradient(sum_of_solution, u0, p)","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"Here this computes the derivative of the output with respect to the initial condition and the derivative with respect to the parameters respectively using the QuadratureAdjoint(). For more information on the choices of sensitivity algorithms, see the reference documentation in choosing sensitivity algorithms.","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"note: Note\nForwardDiff.jl's automatic differentiation system ignores the sensitivity algorithms.","category":"page"},{"location":"getting_started/#When-Should-You-Use-Forward-or-Reverse-Mode?","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"When Should You Use Forward or Reverse Mode?","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"Good question! The simple answer is, if you are differentiating a system of fewer than 100 equations, use forward-mode, otherwise reverse-mode. But it can be a lot more complicated than that! For more information, see the reference documentation in choosing sensitivity algorithms.","category":"page"},{"location":"getting_started/#And-that-is-it!-Where-should-you-go-from-here?","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"And that is it! Where should you go from here?","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"That's all there is to the basics of differentiating the ODE solvers with SciMLSensitivity.jl. That said, check out the following tutorials to dig into more detail:","category":"page"},{"location":"getting_started/","page":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","title":"Getting Started with SciMLSensitivity: Differentiating ODE Solutions","text":"See the ODE parameter estimation tutorial to learn how to fit the parameters of ODE systems\nSee the direct sensitivity tutorial to dig into the lower level API for more performance","category":"page"},{"location":"examples/pde/pde_constrained/#Partial-Differential-Equation-(PDE)-Constrained-Optimization","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"This example uses a prediction model to optimize the one-dimensional Heat Equation. (Step-by-step description below)","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"using DelimitedFiles, Plots\nusing DifferentialEquations, Optimization, OptimizationPolyalgorithms, Zygote\n\n# Problem setup parameters:\nLx = 10.0\nx = 0.0:0.01:Lx\ndx = x[2] - x[1]\nNx = size(x)\n\nu0 = exp.(-(x .- 3.0) .^ 2) # I.C\n\n## Problem Parameters\np = [1.0, 1.0]    # True solution parameters\nxtrs = [dx, Nx]      # Extra parameters\ndt = 0.40 * dx^2    # CFL condition\nt0, tMax = 0.0, 1000 * dt\ntspan = (t0, tMax)\nt = t0:dt:tMax;\n\n## Definition of Auxiliary functions\nfunction ddx(u, dx)\n    \"\"\"\n    2nd order Central difference for 1st degree derivative\n    \"\"\"\n    return [[zero(eltype(u))]; (u[3:end] - u[1:(end - 2)]) ./ (2.0 * dx); [zero(eltype(u))]]\nend\n\nfunction d2dx(u, dx)\n    \"\"\"\n    2nd order Central difference for 2nd degree derivative\n    \"\"\"\n    return [[zero(eltype(u))];\n        (u[3:end] - 2.0 .* u[2:(end - 1)] + u[1:(end - 2)]) ./ (dx^2);\n        [zero(eltype(u))]]\nend\n\n## ODE description of the Physics:\nfunction heat(u, p, t)\n    # Model parameters\n    a0, a1 = p\n    dx, Nx = xtrs #[1.0,3.0,0.125,100]\n    return 2.0 * a0 .* u + a1 .* d2dx(u, dx)\nend\n\n# Testing Solver on linear PDE\nprob = ODEProblem(heat, u0, tspan, p)\nsol = solve(prob, Tsit5(), dt = dt, saveat = t);\n\nplot(x, sol.u[1], lw = 3, label = \"t0\", size = (800, 500))\nplot!(x, sol.u[end], lw = 3, ls = :dash, label = \"tMax\")\n\nps = [0.1, 0.2];   # Initial guess for model parameters\nfunction predict(θ)\n    Array(solve(prob, Tsit5(), p = θ, dt = dt, saveat = t))\nend\n\n## Defining Loss function\nfunction loss(θ)\n    pred = predict(θ)\n    l = predict(θ) - sol\n    return sum(abs2, l), pred # Mean squared error\nend\n\nl, pred = loss(ps)\nsize(pred), size(sol), size(t) # Checking sizes\n\nLOSS = []                              # Loss accumulator\nPRED = []                              # prediction accumulator\nPARS = []                              # parameters accumulator\n\ncallback = function (θ, l, pred) #callback function to observe training\n    display(l)\n    append!(PRED, [pred])\n    append!(LOSS, l)\n    append!(PARS, [θ])\n    false\nend\n\ncallback(ps, loss(ps)...) # Testing callback function\n\n# Let see prediction vs. Truth\nscatter(sol[:, end], label = \"Truth\", size = (800, 500))\nplot!(PRED[end][:, end], lw = 2, label = \"Prediction\")\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\n\noptprob = Optimization.OptimizationProblem(optf, ps)\nres = Optimization.solve(optprob, PolyOpt(), callback = callback)\n@show res.u # returns [0.999999999613485, 0.9999999991343996]","category":"page"},{"location":"examples/pde/pde_constrained/#Step-by-step-Description","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Step-by-step Description","text":"","category":"section"},{"location":"examples/pde/pde_constrained/#Load-Packages","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Load Packages","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"using DelimitedFiles, Plots\nusing DifferentialEquations, Optimization, OptimizationPolyalgorithms,\n    Zygote","category":"page"},{"location":"examples/pde/pde_constrained/#Parameters","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Parameters","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"First, we set up the 1-dimensional space over which our equations will be evaluated. x spans from 0.0 to 10.0 in steps of 0.01; t spans from 0.00 to 0.04 in steps of 4.0e-5.","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"# Problem setup parameters:\nLx = 10.0\nx = 0.0:0.01:Lx\ndx = x[2] - x[1]\nNx = size(x)\n\nu0 = exp.(-(x .- 3.0) .^ 2) # I.C\n\n## Problem Parameters\np = [1.0, 1.0]    # True solution parameters\nxtrs = [dx, Nx]      # Extra parameters\ndt = 0.40 * dx^2    # CFL condition\nt0, tMax = 0.0, 1000 * dt\ntspan = (t0, tMax)\nt = t0:dt:tMax;","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"In plain terms, the quantities that were defined are:","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"x (to Lx) spans the specified 1D space\ndx = distance between two points\nNx = total size of space\nu0 = initial condition\np = true solution\nxtrs = convenient grouping of dx and Nx into Array\ndt = time distance between two points\nt (t0 to tMax) spans the specified time frame\ntspan = span of t","category":"page"},{"location":"examples/pde/pde_constrained/#Auxiliary-Functions","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Auxiliary Functions","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"We then define two functions to compute the derivatives numerically. The Central Difference is used in both the 1st and 2nd degree derivatives.","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"## Definition of Auxiliary functions\nfunction ddx(u, dx)\n    \"\"\"\n    2nd order Central difference for 1st degree derivative\n    \"\"\"\n    return [[zero(eltype(u))]; (u[3:end] - u[1:(end - 2)]) ./ (2.0 * dx); [zero(eltype(u))]]\nend\n\nfunction d2dx(u, dx)\n    \"\"\"\n    2nd order Central difference for 2nd degree derivative\n    \"\"\"\n    return [[zero(eltype(u))];\n        (u[3:end] - 2.0 .* u[2:(end - 1)] + u[1:(end - 2)]) ./ (dx^2);\n        [zero(eltype(u))]]\nend","category":"page"},{"location":"examples/pde/pde_constrained/#Heat-Differential-Equation","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Heat Differential Equation","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"Next, we set up our desired set of equations in order to define our problem.","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"## ODE description of the Physics:\nfunction heat(u, p, t)\n    # Model parameters\n    a0, a1 = p\n    dx, Nx = xtrs #[1.0,3.0,0.125,100]\n    return 2.0 * a0 .* u + a1 .* d2dx(u, dx)\nend","category":"page"},{"location":"examples/pde/pde_constrained/#Solve-and-Plot-Ground-Truth","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Solve and Plot Ground Truth","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"We then solve and plot our partial differential equation. This is the true solution, which we will compare to further on.","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"# Testing Solver on linear PDE\nprob = ODEProblem(heat, u0, tspan, p)\nsol = solve(prob, Tsit5(), dt = dt, saveat = t);\n\nplot(x, sol.u[1], lw = 3, label = \"t0\", size = (800, 500))\nplot!(x, sol.u[end], lw = 3, ls = :dash, label = \"tMax\")","category":"page"},{"location":"examples/pde/pde_constrained/#Building-the-Prediction-Model","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Building the Prediction Model","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"Now we start building our prediction model to try to obtain the values p. We make an initial guess for the parameters and name it ps here. The predict function is a non-linear transformation in one layer using solve. If unfamiliar with the concept, refer to here.","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"ps = [0.1, 0.2];   # Initial guess for model parameters\nfunction predict(θ)\n    Array(solve(prob, Tsit5(), p = θ, dt = dt, saveat = t))\nend","category":"page"},{"location":"examples/pde/pde_constrained/#Train-Parameters","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Train Parameters","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"Training our model requires a loss function, an optimizer, and a callback function to display the progress.","category":"page"},{"location":"examples/pde/pde_constrained/#Loss","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Loss","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"We first make our predictions based on the current values of our parameters ps, then take the difference between the predicted solution and the truth above. For the loss, we use the mean squared error.","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"## Defining Loss function\nfunction loss(θ)\n    pred = predict(θ)\n    l = predict(θ) - sol\n    return sum(abs2, l), pred # Mean squared error\nend\n\nl, pred = loss(ps)\nsize(pred), size(sol), size(t) # Checking sizes","category":"page"},{"location":"examples/pde/pde_constrained/#Optimizer","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Optimizer","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"The optimizers ADAM with a learning rate of 0.01 and BFGS are directly passed in training (see below)","category":"page"},{"location":"examples/pde/pde_constrained/#Callback","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Callback","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"The callback function displays the loss during training. We also keep a history of the loss, the previous predictions and the previous parameters with LOSS, PRED and PARS accumulators.","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"LOSS = []                              # Loss accumulator\nPRED = []                              # prediction accumulator\nPARS = []                              # parameters accumulator\n\ncallback = function (θ, l, pred) #callback function to observe training\n    display(l)\n    append!(PRED, [pred])\n    append!(LOSS, l)\n    append!(PARS, [θ])\n    false\nend\n\ncallback(ps, loss(ps)...) # Testing callback function","category":"page"},{"location":"examples/pde/pde_constrained/#Plotting-Prediction-vs-Ground-Truth","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Plotting Prediction vs Ground Truth","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"The scatter points plotted here are the ground truth obtained from the actual solution we solved for above. The solid line represents our prediction. The goal is for both to overlap almost perfectly when the PDE finishes its training and the loss is close to 0.","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"# Let see prediction vs. Truth\nscatter(sol[:, end], label = \"Truth\", size = (800, 500))\nplot!(PRED[end][:, end], lw = 2, label = \"Prediction\")","category":"page"},{"location":"examples/pde/pde_constrained/#Train","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Train","text":"","category":"section"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"The parameters are trained using Optimization.solve and adjoint sensitivities. The resulting best parameters are stored in res and res.u returns the parameters that minimize the cost function.","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"adtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\n\noptprob = Optimization.OptimizationProblem(optf, ps)\nres = Optimization.solve(optprob, PolyOpt(), callback = callback)\n@show res.u # returns [0.999999999613485, 0.9999999991343996]","category":"page"},{"location":"examples/pde/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"We successfully predict the final ps to be equal to [0.999999999999975, 1.0000000000000213] vs the true solution of p = [1.0, 1.0]","category":"page"},{"location":"examples/neural_ode/simplechains/#Neural-Ordinary-Differential-Equations-with-SimpleChains","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Neural Ordinary Differential Equations with SimpleChains","text":"","category":"section"},{"location":"examples/neural_ode/simplechains/","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Neural Ordinary Differential Equations with SimpleChains","text":"SimpleChains has demonstrated performance boosts of ~5x and ~30x when compared to other mainstream deep learning frameworks like Pytorch for the training and evaluation in the specific case of small neural networks. For the nitty-gritty details, as well as, some SciML related videos around the need and applications of such a library, we can refer to this blogpost. As for doing Scientific Machine Learning, how do we even begin with training neural ODEs with any generic deep learning library?","category":"page"},{"location":"examples/neural_ode/simplechains/#Training-Data","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Training Data","text":"","category":"section"},{"location":"examples/neural_ode/simplechains/","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Neural Ordinary Differential Equations with SimpleChains","text":"First, we'll need data for training the NeuralODE, which can be obtained by solving the ODE u' = f(u,p,t) numerically using the SciML ecosystem in Julia.","category":"page"},{"location":"examples/neural_ode/simplechains/","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Neural Ordinary Differential Equations with SimpleChains","text":"using SimpleChains,\n    StaticArrays, OrdinaryDiffEq, SciMLSensitivity, Optimization,\n    OptimizationFlux, Plots\n\nu0 = @SArray Float32[2.0, 0.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODE(u, p, t)\n    true_A = @SMatrix Float32[-0.1 2.0; -2.0 -0.1]\n    ((u .^ 3)'true_A)'\nend\n\nprob = ODEProblem(trueODE, u0, tspan)\ndata = Array(solve(prob, Tsit5(), saveat = tsteps))","category":"page"},{"location":"examples/neural_ode/simplechains/#Neural-Network","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Neural Network","text":"","category":"section"},{"location":"examples/neural_ode/simplechains/","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Neural Ordinary Differential Equations with SimpleChains","text":"Next, we set up a small neural network. It will be trained to output the derivative of the solution at each time step given the value of the solution at the previous time step, and the parameters of the network. Thus, we are treating the neural network as a function f(u,p,t). The difference is that instead of relying on knowing the exact equation for the ODE, we get to solve it only with the data.","category":"page"},{"location":"examples/neural_ode/simplechains/","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Neural Ordinary Differential Equations with SimpleChains","text":"sc = SimpleChain(static(2),\n    Activation(x -> x .^ 3),\n    TurboDense{true}(tanh, static(50)),\n    TurboDense{true}(identity, static(2)))\n\np_nn = SimpleChains.init_params(sc)\n\nf(u, p, t) = sc(u, p)","category":"page"},{"location":"examples/neural_ode/simplechains/#NeuralODE,-Prediction-and-Loss","page":"Neural Ordinary Differential Equations with SimpleChains","title":"NeuralODE, Prediction and Loss","text":"","category":"section"},{"location":"examples/neural_ode/simplechains/","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Neural Ordinary Differential Equations with SimpleChains","text":"Now instead of the function trueODE(u,p,t) in the first code block, we pass the neural network to the ODE solver. This is our NeuralODE. Now, in order to train it, we obtain predictions from the model and calculate the L2 loss against the data generated numerically previously.","category":"page"},{"location":"examples/neural_ode/simplechains/","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Neural Ordinary Differential Equations with SimpleChains","text":"prob_nn = ODEProblem(f, u0, tspan)\n\nfunction predict_neuralode(p)\n    Array(solve(prob_nn, Tsit5(); p = p, saveat = tsteps,\n        sensealg = QuadratureAdjoint(autojacvec = ZygoteVJP())))\nend\n\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, data .- pred)\n    return loss, pred\nend","category":"page"},{"location":"examples/neural_ode/simplechains/#Training","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Training","text":"","category":"section"},{"location":"examples/neural_ode/simplechains/","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Neural Ordinary Differential Equations with SimpleChains","text":"The next step is to minimize the loss, so that the NeuralODE gets trained. But in order to be able to do that, we have to be able to backpropagate through the NeuralODE model. Here the backpropagation through the neural network is the easy part, and we get that out of the box with any deep learning package(although not as fast as SimpleChains for the small nn case here). But we have to find a way to first propagate the sensitivities of the loss back, first through the ODE solver and then to the neural network.","category":"page"},{"location":"examples/neural_ode/simplechains/","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Neural Ordinary Differential Equations with SimpleChains","text":"The adjoint of a neural ODE can be calculated through the various AD algorithms available in SciMLSensitivity.jl. But working with StaticArrays in SimpleChains.jl requires a special adjoint method as StaticArrays do not allow any mutation. All the adjoint methods make heavy use of in-place mutation to be performant with the heap allocated normal arrays. For our statically sized, stack allocated StaticArrays, in order to be able to compute the ODE adjoint we need to do everything out of place. Hence, we have specifically used QuadratureAdjoint(autojacvec=ZygoteVJP()) adjoint algorithm in the solve call inside predict_neuralode(p) which computes everything out-of-place when u0 is a StaticArray. Hence, we can move forward with the training of the NeuralODE","category":"page"},{"location":"examples/neural_ode/simplechains/","page":"Neural Ordinary Differential Equations with SimpleChains","title":"Neural Ordinary Differential Equations with SimpleChains","text":"callback = function (p, l, pred; doplot = true)\n    display(l)\n    plt = scatter(tsteps, data[1, :], label = \"data\")\n    scatter!(plt, tsteps, pred[1, :], label = \"prediction\")\n    if doplot\n        display(plot(plt))\n    end\n    return false\nend\n\noptf = Optimization.OptimizationFunction((x, p) -> loss_neuralode(x),\n    Optimization.AutoZygote())\noptprob = Optimization.OptimizationProblem(optf, p_nn)\n\nres = Optimization.solve(optprob, ADAM(0.05), callback = callback, maxiters = 300)","category":"page"},{"location":"#SciMLSensitivity:-Automatic-Differentiation-and-Adjoints-for-(Differential)-Equation-Solvers","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"","category":"section"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"SciMLSensitivity.jl is the automatic differentiation and adjoints system for the SciML ecosystem. Also known as local sensitivity analysis, these methods allow for calculation of fast derivatives of SciML problem types which are commonly used to analyze model sensitivities, calibrate models to data, train neural ODEs, perform automated model discovery via universal differential equations, and more. SciMLSensitivity.jl is a high-level interface that pulls together all the tools with heuristics and helper functions to make solving inverse problems and inferring models as easy as possible without losing efficiency.","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Thus, what SciMLSensitivity.jl provides is:","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Automatic differentiation overloads for improving the performance and flexibility of AD calls over solve.\nA lower level direct interface for defining forward sensitivity and adjoint problems to allow for minimal overhead and maximal performance.\nA bunch of tutorials, documentation, and test cases for this combination with parameter estimation (data fitting / model calibration), neural network libraries and GPUs.","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"note: Note\nThis documentation assumes familiarity with the solver packages for the respective problem types. If one is not familiar with the solver packages, please consult the documentation for pieces like DifferentialEquations.jl, NonlinearSolve.jl, LinearSolve.jl, etc. first.","category":"page"},{"location":"#Installation","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"Installation","text":"","category":"section"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"To install SciMLSensitivity.jl, use the Julia package manager:","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"using Pkg\nPkg.add(\"SciMLSensitivity\")","category":"page"},{"location":"#High-Level-Interface:-sensealg","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"High-Level Interface: sensealg","text":"","category":"section"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"The highest level interface is provided by the function solve:","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"solve(prob, args...; sensealg = InterpolatingAdjoint(),\n    checkpoints = sol.t, kwargs...)","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"solve is fully compatible with automatic differentiation libraries like:","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Zygote.jl\nReverseDiff.jl\nTracker.jl\nForwardDiff.jl","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"and will automatically replace any calculations of the solution's derivative with a fast method. The keyword argument sensealg controls the dispatch to the AbstractSensitivityAlgorithm used for the sensitivity calculation. Note that solve in an AD context does not allow higher order interpolations unless sensealg=DiffEqBase.SensitivityADPassThrough() is used, i.e. going back to the AD mechanism.","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"note: Note\nThe behavior of ForwardDiff.jl is different from the other automatic differentiation libraries mentioned above. The sensealg keyword is ignored. Instead, the differential equations are solved using Dual numbers for u0 and p. If only p is perturbed in the sensitivity analysis, but not u0, the state is still implemented as a Dual number. ForwardDiff.jl will thus not dispatch into continuous forward nor adjoint sensitivity analysis even if a sensealg is provided.","category":"page"},{"location":"#Equation-Scope","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"Equation Scope","text":"","category":"section"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"SciMLSensitivity.jl supports all the equation types of the SciML Common Interface, extending the problem types by adding overloads for automatic differentiation to improve the performance and flexibility of the differentiation system. This includes:","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Linear systems (LinearProblem)\nDirect methods for dense and sparse\nIterative solvers with preconditioning\nNonlinear Systems (NonlinearProblem)\nSystems of nonlinear equations\nScalar bracketing systems\nIntegrals (quadrature) (QuadratureProblem)\nDifferential Equations\nDiscrete equations (function maps, discrete stochastic (Gillespie/Markov) simulations) (DiscreteProblem)\nOrdinary differential equations (ODEs) (ODEProblem)\nSplit and Partitioned ODEs (Symplectic integrators, IMEX Methods) (SplitODEProblem)\nStochastic ordinary differential equations (SODEs or SDEs) (SDEProblem)\nStochastic differential-algebraic equations (SDAEs) (SDEProblem with mass matrices)\nRandom differential equations (RODEs or RDEs) (RODEProblem)\nDifferential algebraic equations (DAEs) (DAEProblem and ODEProblem with mass matrices)\nDelay differential equations (DDEs) (DDEProblem)\nNeutral, retarded, and algebraic delay differential equations (NDDEs, RDDEs, and DDAEs)\nStochastic delay differential equations (SDDEs) (SDDEProblem)\nExperimental support for stochastic neutral, retarded, and algebraic delay differential equations (SNDDEs, SRDDEs, and SDDAEs)\nMixed discrete and continuous equations (Hybrid Equations, Jump Diffusions) (DEProblems with callbacks)\nOptimization (OptimizationProblem)\nNonlinear (constrained) optimization\n(Stochastic/Delay/Differential-Algebraic) Partial Differential Equations (PDESystem)\nFinite difference and finite volume methods\nInterfaces to finite element methods\nPhysics-Informed Neural Networks (PINNs)\nIntegro-Differential Equations\nFractional Differential Equations","category":"page"},{"location":"#SciMLSensitivity-and-Universal-Differential-Equations","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity and Universal Differential Equations","text":"","category":"section"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"SciMLSensitivity is for universal differential equations, where these can include delays, physical constraints, stochasticity, events, and all other kinds of interesting behavior that shows up in scientific simulations. Neural networks can be all or part of the model. They can be around the differential equation, in the cost function, or inside the differential equation. Neural networks representing unknown portions of the model or functions can go anywhere you have uncertainty in the form of the scientific simulator. Forward sensitivity and adjoint equations are automatically generated with checkpointing and stabilization to ensure it works for large stiff equations, while specializations on static objects allows for high efficiency on small equations. For an overview of the topic with applications, consult the paper Universal Differential Equations for Scientific Machine Learning.","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"You can efficiently use the package for:","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Parameter estimation of scientific models (ODEs, SDEs, DDEs, DAEs, etc.)\nNeural ODEs, Neural SDE, Neural DAEs, Neural DDEs, etc.\nNonlinear optimal control, including training neural controllers\n(Stiff) universal ordinary differential equations (universal ODEs)\nUniversal stochastic differential equations (universal SDEs)\nUniversal delay differential equations (universal DDEs)\nUniversal partial differential equations (universal PDEs)\nUniversal jump stochastic differential equations (universal jump diffusions)\nHybrid universal differential equations (universal DEs with event handling)","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"with high order, adaptive, implicit, GPU-accelerated, Newton-Krylov, etc. methods. For examples, please refer to the DiffEqFlux release blog post (which we try to keep updated for changes to the libraries). Additional demonstrations, like neural PDEs and neural jump SDEs, can be found at this blog post (among many others!). All these features are only part of the advantage, as this library routinely benchmarks orders of magnitude faster than competing libraries like torchdiffeq. Use with GPUs is highly optimized by recompiling the solvers to GPUs to remove all CPU-GPU data transfers, while use with CPUs uses specialized kernels for accelerating differential equation solves.","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Many training techniques are supported by this package, including:","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Optimize-then-discretize (backsolve adjoints, checkpointed adjoints, quadrature adjoints)\nDiscretize-then-optimize (forward and reverse mode discrete sensitivity analysis)\nThis is a generalization of ANODE and ANODEv2 to all DifferentialEquations.jl ODE solvers\nHybrid approaches (adaptive time stepping + AD for adaptive discretize-then-optimize)\nO(1) memory backprop of ODEs via BacksolveAdjoint, and Virtual Brownian Trees for O(1) backprop of SDEs\nContinuous adjoints for integral loss functions\nProbabilistic programming and variational inference on ODEs/SDEs/DAEs/DDEs/hybrid equations etc. is provided by integration with Turing.jl and Gen.jl. Reproduce variational loss functions by plugging composable libraries together.","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"all while mixing forward mode and reverse mode approaches as appropriate for the most speed. For more details on the adjoint sensitivity analysis methods for computing fast gradients, see the adjoints details page.","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"With this package, you can explore various ways to integrate the two methodologies:","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Neural networks can be defined where the “activations” are nonlinear functions described by differential equations\nNeural networks can be defined where some layers are ODE solves\nODEs can be defined where some terms are neural networks\nCost functions on ODEs can define neural networks","category":"page"},{"location":"#Note-on-Modularity-and-Composability-with-Solvers","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"Note on Modularity and Composability with Solvers","text":"","category":"section"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Note that SciMLSensitivity.jl purely built on composable and modular infrastructure. SciMLSensitivity provides high-level helper functions and documentation for the user, but the code generation stack is modular and composes in many ways. For example, one can use and swap out the ODE solver between any common interface compatible library, like:","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Sundials.jl\nOrdinaryDiffEq.jl\nLSODA.jl\nIRKGaussLegendre.jl\nSciPyDiffEq.jl\n… etc. many other choices!","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"In addition, due to the composability of the system, none of the components are directly tied to the Flux.jl machine learning framework. For example, you can use SciMLSensitivity.jl to generate TensorFlow graphs and train the neural network with TensorFlow.jl, use PyTorch arrays via Torch.jl, and more all with single line code changes by utilizing the underlying code generation. The tutorials shown here are thus mostly a guide on how to use the ecosystem as a whole, only showing a small snippet of the possible ways to compose the thousands of differentiable libraries together! Swap out ODEs for SDEs, DDEs, DAEs, etc., put quadrature libraries or Tullio.jl in the loss function, the world is your oyster!","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"As a proof of composability, note that the implementation of Bayesian neural ODEs required zero code changes to the library, and instead just relied on the composability with other Julia packages.","category":"page"},{"location":"#Contributing","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"Contributing","text":"","category":"section"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nSee the SciML Style Guide for common coding practices and other style decisions.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Zulip\nOn the Julia Discourse forums\nSee also SciML Community page","category":"page"},{"location":"#Citation","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"Citation","text":"","category":"section"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"If you use SciMLSensitivity.jl or are influenced by its ideas, please cite:","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"@article{rackauckas2020universal,\n  title={Universal differential equations for scientific machine learning},\n  author={Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali},\n  journal={arXiv preprint arXiv:2001.04385},\n  year={2020}\n}","category":"page"},{"location":"#Reproducibility","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"Reproducibility","text":"","category":"section"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"</details>","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"</details>","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"using Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"</details>","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"You can also download the \n<a href=\"","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"using TOML\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n       \"/assets/Manifest.toml\"","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"\">manifest</a> file and the\n<a href=\"","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"using TOML\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n       \"/assets/Project.toml\"","category":"page"},{"location":"","page":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"\">project</a> file.","category":"page"},{"location":"examples/optimal_control/optimal_control/#optcontrol","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"","category":"section"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"Here we will solve a classic optimal control problem with a universal differential equation. Let","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"x^ = u^3(t)","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"where we want to optimize our controller u(t) such that the following is minimized:","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"L(theta) = sum_i Vert 4 - x(t_i) Vert + 2 Vert x^prime(t_i) Vert + Vert u(t_i) Vert","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"where i is measured on (0,8) at 0.01 intervals. To do this, we rewrite the ODE in first order form:","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"beginaligned\nx^prime = v \nv^ = u^3(t) \nendaligned","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"and thus","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"L(theta) = sum_i Vert 4 - x(t_i) Vert + 2 Vert v(t_i) Vert + Vert u(t_i) Vert","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"is our loss function on the first order system. We thus choose a neural network form for u and optimize the equation with respect to this loss. Note that we will first reduce control cost (the last term) by 10x in order to bump the network out of a local minimum. This looks like:","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"using Flux, DifferentialEquations, Optimization, OptimizationNLopt, OptimizationFlux,\n    SciMLSensitivity, Zygote, Plots, Statistics, Random\n\nrng = Random.default_rng()\ntspan = (0.0f0, 8.0f0)\nann = Flux.Chain(Flux.Dense(1, 32, tanh), Flux.Dense(32, 32, tanh), Flux.Dense(32, 1))\nθ, re = Flux.destructure(ann)\nfunction dxdt_(dx, x, p, t)\n    x1, x2 = x\n    dx[1] = x[2]\n    dx[2] = re(p)([t])[1]^3\nend\nx0 = [-4.0f0, 0.0f0]\nts = Float32.(collect(0.0:0.01:tspan[2]))\nprob = ODEProblem(dxdt_, x0, tspan, θ)\nsolve(prob, Vern9(), abstol = 1e-10, reltol = 1e-10)\n\nfunction predict_adjoint(θ)\n    Array(solve(prob, Vern9(), p = θ, saveat = ts,\n        sensealg = InterpolatingAdjoint(autojacvec = ReverseDiffVJP(true))))\nend\nfunction loss_adjoint(θ)\n    x = predict_adjoint(θ)\n    mean(abs2, 4.0 .- x[1, :]) + 2mean(abs2, x[2, :]) +\n    mean(abs2, [first(re(θ)([t])) for t in ts]) / 10\nend\n\nl = loss_adjoint(θ)\ncallback = function (θ, l; doplot = false)\n    println(l)\n\n    if doplot\n        p = plot(solve(remake(prob, p = θ), Tsit5(), saveat = 0.01), ylim = (-6, 6), lw = 3)\n        plot!(p, ts, [first(re(θ)([t])) for t in ts], label = \"u(t)\", lw = 3)\n        display(p)\n    end\n\n    return false\nend\n\n# Display the ODE with the current parameter values.\n\ncallback(θ, l)\n\n# Setup and run the optimization\n\nloss1 = loss_adjoint(θ)\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss_adjoint(x), adtype)\n\noptprob = Optimization.OptimizationProblem(optf, θ)\nres1 = Optimization.solve(optprob, ADAM(0.005), callback = callback, maxiters = 100)\n\noptprob2 = Optimization.OptimizationProblem(optf, res1.u)\nres2 = Optimization.solve(optprob2,\n    NLopt.LD_LBFGS(), maxiters = 100)","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"Now that the system is in a better behaved part of parameter space, we return to the original loss function to finish the optimization:","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"function loss_adjoint(θ)\n    x = predict_adjoint(θ)\n    mean(abs2, 4.0 .- x[1, :]) + 2mean(abs2, x[2, :]) +\n    mean(abs2, [first(re(θ)([t])) for t in ts])\nend\noptf3 = Optimization.OptimizationFunction((x, p) -> loss_adjoint(x), adtype)\n\noptprob3 = Optimization.OptimizationProblem(optf3, res2.u)\nres3 = Optimization.solve(optprob3,\n    NLopt.LD_LBFGS(), maxiters = 100)","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"Now let's see what we received:","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"l = loss_adjoint(res3.u)\ncallback(res3.u, l)\np = plot(solve(remake(prob, p = res3.u), Tsit5(), saveat = 0.01), ylim = (-6, 6), lw = 3)\nplot!(p, ts, [first(re(res3.u)([t])) for t in ts], label = \"u(t)\", lw = 3)","category":"page"},{"location":"examples/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"(Image: )","category":"page"},{"location":"tutorials/training_tips/divergence/#Handling-Divergent-and-Unstable-Trajectories","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"","category":"section"},{"location":"tutorials/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"It is not uncommon for a set of parameters in an ODE model to simply give a divergent trajectory. If the rate of growth compounds and outpaces the rate of decay, you will end up at infinity in finite time. This it is not uncommon to see divergent trajectories in the optimization of parameters, as many times an optimizer can take an excursion into a parameter regime which simply gives a model with an infinite solution.","category":"page"},{"location":"tutorials/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"This can be addressed by using the retcode system. In DifferentialEquations.jl, ReturnCodes detail the status of the returned solution. Thus if the retcode corresponds to a failure, we can use this to give an infinite loss and effectively discard the parameters. This is shown in the loss function:","category":"page"},{"location":"tutorials/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"function loss(p)\n    tmp_prob = remake(prob, p = p)\n    tmp_sol = solve(tmp_prob, Tsit5(), saveat = 0.1)\n    if tmp_sol.retcode == ReturnCode.Success\n        return sum(abs2, Array(tmp_sol) - dataset)\n    else\n        return Inf\n    end\nend","category":"page"},{"location":"tutorials/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"A full example making use of this trick is:","category":"page"},{"location":"tutorials/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"using DifferentialEquations,\n    SciMLSensitivity, Optimization, OptimizationFlux,\n    OptimizationNLopt, Plots\n\nfunction lotka_volterra!(du, u, p, t)\n    rab, wol = u\n    α, β, γ, δ = p\n    du[1] = drab = α * rab - β * rab * wol\n    du[2] = dwol = γ * rab * wol - δ * wol\n    nothing\nend\n\nu0 = [1.0, 1.0]\ntspan = (0.0, 10.0)\np = [1.5, 1.0, 3.0, 1.0]\nprob = ODEProblem(lotka_volterra!, u0, tspan, p)\nsol = solve(prob, saveat = 0.1)\nplot(sol)\n\ndataset = Array(sol)\nscatter!(sol.t, dataset')\n\ntmp_prob = remake(prob, p = [1.2, 0.8, 2.5, 0.8])\ntmp_sol = solve(tmp_prob)\nplot(tmp_sol)\nscatter!(sol.t, dataset')\n\nfunction loss(p)\n    tmp_prob = remake(prob, p = p)\n    tmp_sol = solve(tmp_prob, Tsit5(), saveat = 0.1)\n    if tmp_sol.retcode == ReturnCode.Success\n        return sum(abs2, Array(tmp_sol) - dataset)\n    else\n        return Inf\n    end\nend\n\npinit = [1.2, 0.8, 2.5, 0.8]\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\n\noptprob = Optimization.OptimizationProblem(optf, pinit)\nres = Optimization.solve(optprob, ADAM(), maxiters = 1000)\n\n# res = Optimization.solve(optprob,NLopt.LD_LBFGS(), maxiters = 1000) ### errors!","category":"page"},{"location":"tutorials/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"You might notice that AutoZygote (default) fails for the above Optimization.solve call with Optim's optimizers, which happens because of Zygote's behavior for zero gradients, in which case it returns nothing. To avoid such issues, you can just use a different version of the same check which compares the size of the obtained solution and the data we have, shown below, which is easier to AD.","category":"page"},{"location":"tutorials/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"function loss(p)\n    tmp_prob = remake(prob, p = p)\n    tmp_sol = solve(tmp_prob, Tsit5(), saveat = 0.1)\n    if size(tmp_sol) == size(dataset)\n        return sum(abs2, Array(tmp_sol) .- dataset)\n    else\n        return Inf\n    end\nend","category":"page"}]
}
