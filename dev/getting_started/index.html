<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting Started with SciMLSensitivity: Differentiating ODE Solutions · SciMLSensitivity.jl</title><meta name="title" content="Getting Started with SciMLSensitivity: Differentiating ODE Solutions · SciMLSensitivity.jl"/><meta property="og:title" content="Getting Started with SciMLSensitivity: Differentiating ODE Solutions · SciMLSensitivity.jl"/><meta property="twitter:title" content="Getting Started with SciMLSensitivity: Differentiating ODE Solutions · SciMLSensitivity.jl"/><meta name="description" content="Documentation for SciMLSensitivity.jl."/><meta property="og:description" content="Documentation for SciMLSensitivity.jl."/><meta property="twitter:description" content="Documentation for SciMLSensitivity.jl."/><meta property="og:url" content="https://docs.sciml.ai/SciMLSensitivity/stable/getting_started/"/><meta property="twitter:url" content="https://docs.sciml.ai/SciMLSensitivity/stable/getting_started/"/><link rel="canonical" href="https://docs.sciml.ai/SciMLSensitivity/stable/getting_started/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="SciMLSensitivity.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">SciMLSensitivity.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers</a></li><li class="is-active"><a class="tocitem" href>Getting Started with SciMLSensitivity: Differentiating ODE Solutions</a><ul class="internal"><li><a class="tocitem" href="#Setup"><span>Setup</span></a></li><li><a class="tocitem" href="#Forward-Mode-Automatic-Differentiation-with-ForwardDiff.jl"><span>Forward-Mode Automatic Differentiation with ForwardDiff.jl</span></a></li><li><a class="tocitem" href="#Reverse-Mode-Automatic-Differentiation"><span>Reverse-Mode Automatic Differentiation</span></a></li><li><a class="tocitem" href="#When-Should-You-Use-Forward-or-Reverse-Mode?"><span>When Should You Use Forward or Reverse Mode?</span></a></li><li><a class="tocitem" href="#And-that-is-it!-Where-should-you-go-from-here?"><span>And that is it! Where should you go from here?</span></a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorials/parameter_estimation_ode/">Parameter Estimation of Ordinary Differential Equations</a></li><li><a class="tocitem" href="../tutorials/direct_sensitivity/">Direct Sensitivity Analysis Functionality</a></li><li><a class="tocitem" href="../tutorials/adjoint_continuous_functional/">Adjoint Sensitivity Analysis of Continuous Functionals</a></li><li><a class="tocitem" href="../tutorials/data_parallel/">Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching</a></li><li><a class="tocitem" href="../tutorials/chaotic_ode/">Sensitivity analysis for chaotic systems (shadowing methods)</a></li><li><input class="collapse-toggle" id="menuitem-3-6" type="checkbox"/><label class="tocitem" for="menuitem-3-6"><span class="docs-label">Training Techniques and Tips</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../tutorials/training_tips/local_minima/">Strategies to Avoid Local Minima</a></li><li><a class="tocitem" href="../tutorials/training_tips/divergence/">Handling Divergent and Unstable Trajectories</a></li><li><a class="tocitem" href="../tutorials/training_tips/multiple_nn/">Simultaneous Fitting of Multiple Neural Networks</a></li></ul></li></ul></li><li><a class="tocitem" href="../faq/">Frequently Asked Questions (FAQ)</a></li><li><span class="tocitem">Examples</span><ul><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Ordinary Differential Equations (ODEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../examples/ode/exogenous_input/">Handling Exogenous Input Signals</a></li><li><a class="tocitem" href="../examples/ode/prediction_error_method/">Prediction error method (PEM)</a></li><li><a class="tocitem" href="../examples/ode/second_order_adjoints/">Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis</a></li><li><a class="tocitem" href="../examples/ode/second_order_neural/">Neural Second Order Ordinary Differential Equation</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-2" type="checkbox"/><label class="tocitem" for="menuitem-5-2"><span class="docs-label">Neural Ordinary Differential Equations (Neural ODE)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../examples/neural_ode/neural_ode_flux/">Neural Ordinary Differential Equations with Flux</a></li><li><a class="tocitem" href="../examples/neural_ode/simplechains/">Faster Neural Ordinary Differential Equations with SimpleChains</a></li><li><a class="tocitem" href="../examples/neural_ode/minibatch/">Training a Neural Ordinary Differential Equation with Mini-Batching</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Stochastic Differential Equations (SDEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../examples/sde/optimization_sde/">Optimization of Stochastic Differential Equations</a></li><li><a class="tocitem" href="../examples/sde/SDE_control/">Controlling Stochastic Differential Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-4" type="checkbox"/><label class="tocitem" for="menuitem-5-4"><span class="docs-label">Delay Differential Equations (DDEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../examples/dde/delay_diffeq/">Delay Differential Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-5" type="checkbox"/><label class="tocitem" for="menuitem-5-5"><span class="docs-label">Partial Differential Equations (PDEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../examples/pde/pde_constrained/">Partial Differential Equation (PDE) Constrained Optimization</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-6" type="checkbox"/><label class="tocitem" for="menuitem-5-6"><span class="docs-label">Hybrid and Jump Equations</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../examples/hybrid_jump/hybrid_diffeq/">Training Neural Networks in Hybrid Differential Equations</a></li><li><a class="tocitem" href="../examples/hybrid_jump/bouncing_ball/">Bouncing Ball Hybrid ODE Optimization</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-7" type="checkbox"/><label class="tocitem" for="menuitem-5-7"><span class="docs-label">Bayesian Estimation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../examples/bayesian/turing_bayesian/">Bayesian Estimation of Differential Equations with Probabilistic Programming</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-8" type="checkbox"/><label class="tocitem" for="menuitem-5-8"><span class="docs-label">Optimal and Model Predictive Control</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../examples/optimal_control/optimal_control/">Solving Optimal Control Problems with Universal Differential Equations</a></li><li><a class="tocitem" href="../examples/optimal_control/feedback_control/">Universal Differential Equations for Neural Feedback Control</a></li></ul></li></ul></li><li><span class="tocitem">Manual and APIs</span><ul><li><a class="tocitem" href="../manual/differential_equation_sensitivities/">Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)</a></li><li><a class="tocitem" href="../manual/nonlinear_solve_sensitivities/">Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)</a></li><li><a class="tocitem" href="../manual/direct_forward_sensitivity/">Direct Forward Sensitivity Analysis of ODEs</a></li><li><a class="tocitem" href="../manual/direct_adjoint_sensitivities/">Direct Adjoint Sensitivities of Differential Equations</a></li></ul></li><li><a class="tocitem" href="../Benchmark/">Benchmarks</a></li><li><a class="tocitem" href="../sensitivity_math/">Sensitivity Math Details</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Getting Started with SciMLSensitivity: Differentiating ODE Solutions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Getting Started with SciMLSensitivity: Differentiating ODE Solutions</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/SciMLSensitivity.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/SciMLSensitivity.jl/blob/master/docs/src/getting_started.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="auto_diff"><a class="docs-heading-anchor" href="#auto_diff">Getting Started with SciMLSensitivity: Differentiating ODE Solutions</a><a id="auto_diff-1"></a><a class="docs-heading-anchor-permalink" href="#auto_diff" title="Permalink"></a></h1><div class="admonition is-category-warn"><header class="admonition-header">Warn</header><div class="admonition-body"><p>This tutorial assumes familiarity with DifferentialEquations.jl. If you are not familiar with DifferentialEquations.jl, please consult <a href="https://docs.sciml.ai/DiffEqDocs/stable/">the DifferentialEquations.jl documentation</a>.</p></div></div><p>SciMLSensitivity.jl is a tool for obtaining derivatives of equation solvers, such as differential equation solvers. These can be used in many ways, such as for analyzing the local sensitivities of a system or to compute the gradients of cost functions for model calibration and parameter estimation. In this tutorial, we will show how to make use of the tooling in SciMLSensitivity.jl to differentiate the ODE solvers.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>SciMLSensitivity.jl applies to all equation solvers of the SciML ecosystem, such as linear solvers, nonlinear solvers, nonlinear optimization, and more. This tutorial focuses on differential equations, so please see the other tutorials focused on these other SciMLProblem types as necessary. While the interface works similarly for all problem types, these tutorials will showcase the aspects that are special to a given problem.</p></div></div><h2 id="Setup"><a class="docs-heading-anchor" href="#Setup">Setup</a><a id="Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Setup" title="Permalink"></a></h2><p>Let&#39;s first define a differential equation we wish to solve. We will choose the Lotka-Volterra equation. This is done via DifferentialEquations.jl using:</p><pre><code class="language-julia hljs">using OrdinaryDiffEq

function lotka_volterra!(du, u, p, t)
    du[1] = dx = p[1] * u[1] - p[2] * u[1] * u[2]
    du[2] = dy = -p[3] * u[2] + p[4] * u[1] * u[2]
end
p = [1.5, 1.0, 3.0, 1.0];
u0 = [1.0; 1.0];
prob = ODEProblem(lotka_volterra!, u0, (0.0, 10.0), p)
sol = solve(prob, Tsit5(), reltol = 1e-6, abstol = 1e-6)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">retcode: Success
Interpolation: specialized 4th order &quot;free&quot; interpolation
t: 104-element Vector{Float64}:
  0.0
  0.022388671774158386
  0.06688455772214347
  0.12204057861057453
  0.1901739088897294
  0.2700958843663612
  0.3624899566568635
  0.4663498913963812
  0.5804932242040545
  0.7035670559596722
  ⋮
  9.363458919328917
  9.438253960677558
  9.514924295802581
  9.5948773310752
  9.679331554459784
  9.769895481406428
  9.868269555469228
  9.975570635758869
 10.0
u: 104-element Vector{Vector{Float64}}:
 [1.0, 1.0]
 [1.0117558257818347, 0.9563342092954507]
 [1.0384182072226116, 0.8758683249561677]
 [1.0774848848533785, 0.786875167161091]
 [1.134905782974095, 0.6915813161179499]
 [1.215349431258797, 0.5976695404830108]
 [1.3266197064716623, 0.509348518202066]
 [1.4766110896773839, 0.43133598821934244]
 [1.674672297975389, 0.36648541983542293]
 [1.9317152588988318, 0.31613609919958985]
 ⋮
 [1.280491754436697, 3.2111901642776264]
 [1.1439255035472293, 2.8083596202276446]
 [1.0502507522603817, 2.426494591751833]
 [0.9895322686715115, 2.070758390747169]
 [0.9563824267282467, 1.7446017637035662]
 [0.9484176841185465, 1.4490309505420775]
 [0.9660834157927825, 1.1849911555290313]
 [1.0122116806002588, 0.9547855316946803]
 [1.0263542618083945, 0.9096831916592041]</code></pre><p>Now let&#39;s differentiate the solution to this ODE using a few different automatic differentiation methods.</p><h2 id="Forward-Mode-Automatic-Differentiation-with-ForwardDiff.jl"><a class="docs-heading-anchor" href="#Forward-Mode-Automatic-Differentiation-with-ForwardDiff.jl">Forward-Mode Automatic Differentiation with ForwardDiff.jl</a><a id="Forward-Mode-Automatic-Differentiation-with-ForwardDiff.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Forward-Mode-Automatic-Differentiation-with-ForwardDiff.jl" title="Permalink"></a></h2><p>Let&#39;s say we need the derivative of the solution with respect to the initial condition <code>u0</code> and its parameters <code>p</code>. One of the simplest ways to do this is via ForwardDiff.jl. All one needs to do is to use <a href="https://juliadiff.org/ForwardDiff.jl/stable/">the ForwardDiff.jl library</a> to differentiate some function <code>f</code> which uses a differential equation <code>solve</code> inside of it. For example, let&#39;s say we want the derivative of the first component of the ODE solution with respect to these quantities at evenly spaced time points of <code>dt = 1</code>. We can compute this via:</p><pre><code class="language-julia hljs">using ForwardDiff

function f(x)
    _prob = remake(prob, u0 = x[1:2], p = x[3:end])
    solve(_prob, Tsit5(), reltol = 1e-6, abstol = 1e-6, saveat = 1)[1, :]
end
x = [u0; p]
dx = ForwardDiff.jacobian(f, x)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">11×6 Matrix{Float64}:
   1.0        0.0           0.0        0.0          0.0          0.0
   2.14463   -1.1848        2.54832   -1.1848       0.477483    -0.628218
  -5.88478    0.266338     -3.38158    0.266338     3.50594    -12.662
   0.691824   0.3718       -0.762033   0.3718      -0.0477691   -0.278507
   2.7989    -0.408784      3.80837   -0.408784     0.883252     0.914524
   4.0171    -1.65424      12.3007    -1.65424      3.95659     -2.0814
  -2.07453    0.851802     -7.0992     0.851802    -1.06005     -3.46806
   2.63655   -0.00114306    3.54679   -0.00114306   0.872776     1.30651
   7.88534   -0.610538     16.9144    -0.610538     4.3355       3.54215
 -16.5707     0.866198    -36.104      0.866198    -5.67502    -19.8444
   1.96602    0.188561      2.16063    0.188561     0.563199     0.939672</code></pre><p>Let&#39;s dig into what this is saying a bit. <code>x</code> is a vector which concatenates the initial condition and parameters, meaning that the first 2 values are the initial conditions and the last 4 are the parameters. We use the <code>remake</code> function to build a function <code>f(x)</code> which uses these new initial conditions and parameters to solve the differential equation and return the time series of the first component.</p><p>Then <code>ForwardDiff.jacobian(f,x)</code> computes the Jacobian of <code>f</code> with respect to <code>x</code>. The output <code>dx[i,j]</code> corresponds to the derivative of the solution of the first component at time <code>t=j-1</code> with respect to <code>x[i]</code>. For example, <code>dx[3,2]</code> is the derivative of the first component of the solution at time <code>t=1</code> with respect to <code>p[1]</code>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Since <a href="https://docs.sciml.ai/DiffEqDocs/stable/basics/faq/#What-does-tolerance-mean-and-how-much-error-should-I-expect">the global error is 1-2 orders of magnitude higher than the local error</a>, we use accuracies of 1e-6 (instead of the default 1e-3) to get reasonable sensitivities</p></div></div><h2 id="Reverse-Mode-Automatic-Differentiation"><a class="docs-heading-anchor" href="#Reverse-Mode-Automatic-Differentiation">Reverse-Mode Automatic Differentiation</a><a id="Reverse-Mode-Automatic-Differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Reverse-Mode-Automatic-Differentiation" title="Permalink"></a></h2><p><a href="https://docs.sciml.ai/SciMLSensitivity/stable/">The <code>solve</code> function is automatically compatible with AD systems like Zygote.jl</a> and thus there is no machinery that is necessary to use other than to put <code>solve</code> inside a function that is differentiated by Zygote. For example, the following computes the solution to an ODE and computes the gradient of a loss function (the sum of the ODE&#39;s output at each timepoint with dt=0.1) via the adjoint method:</p><pre><code class="language-julia hljs">using Zygote, SciMLSensitivity

function sum_of_solution(u0, p)
    _prob = remake(prob, u0 = u0, p = p)
    sum(solve(_prob, Tsit5(), reltol = 1e-6, abstol = 1e-6, saveat = 0.1))
end
du01, dp1 = Zygote.gradient(sum_of_solution, u0, p)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([-39.127737527250886, -8.787495434474875], [8.304244028181543, -159.48401961551914, 75.2031622989798, -339.19516313730287])</code></pre><p>Zygote.jl&#39;s automatic differentiation system is overloaded to allow SciMLSensitivity.jl to redefine the way the derivatives are computed, allowing trade-offs between numerical stability, memory, and compute performance, similar to how ODE solver algorithms are chosen.</p><h3 id="Choosing-Sensitivity-Algorithms"><a class="docs-heading-anchor" href="#Choosing-Sensitivity-Algorithms">Choosing Sensitivity Algorithms</a><a id="Choosing-Sensitivity-Algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Choosing-Sensitivity-Algorithms" title="Permalink"></a></h3><p>The algorithms for differentiation calculation are called <code>AbstractSensitivityAlgorithms</code>, or <code>sensealg</code>s for short. These are chosen by passing the <code>sensealg</code> keyword argument into solve. Let&#39;s demonstrate this by choosing the <code>QuadratureAdjoint</code> <code>sensealg</code> for the differentiation of this system:</p><pre><code class="language-julia hljs">function sum_of_solution(u0, p)
    _prob = remake(prob, u0 = u0, p = p)
    sum(solve(_prob, Tsit5(), reltol = 1e-6, abstol = 1e-6, saveat = 0.1,
        sensealg = GaussAdjoint()))
end
du01, dp1 = Zygote.gradient(sum_of_solution, u0, p)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([-39.12610324614078, -8.787925707602177], [8.307610397557578, -159.48459638034836, 75.2035429783264, -339.1934967614003])</code></pre><p>Here this computes the derivative of the output with respect to the initial condition and the derivative with respect to the parameters respectively using the <code>GaussAdjoint()</code>. For more information on the choices of sensitivity algorithms, see the <a href="../manual/differential_equation_sensitivities/#sensitivity_diffeq">reference documentation in choosing sensitivity algorithms</a>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>ForwardDiff.jl&#39;s automatic differentiation system ignores the sensitivity algorithms.</p></div></div><h2 id="When-Should-You-Use-Forward-or-Reverse-Mode?"><a class="docs-heading-anchor" href="#When-Should-You-Use-Forward-or-Reverse-Mode?">When Should You Use Forward or Reverse Mode?</a><a id="When-Should-You-Use-Forward-or-Reverse-Mode?-1"></a><a class="docs-heading-anchor-permalink" href="#When-Should-You-Use-Forward-or-Reverse-Mode?" title="Permalink"></a></h2><p>Good question! The simple answer is, if you are differentiating a system of fewer than 100 equations, use forward-mode, otherwise reverse-mode. But it can be a lot more complicated than that! For more information, see the <a href="../manual/differential_equation_sensitivities/#sensitivity_diffeq">reference documentation in choosing sensitivity algorithms</a>.</p><h2 id="And-that-is-it!-Where-should-you-go-from-here?"><a class="docs-heading-anchor" href="#And-that-is-it!-Where-should-you-go-from-here?">And that is it! Where should you go from here?</a><a id="And-that-is-it!-Where-should-you-go-from-here?-1"></a><a class="docs-heading-anchor-permalink" href="#And-that-is-it!-Where-should-you-go-from-here?" title="Permalink"></a></h2><p>That&#39;s all there is to the basics of differentiating the ODE solvers with SciMLSensitivity.jl. That said, check out the following tutorials to dig into more detail:</p><ul><li>See the <a href="../tutorials/parameter_estimation_ode/#odeparamestim">ODE parameter estimation tutorial</a> to learn how to fit the parameters of ODE systems</li><li>See the <a href="../tutorials/direct_sensitivity/#direct_sensitivity">direct sensitivity tutorial</a> to dig into the lower level API for more performance</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers</a><a class="docs-footer-nextpage" href="../tutorials/parameter_estimation_ode/">Parameter Estimation of Ordinary Differential Equations »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Tuesday 19 November 2024 01:07">Tuesday 19 November 2024</span>. Using Julia version 1.11.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
