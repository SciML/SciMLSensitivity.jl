<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Partial Differential Equation (PDE) Constrained Optimization · SciMLSensitivity.jl</title><meta name="title" content="Partial Differential Equation (PDE) Constrained Optimization · SciMLSensitivity.jl"/><meta property="og:title" content="Partial Differential Equation (PDE) Constrained Optimization · SciMLSensitivity.jl"/><meta property="twitter:title" content="Partial Differential Equation (PDE) Constrained Optimization · SciMLSensitivity.jl"/><meta name="description" content="Documentation for SciMLSensitivity.jl."/><meta property="og:description" content="Documentation for SciMLSensitivity.jl."/><meta property="twitter:description" content="Documentation for SciMLSensitivity.jl."/><meta property="og:url" content="https://docs.sciml.ai/SciMLSensitivity/stable/examples/pde/pde_constrained/"/><meta property="twitter:url" content="https://docs.sciml.ai/SciMLSensitivity/stable/examples/pde/pde_constrained/"/><link rel="canonical" href="https://docs.sciml.ai/SciMLSensitivity/stable/examples/pde/pde_constrained/"/><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.png" alt="SciMLSensitivity.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">SciMLSensitivity.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers</a></li><li><a class="tocitem" href="../../../getting_started/">Getting Started with SciMLSensitivity: Differentiating ODE Solutions</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../../tutorials/parameter_estimation_ode/">Parameter Estimation of Ordinary Differential Equations</a></li><li><a class="tocitem" href="../../../tutorials/direct_sensitivity/">Direct Sensitivity Analysis Functionality</a></li><li><a class="tocitem" href="../../../tutorials/adjoint_continuous_functional/">Adjoint Sensitivity Analysis of Continuous Functionals</a></li><li><a class="tocitem" href="../../../tutorials/data_parallel/">Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching</a></li><li><a class="tocitem" href="../../../tutorials/chaotic_ode/">Sensitivity analysis for chaotic systems (shadowing methods)</a></li><li><input class="collapse-toggle" id="menuitem-3-6" type="checkbox"/><label class="tocitem" for="menuitem-3-6"><span class="docs-label">Training Techniques and Tips</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../tutorials/training_tips/local_minima/">Strategies to Avoid Local Minima</a></li><li><a class="tocitem" href="../../../tutorials/training_tips/divergence/">Handling Divergent and Unstable Trajectories</a></li><li><a class="tocitem" href="../../../tutorials/training_tips/multiple_nn/">Simultaneous Fitting of Multiple Neural Networks</a></li></ul></li></ul></li><li><span class="tocitem">Examples</span><ul><li><input class="collapse-toggle" id="menuitem-4-1" type="checkbox"/><label class="tocitem" for="menuitem-4-1"><span class="docs-label">Ordinary Differential Equations (ODEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../ode/exogenous_input/">Handling Exogenous Input Signals</a></li><li><a class="tocitem" href="../../ode/prediction_error_method/">Prediction error method (PEM)</a></li><li><a class="tocitem" href="../../ode/second_order_adjoints/">Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis</a></li><li><a class="tocitem" href="../../ode/second_order_neural/">Neural Second Order Ordinary Differential Equation</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox"/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Neural Ordinary Differential Equations (Neural ODE)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../neural_ode/neural_ode_flux/">Neural Ordinary Differential Equations with Flux</a></li><li><a class="tocitem" href="../../neural_ode/simplechains/">Neural Ordinary Differential Equations with SimpleChains</a></li><li><a class="tocitem" href="../../neural_ode/neural_gde/">Neural Graph Differential Equations</a></li><li><a class="tocitem" href="../../neural_ode/minibatch/">Training a Neural Ordinary Differential Equation with Mini-Batching</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Stochastic Differential Equations (SDEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sde/optimization_sde/">Optimization of Stochastic Differential Equations</a></li><li><a class="tocitem" href="../../sde/SDE_control/">Controlling Stochastic Differential Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Delay Differential Equations (DDEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../dde/delay_diffeq/">Delay Differential Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox"/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Differential-Algebraic Equations (DAEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../dae/physical_constraints/">Enforcing Physical Constraints via Universal Differential-Algebraic Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-6" type="checkbox" checked/><label class="tocitem" for="menuitem-4-6"><span class="docs-label">Partial Differential Equations (PDEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Partial Differential Equation (PDE) Constrained Optimization</a><ul class="internal"><li><a class="tocitem" href="#Step-by-step-Description"><span>Step-by-step Description</span></a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-7" type="checkbox"/><label class="tocitem" for="menuitem-4-7"><span class="docs-label">Hybrid and Jump Equations</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../hybrid_jump/hybrid_diffeq/">Training Neural Networks in Hybrid Differential Equations</a></li><li><a class="tocitem" href="../../hybrid_jump/bouncing_ball/">Bouncing Ball Hybrid ODE Optimization</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-8" type="checkbox"/><label class="tocitem" for="menuitem-4-8"><span class="docs-label">Bayesian Estimation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/turing_bayesian/">Bayesian Estimation of Differential Equations with Probabilistic Programming</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-9" type="checkbox"/><label class="tocitem" for="menuitem-4-9"><span class="docs-label">Optimal and Model Predictive Control</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../optimal_control/optimal_control/">Solving Optimal Control Problems with Universal Differential Equations</a></li><li><a class="tocitem" href="../../optimal_control/feedback_control/">Universal Differential Equations for Neural Feedback Control</a></li></ul></li></ul></li><li><span class="tocitem">Manual and APIs</span><ul><li><a class="tocitem" href="../../../manual/differential_equation_sensitivities/">Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)</a></li><li><a class="tocitem" href="../../../manual/nonlinear_solve_sensitivities/">Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)</a></li><li><a class="tocitem" href="../../../manual/direct_forward_sensitivity/">Direct Forward Sensitivity Analysis of ODEs</a></li><li><a class="tocitem" href="../../../manual/direct_adjoint_sensitivities/">Direct Adjoint Sensitivities of Differential Equations</a></li></ul></li><li><a class="tocitem" href="../../../Benchmark/">Benchmarks</a></li><li><a class="tocitem" href="../../../sensitivity_math/">Sensitivity Math Details</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li><a class="is-disabled">Partial Differential Equations (PDEs)</a></li><li class="is-active"><a href>Partial Differential Equation (PDE) Constrained Optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Partial Differential Equation (PDE) Constrained Optimization</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/DiffEqSensitivity.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/DiffEqSensitivity.jl/blob/master/docs/src/examples/pde/pde_constrained.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Partial-Differential-Equation-(PDE)-Constrained-Optimization"><a class="docs-heading-anchor" href="#Partial-Differential-Equation-(PDE)-Constrained-Optimization">Partial Differential Equation (PDE) Constrained Optimization</a><a id="Partial-Differential-Equation-(PDE)-Constrained-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Partial-Differential-Equation-(PDE)-Constrained-Optimization" title="Permalink"></a></h1><p>This example uses a prediction model to optimize the one-dimensional Heat Equation. (Step-by-step description below)</p><pre><code class="language-julia hljs">using DelimitedFiles, Plots
using DifferentialEquations, Optimization, OptimizationPolyalgorithms, Zygote

# Problem setup parameters:
Lx = 10.0
x = 0.0:0.01:Lx
dx = x[2] - x[1]
Nx = size(x)

u0 = exp.(-(x .- 3.0) .^ 2) # I.C

## Problem Parameters
p = [1.0, 1.0]    # True solution parameters
xtrs = [dx, Nx]      # Extra parameters
dt = 0.40 * dx^2    # CFL condition
t0, tMax = 0.0, 1000 * dt
tspan = (t0, tMax)
t = t0:dt:tMax;

## Definition of Auxiliary functions
function ddx(u, dx)
    &quot;&quot;&quot;
    2nd order Central difference for 1st degree derivative
    &quot;&quot;&quot;
    return [[zero(eltype(u))]; (u[3:end] - u[1:(end - 2)]) ./ (2.0 * dx); [zero(eltype(u))]]
end

function d2dx(u, dx)
    &quot;&quot;&quot;
    2nd order Central difference for 2nd degree derivative
    &quot;&quot;&quot;
    return [[zero(eltype(u))];
        (u[3:end] - 2.0 .* u[2:(end - 1)] + u[1:(end - 2)]) ./ (dx^2);
        [zero(eltype(u))]]
end

## ODE description of the Physics:
function heat(u, p, t)
    # Model parameters
    a0, a1 = p
    dx, Nx = xtrs #[1.0,3.0,0.125,100]
    return 2.0 * a0 .* u + a1 .* d2dx(u, dx)
end

# Testing Solver on linear PDE
prob = ODEProblem(heat, u0, tspan, p)
sol = solve(prob, Tsit5(), dt = dt, saveat = t);

plot(x, sol.u[1], lw = 3, label = &quot;t0&quot;, size = (800, 500))
plot!(x, sol.u[end], lw = 3, ls = :dash, label = &quot;tMax&quot;)

ps = [0.1, 0.2];   # Initial guess for model parameters
function predict(θ)
    Array(solve(prob, Tsit5(), p = θ, dt = dt, saveat = t))
end

## Defining Loss function
function loss(θ)
    pred = predict(θ)
    l = predict(θ) - sol
    return sum(abs2, l), pred # Mean squared error
end

l, pred = loss(ps)
size(pred), size(sol), size(t) # Checking sizes

LOSS = []                              # Loss accumulator
PRED = []                              # prediction accumulator
PARS = []                              # parameters accumulator

callback = function (θ, l, pred) #callback function to observe training
    display(l)
    append!(PRED, [pred])
    append!(LOSS, l)
    append!(PARS, [θ])
    false
end

callback(ps, loss(ps)...) # Testing callback function

# Let see prediction vs. Truth
scatter(sol[:, end], label = &quot;Truth&quot;, size = (800, 500))
plot!(PRED[end][:, end], lw = 2, label = &quot;Prediction&quot;)

adtype = Optimization.AutoZygote()
optf = Optimization.OptimizationFunction((x, p) -&gt; loss(x), adtype)

optprob = Optimization.OptimizationProblem(optf, ps)
res = Optimization.solve(optprob, PolyOpt(), callback = callback)
@show res.u # returns [0.999999999613485, 0.9999999991343996]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 1.0000000000000002
 0.9999999999999981</code></pre><h2 id="Step-by-step-Description"><a class="docs-heading-anchor" href="#Step-by-step-Description">Step-by-step Description</a><a id="Step-by-step-Description-1"></a><a class="docs-heading-anchor-permalink" href="#Step-by-step-Description" title="Permalink"></a></h2><h3 id="Load-Packages"><a class="docs-heading-anchor" href="#Load-Packages">Load Packages</a><a id="Load-Packages-1"></a><a class="docs-heading-anchor-permalink" href="#Load-Packages" title="Permalink"></a></h3><pre><code class="language-julia hljs">using DelimitedFiles, Plots
using DifferentialEquations, Optimization, OptimizationPolyalgorithms,
    Zygote</code></pre><h3 id="Parameters"><a class="docs-heading-anchor" href="#Parameters">Parameters</a><a id="Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Parameters" title="Permalink"></a></h3><p>First, we set up the 1-dimensional space over which our equations will be evaluated. <code>x</code> spans <strong>from 0.0 to 10.0</strong> in steps of <strong>0.01</strong>; <code>t</code> spans <strong>from 0.00 to 0.04</strong> in steps of <strong>4.0e-5</strong>.</p><pre><code class="language-julia hljs"># Problem setup parameters:
Lx = 10.0
x = 0.0:0.01:Lx
dx = x[2] - x[1]
Nx = size(x)

u0 = exp.(-(x .- 3.0) .^ 2) # I.C

## Problem Parameters
p = [1.0, 1.0]    # True solution parameters
xtrs = [dx, Nx]      # Extra parameters
dt = 0.40 * dx^2    # CFL condition
t0, tMax = 0.0, 1000 * dt
tspan = (t0, tMax)
t = t0:dt:tMax;</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.0:4.0e-5:0.04</code></pre><p>In plain terms, the quantities that were defined are:</p><ul><li><code>x</code> (to <code>Lx</code>) spans the specified 1D space</li><li><code>dx</code> = distance between two points</li><li><code>Nx</code> = total size of space</li><li><code>u0</code> = initial condition</li><li><code>p</code> = true solution</li><li><code>xtrs</code> = convenient grouping of <code>dx</code> and <code>Nx</code> into Array</li><li><code>dt</code> = time distance between two points</li><li><code>t</code> (<code>t0</code> to <code>tMax</code>) spans the specified time frame</li><li><code>tspan</code> = span of <code>t</code></li></ul><h3 id="Auxiliary-Functions"><a class="docs-heading-anchor" href="#Auxiliary-Functions">Auxiliary Functions</a><a id="Auxiliary-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Auxiliary-Functions" title="Permalink"></a></h3><p>We then define two functions to compute the derivatives numerically. The <strong>Central Difference</strong> is used in both the 1st and 2nd degree derivatives.</p><pre><code class="language-julia hljs">## Definition of Auxiliary functions
function ddx(u, dx)
    &quot;&quot;&quot;
    2nd order Central difference for 1st degree derivative
    &quot;&quot;&quot;
    return [[zero(eltype(u))]; (u[3:end] - u[1:(end - 2)]) ./ (2.0 * dx); [zero(eltype(u))]]
end

function d2dx(u, dx)
    &quot;&quot;&quot;
    2nd order Central difference for 2nd degree derivative
    &quot;&quot;&quot;
    return [[zero(eltype(u))];
        (u[3:end] - 2.0 .* u[2:(end - 1)] + u[1:(end - 2)]) ./ (dx^2);
        [zero(eltype(u))]]
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">d2dx (generic function with 1 method)</code></pre><h3 id="Heat-Differential-Equation"><a class="docs-heading-anchor" href="#Heat-Differential-Equation">Heat Differential Equation</a><a id="Heat-Differential-Equation-1"></a><a class="docs-heading-anchor-permalink" href="#Heat-Differential-Equation" title="Permalink"></a></h3><p>Next, we set up our desired set of equations in order to define our problem.</p><pre><code class="language-julia hljs">## ODE description of the Physics:
function heat(u, p, t)
    # Model parameters
    a0, a1 = p
    dx, Nx = xtrs #[1.0,3.0,0.125,100]
    return 2.0 * a0 .* u + a1 .* d2dx(u, dx)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">heat (generic function with 1 method)</code></pre><h3 id="Solve-and-Plot-Ground-Truth"><a class="docs-heading-anchor" href="#Solve-and-Plot-Ground-Truth">Solve and Plot Ground Truth</a><a id="Solve-and-Plot-Ground-Truth-1"></a><a class="docs-heading-anchor-permalink" href="#Solve-and-Plot-Ground-Truth" title="Permalink"></a></h3><p>We then solve and plot our partial differential equation. This is the true solution, which we will compare to further on.</p><pre><code class="language-julia hljs"># Testing Solver on linear PDE
prob = ODEProblem(heat, u0, tspan, p)
sol = solve(prob, Tsit5(), dt = dt, saveat = t);

plot(x, sol.u[1], lw = 3, label = &quot;t0&quot;, size = (800, 500))
plot!(x, sol.u[end], lw = 3, ls = :dash, label = &quot;tMax&quot;)</code></pre><img src="9414e0f5.svg" alt="Example block output"/><h3 id="Building-the-Prediction-Model"><a class="docs-heading-anchor" href="#Building-the-Prediction-Model">Building the Prediction Model</a><a id="Building-the-Prediction-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Building-the-Prediction-Model" title="Permalink"></a></h3><p>Now we start building our prediction model to try to obtain the values <code>p</code>. We make an initial guess for the parameters and name it <code>ps</code> here. The <code>predict</code> function is a non-linear transformation in one layer using <code>solve</code>. If unfamiliar with the concept, refer to <a href="https://julialang.org/blog/2019/01/fluxdiffeq/">here</a>.</p><pre><code class="language-julia hljs">ps = [0.1, 0.2];   # Initial guess for model parameters
function predict(θ)
    Array(solve(prob, Tsit5(), p = θ, dt = dt, saveat = t))
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">predict (generic function with 1 method)</code></pre><h3 id="Train-Parameters"><a class="docs-heading-anchor" href="#Train-Parameters">Train Parameters</a><a id="Train-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Train-Parameters" title="Permalink"></a></h3><p>Training our model requires a <strong>loss function</strong>, an <strong>optimizer</strong>, and a <strong>callback function</strong> to display the progress.</p><h4 id="Loss"><a class="docs-heading-anchor" href="#Loss">Loss</a><a id="Loss-1"></a><a class="docs-heading-anchor-permalink" href="#Loss" title="Permalink"></a></h4><p>We first make our predictions based on the current values of our parameters <code>ps</code>, then take the difference between the predicted solution and the truth above. For the loss, we use the <strong>mean squared error</strong>.</p><pre><code class="language-julia hljs">## Defining Loss function
function loss(θ)
    pred = predict(θ)
    l = predict(θ) - sol
    return sum(abs2, l), pred # Mean squared error
end

l, pred = loss(ps)
size(pred), size(sol), size(t) # Checking sizes</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((1001, 1001), (1001, 1001), (1001,))</code></pre><h4 id="Optimizer"><a class="docs-heading-anchor" href="#Optimizer">Optimizer</a><a id="Optimizer-1"></a><a class="docs-heading-anchor-permalink" href="#Optimizer" title="Permalink"></a></h4><p>The optimizers <code>ADAM</code> with a learning rate of 0.01 and <code>BFGS</code> are directly passed in training (see below)</p><h4 id="Callback"><a class="docs-heading-anchor" href="#Callback">Callback</a><a id="Callback-1"></a><a class="docs-heading-anchor-permalink" href="#Callback" title="Permalink"></a></h4><p>The callback function displays the loss during training. We also keep a history of the loss, the previous predictions and the previous parameters with <code>LOSS</code>, <code>PRED</code> and <code>PARS</code> accumulators.</p><pre><code class="language-julia hljs">LOSS = []                              # Loss accumulator
PRED = []                              # prediction accumulator
PARS = []                              # parameters accumulator

callback = function (θ, l, pred) #callback function to observe training
    display(l)
    append!(PRED, [pred])
    append!(LOSS, l)
    append!(PARS, [θ])
    false
end

callback(ps, loss(ps)...) # Testing callback function</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">false</code></pre><h3 id="Plotting-Prediction-vs-Ground-Truth"><a class="docs-heading-anchor" href="#Plotting-Prediction-vs-Ground-Truth">Plotting Prediction vs Ground Truth</a><a id="Plotting-Prediction-vs-Ground-Truth-1"></a><a class="docs-heading-anchor-permalink" href="#Plotting-Prediction-vs-Ground-Truth" title="Permalink"></a></h3><p>The scatter points plotted here are the ground truth obtained from the actual solution we solved for above. The solid line represents our prediction. The goal is for both to overlap almost perfectly when the PDE finishes its training and the loss is close to 0.</p><pre><code class="language-julia hljs"># Let see prediction vs. Truth
scatter(sol[:, end], label = &quot;Truth&quot;, size = (800, 500))
plot!(PRED[end][:, end], lw = 2, label = &quot;Prediction&quot;)</code></pre><img src="e469856e.svg" alt="Example block output"/><h3 id="Train"><a class="docs-heading-anchor" href="#Train">Train</a><a id="Train-1"></a><a class="docs-heading-anchor-permalink" href="#Train" title="Permalink"></a></h3><p>The parameters are trained using <code>Optimization.solve</code> and adjoint sensitivities. The resulting best parameters are stored in <code>res</code> and <code>res.u</code> returns the parameters that minimize the cost function.</p><pre><code class="language-julia hljs">adtype = Optimization.AutoZygote()
optf = Optimization.OptimizationFunction((x, p) -&gt; loss(x), adtype)

optprob = Optimization.OptimizationProblem(optf, ps)
res = Optimization.solve(optprob, PolyOpt(), callback = callback)
@show res.u # returns [0.999999999613485, 0.9999999991343996]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 1.0000000000000002
 0.9999999999999981</code></pre><p>We successfully predict the final <code>ps</code> to be equal to <strong>[0.999999999999975, 1.0000000000000213]</strong> vs the true solution of <code>p</code> = <strong>[1.0, 1.0]</strong></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../dae/physical_constraints/">« Enforcing Physical Constraints via Universal Differential-Algebraic Equations</a><a class="docs-footer-nextpage" href="../../hybrid_jump/hybrid_diffeq/">Training Neural Networks in Hybrid Differential Equations »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.1 on <span class="colophon-date" title="Tuesday 17 October 2023 11:25">Tuesday 17 October 2023</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
