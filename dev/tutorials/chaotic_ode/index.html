<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Sensitivity analysis for chaotic systems (shadowing methods) · SciMLSensitivity.jl</title><meta name="title" content="Sensitivity analysis for chaotic systems (shadowing methods) · SciMLSensitivity.jl"/><meta property="og:title" content="Sensitivity analysis for chaotic systems (shadowing methods) · SciMLSensitivity.jl"/><meta property="twitter:title" content="Sensitivity analysis for chaotic systems (shadowing methods) · SciMLSensitivity.jl"/><meta name="description" content="Documentation for SciMLSensitivity.jl."/><meta property="og:description" content="Documentation for SciMLSensitivity.jl."/><meta property="twitter:description" content="Documentation for SciMLSensitivity.jl."/><meta property="og:url" content="https://docs.sciml.ai/SciMLSensitivity/stable/tutorials/chaotic_ode/"/><meta property="twitter:url" content="https://docs.sciml.ai/SciMLSensitivity/stable/tutorials/chaotic_ode/"/><link rel="canonical" href="https://docs.sciml.ai/SciMLSensitivity/stable/tutorials/chaotic_ode/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="SciMLSensitivity.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">SciMLSensitivity.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">SciMLSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers</a></li><li><a class="tocitem" href="../../getting_started/">Getting Started with SciMLSensitivity: Differentiating ODE Solutions</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../parameter_estimation_ode/">Parameter Estimation of Ordinary Differential Equations</a></li><li><a class="tocitem" href="../direct_sensitivity/">Direct Sensitivity Analysis Functionality</a></li><li><a class="tocitem" href="../adjoint_continuous_functional/">Adjoint Sensitivity Analysis of Continuous Functionals</a></li><li><a class="tocitem" href="../data_parallel/">Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching</a></li><li class="is-active"><a class="tocitem" href>Sensitivity analysis for chaotic systems (shadowing methods)</a></li><li><input class="collapse-toggle" id="menuitem-3-6" type="checkbox"/><label class="tocitem" for="menuitem-3-6"><span class="docs-label">Training Techniques and Tips</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../training_tips/local_minima/">Strategies to Avoid Local Minima</a></li><li><a class="tocitem" href="../training_tips/divergence/">Handling Divergent and Unstable Trajectories</a></li><li><a class="tocitem" href="../training_tips/multiple_nn/">Simultaneous Fitting of Multiple Neural Networks</a></li></ul></li></ul></li><li><span class="tocitem">Examples</span><ul><li><input class="collapse-toggle" id="menuitem-4-1" type="checkbox"/><label class="tocitem" for="menuitem-4-1"><span class="docs-label">Ordinary Differential Equations (ODEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/ode/exogenous_input/">Handling Exogenous Input Signals</a></li><li><a class="tocitem" href="../../examples/ode/prediction_error_method/">Prediction error method (PEM)</a></li><li><a class="tocitem" href="../../examples/ode/second_order_adjoints/">Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis</a></li><li><a class="tocitem" href="../../examples/ode/second_order_neural/">Neural Second Order Ordinary Differential Equation</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox"/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Neural Ordinary Differential Equations (Neural ODE)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/neural_ode/neural_ode_flux/">Neural Ordinary Differential Equations with Flux</a></li><li><a class="tocitem" href="../../examples/neural_ode/simplechains/">Faster Neural Ordinary Differential Equations with SimpleChains</a></li><li><a class="tocitem" href="../../examples/neural_ode/neural_gde/">Neural Graph Differential Equations</a></li><li><a class="tocitem" href="../../examples/neural_ode/minibatch/">Training a Neural Ordinary Differential Equation with Mini-Batching</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Stochastic Differential Equations (SDEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/sde/optimization_sde/">Optimization of Stochastic Differential Equations</a></li><li><a class="tocitem" href="../../examples/sde/SDE_control/">Controlling Stochastic Differential Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Delay Differential Equations (DDEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/dde/delay_diffeq/">Delay Differential Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox"/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Differential-Algebraic Equations (DAEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/dae/physical_constraints/">Enforcing Physical Constraints via Universal Differential-Algebraic Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-6" type="checkbox"/><label class="tocitem" for="menuitem-4-6"><span class="docs-label">Partial Differential Equations (PDEs)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/pde/pde_constrained/">Partial Differential Equation (PDE) Constrained Optimization</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-7" type="checkbox"/><label class="tocitem" for="menuitem-4-7"><span class="docs-label">Hybrid and Jump Equations</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/hybrid_jump/hybrid_diffeq/">Training Neural Networks in Hybrid Differential Equations</a></li><li><a class="tocitem" href="../../examples/hybrid_jump/bouncing_ball/">Bouncing Ball Hybrid ODE Optimization</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-8" type="checkbox"/><label class="tocitem" for="menuitem-4-8"><span class="docs-label">Bayesian Estimation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/bayesian/turing_bayesian/">Bayesian Estimation of Differential Equations with Probabilistic Programming</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-9" type="checkbox"/><label class="tocitem" for="menuitem-4-9"><span class="docs-label">Optimal and Model Predictive Control</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../examples/optimal_control/optimal_control/">Solving Optimal Control Problems with Universal Differential Equations</a></li><li><a class="tocitem" href="../../examples/optimal_control/feedback_control/">Universal Differential Equations for Neural Feedback Control</a></li></ul></li></ul></li><li><span class="tocitem">Manual and APIs</span><ul><li><a class="tocitem" href="../../manual/differential_equation_sensitivities/">Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)</a></li><li><a class="tocitem" href="../../manual/nonlinear_solve_sensitivities/">Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)</a></li><li><a class="tocitem" href="../../manual/direct_forward_sensitivity/">Direct Forward Sensitivity Analysis of ODEs</a></li><li><a class="tocitem" href="../../manual/direct_adjoint_sensitivities/">Direct Adjoint Sensitivities of Differential Equations</a></li></ul></li><li><a class="tocitem" href="../../Benchmark/">Benchmarks</a></li><li><a class="tocitem" href="../../sensitivity_math/">Sensitivity Math Details</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Sensitivity analysis for chaotic systems (shadowing methods)</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Sensitivity analysis for chaotic systems (shadowing methods)</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/SciMLSensitivity.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/SciMLSensitivity.jl/blob/master/docs/src/tutorials/chaotic_ode.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="shadowing_methods"><a class="docs-heading-anchor" href="#shadowing_methods">Sensitivity analysis for chaotic systems (shadowing methods)</a><a id="shadowing_methods-1"></a><a class="docs-heading-anchor-permalink" href="#shadowing_methods" title="Permalink"></a></h1><p>Let us define the instantaneous objective <span>$g(u,p)$</span> which depends on the state <code>u</code> and the parameter <code>p</code> of the differential equation. Then, if the objective is a long-time average quantity</p><p class="math-container">\[\langle g \rangle_∞ = \lim_{T \rightarrow ∞} \langle g \rangle_T,\]</p><p>where</p><p class="math-container">\[\langle g \rangle_T = \frac{1}{T} \int_0^T g(u,p) \text{d}t,\]</p><p>under the assumption of ergodicity, <span>$\langle g \rangle_∞$</span> only depends on <code>p</code>.</p><p>In the case of chaotic systems, the trajectories diverge with <span>$O(1)$</span> error. This can be seen, for instance, when solving the <a href="https://en.wikipedia.org/wiki/Lorenz_system">Lorenz system</a> at <code>1e-14</code> tolerances with 9th order integrators and a small machine-epsilon perturbation:</p><pre><code class="language-julia hljs">using OrdinaryDiffEq, SciMLSensitivity, Zygote, Plots

function lorenz!(du, u, p, t)
    du[1] = 10 * (u[2] - u[1])
    du[2] = u[1] * (p[1] - u[3]) - u[2]
    du[3] = u[1] * u[2] - (8 // 3) * u[3]
end

p = [28.0]
tspan = (0.0, 100.0)
u0 = [1.0, 0.0, 0.0]
prob = ODEProblem(lorenz!, u0, tspan, p)
sol = solve(prob, Vern9(), abstol = 1e-14, reltol = 1e-14)
sol2 = solve(prob, Vern9(), abstol = 1e-14 + eps(Float64), reltol = 1e-14)
pl1 = plot(sol, vars = (1, 2, 3), legend = true,
  label = &quot;sol&quot;,
  labelfontsize = 20,
  lw = 2,
  xlabel = &quot;x&quot;, ylabel = &quot;y&quot;, zlabel = &quot;z&quot;,
  margin = 4Plots.mm
)
plot!(pl1, sol2, vars = (1, 2, 3), label = &quot;sol2&quot;, xlims = (-25, 30), ylims = (-30, 30), zlims = (5, 49)
)</code></pre><img src="3344934f.svg" alt="Example block output"/><p>More formally, such chaotic behavior can be analyzed using tools from <a href="https://docs.sciml.ai/DiffEqCallbacks/stable/uncertainty_quantification/">uncertainty quantification</a>. This effect of diverging trajectories is known as the butterfly effect, and can be formulated as &quot;most (small) perturbations on initial conditions or parameters lead to new trajectories diverging exponentially fast from the original trajectory&quot;.</p><p>The latter statement can be roughly translated to the level of sensitivity calculation as follows: &quot;For most initial conditions, the (homogeneous) tangent solutions grow exponentially fast.&quot;</p><p>To compute derivatives of an objective <span>$\langle g \rangle_∞$</span> with respect to the parameters <code>p</code> of a chaotic system, one thus encounters that “traditional” forward and adjoint sensitivity methods diverge because the tangent space diverges with a rate given by the Lyapunov exponent. Taking the average of these derivative can then also fail, i.e., one finds that the average derivative is not the derivative of the average.</p><p>Although numerically computed chaotic trajectories diverge from the true/original trajectory, the <a href="http://mathworld.wolfram.com/ShadowingTheorem.html">shadowing theorem</a> guarantees that there exists an errorless trajectory with a slightly different initial condition that stays near (“shadows”) the numerically computed one, see, e.g, the <a href="https://frankschae.github.io/post/shadowing/">blog post</a> or the <a href="https://arxiv.org/abs/1611.00880">non-intrusive least squares shadowing paper</a> for more details. Essentially, the idea is to replace the ill-conditioned ODE by a well-conditioned optimization problem. Shadowing methods use the shadowing theorem within a renormalization procedure to distill the long-time effect from the joint observation of the long-time and the butterfly effect. This allows us to accurately compute derivatives w.r.t. the long-time average quantities.</p><p>The following <code>sensealg</code> choices exist</p><ul><li><code>ForwardLSS(;LSSregularizer=TimeDilation(10.0,0.0,0.0),g=nothing,ADKwargs...)</code>: An implementation of the forward <a href="https://arxiv.org/abs/1204.0159">least square shadowing</a> method. For <code>LSSregularizer</code>, one can choose between two different windowing options, <code>TimeDilation</code> (default) with weight <code>10.0</code> and <code>CosWindowing</code>, and <code>Cos2Windowing</code>.</li><li><code>AdjointLSS(;LSSRegularizer=TimeDilation(10.0, 0.0, 0.0),g=nothing,ADKwargs...)</code>: An implementation of the adjoint-mode <a href="https://arxiv.org/abs/1204.0159">least square shadowing</a> method. <code>10.0</code> controls the weight of the time dilation term in <code>AdjointLSS</code>.</li><li><code>NILSS(nseg,nstep;nus=nothing,rng=Xorshifts.Xoroshiro128Plus(rand(UInt64)),g=nothing,ADKwargs...)</code>: An implementation of the <a href="https://arxiv.org/abs/1611.00880">non-intrusive least squares shadowing (NILSS)</a> method. Here, <code>nseg</code> is the number of segments, <code>nstep</code> is the number of steps per segment, and <code>nus</code> is the number of unstable Lyapunov exponents.</li><li><code>NILSAS(nseg,nstep,M=nothing;rng =Xorshifts.Xoroshiro128Plus(rand(UInt64)), adjoint_sensealg=BacksolveAdjoint(autojacvec=ReverseDiffVJP()),g=nothing,ADKwargs...)</code>: An implementation of the <a href="https://arxiv.org/abs/1801.08674">non-intrusive least squares adjoint shadowing (NILSAS)</a> method. <code>nseg</code> is the number of segments. <code>nstep</code> is the number of steps per segment, <code>M &gt;= nus + 1</code> has to be provided, where <code>nus</code> is the number of unstable covariant Lyapunov vectors.</li></ul><p>Recommendation: Since the computational and memory costs of <code>NILSS()</code> scale with the number of positive (unstable) Lyapunov, it is typically less expensive than <code>ForwardLSS()</code>. <code>AdjointLSS()</code> and <code>NILSAS()</code> are favorable for a large number of system parameters.</p><p>As an example, for the Lorenz system with <code>g(u,p,t) = u[3]</code>, i.e., the <span>$z$</span> coordinate, as the instantaneous objective, we can use the direct interface by passing <code>ForwardLSS</code> as the <code>sensealg</code>:</p><pre><code class="language-julia hljs">function lorenz!(du, u, p, t)
    du[1] = p[1] * (u[2] - u[1])
    du[2] = u[1] * (p[2] - u[3]) - u[2]
    du[3] = u[1] * u[2] - p[3] * u[3]
end

p = [10.0, 28.0, 8 / 3]

tspan_init = (0.0, 30.0)
tspan_attractor = (30.0, 50.0)
u0 = rand(3)
prob_init = ODEProblem(lorenz!, u0, tspan_init, p)
sol_init = solve(prob_init, Tsit5())
prob_attractor = ODEProblem(lorenz!, sol_init[end], tspan_attractor, p)

g(u, p, t) = u[end]

function G(p)
    _prob = remake(prob_attractor, p = p)
    _sol = solve(_prob, Vern9(), abstol = 1e-14, reltol = 1e-14, saveat = 0.01,
        sensealg = ForwardLSS(g = g))
    sum(getindex.(_sol.u, 3))
end
dp1 = Zygote.gradient(p -&gt; G(p), p)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([0.13201076658569133, 1.0115436367249868, -1.636943828230061],)</code></pre><p>Alternatively, we can define the <code>ForwardLSSProblem</code> and solve it via <code>shadow_forward</code> as follows:</p><pre><code class="language-julia hljs">sol_attractor = solve(prob_attractor, Vern9(), abstol = 1e-14, reltol = 1e-14)
lss_problem = ForwardLSSProblem(sol_attractor, ForwardLSS(g = g))
resfw = shadow_forward(lss_problem)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Float64}:
  0.12014551728125025
  1.026535095455568
 -1.4085885979695627</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../data_parallel/">« Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching</a><a class="docs-footer-nextpage" href="../training_tips/local_minima/">Strategies to Avoid Local Minima »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Friday 2 February 2024 20:17">Friday 2 February 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
