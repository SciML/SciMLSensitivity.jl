<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Adjoint Sensitivity Analysis of Continuous Functionals Â· SciMLSensitivity.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://sensitivity.sciml.ai/stable/ad_examples/adjoint_continuous_functional/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="SciMLSensitivity.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">SciMLSensitivity.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">SciMLSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers</a></li><li><span class="tocitem">Tutorials</span><ul><li><input class="collapse-toggle" id="menuitem-2-1" type="checkbox" checked/><label class="tocitem" for="menuitem-2-1"><span class="docs-label">Differentiating Ordinary Differential Equations (ODE) Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../differentiating_ode/">Differentiating an ODE Solution with Automatic Differentiation</a></li><li><a class="tocitem" href="../direct_sensitivity/">Direct Sensitivity Analysis Functionality</a></li><li class="is-active"><a class="tocitem" href>Adjoint Sensitivity Analysis of Continuous Functionals</a><ul class="internal"><li><a class="tocitem" href="#Example:-Continuous-Functionals-with-Forward-Sensitivity-Analysis-via-Interpolation"><span>Example: Continuous Functionals with Forward Sensitivity Analysis via Interpolation</span></a></li><li><a class="tocitem" href="#Example:-Continuous-Adjoints-on-an-Energy-Functional"><span>Example: Continuous Adjoints on an Energy Functional</span></a></li></ul></li><li><a class="tocitem" href="../chaotic_ode/">Sensitivity analysis for chaotic systems (shadowing methods)</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Fitting Ordinary Differential Equation (ODE) Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../ode_fitting/optimization_ode/">Optimization of Ordinary Differential Equations</a></li><li><a class="tocitem" href="../../ode_fitting/stiff_ode_fit/">Parameter Estimation on Highly Stiff Systems</a></li><li><a class="tocitem" href="../../ode_fitting/exogenous_input/">Handling Exogenous Input Signals</a></li><li><a class="tocitem" href="../../ode_fitting/data_parallel/">Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching</a></li><li><a class="tocitem" href="../../ode_fitting/prediction_error_method/">Prediction error method (PEM)</a></li><li><a class="tocitem" href="../../ode_fitting/second_order_adjoints/">Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis</a></li><li><a class="tocitem" href="../../ode_fitting/second_order_neural/">Neural Second Order Ordinary Differential Equation</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Training Techniques and Tips</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../training_tips/local_minima/">Strategies to Avoid Local Minima</a></li><li><a class="tocitem" href="../../training_tips/divergence/">Handling Divergent and Unstable Trajectories</a></li><li><a class="tocitem" href="../../training_tips/multiple_nn/">Simultaneous Fitting of Multiple Neural Networks</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-4" type="checkbox"/><label class="tocitem" for="menuitem-2-4"><span class="docs-label">Neural Ordinary Differential Equation (Neural ODE) Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../neural_ode/neural_ode_flux/">Neural Ordinary Differential Equations with Flux</a></li><li><a class="tocitem" href="../../neural_ode/neural_gde/">Neural Graph Differential Equations</a></li><li><a class="tocitem" href="../../neural_ode/minibatch/">Training a Neural Ordinary Differential Equation with Mini-Batching</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-5" type="checkbox"/><label class="tocitem" for="menuitem-2-5"><span class="docs-label">Stochastic Differential Equation (SDE) Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sde_fitting/optimization_sde/">Optimization of Stochastic Differential Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-6" type="checkbox"/><label class="tocitem" for="menuitem-2-6"><span class="docs-label">Delay Differential Equation (DDE) Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../dde_fitting/delay_diffeq/">Delay Differential Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-7" type="checkbox"/><label class="tocitem" for="menuitem-2-7"><span class="docs-label">Differential-Algebraic Equation (DAE) Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../dae_fitting/physical_constraints/">Enforcing Physical Constraints via Universal Differential-Algebraic Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-8" type="checkbox"/><label class="tocitem" for="menuitem-2-8"><span class="docs-label">Partial Differential Equation (PDE) Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../pde_fitting/pde_constrained/">Partial Differential Equation (PDE) Constrained Optimization</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-9" type="checkbox"/><label class="tocitem" for="menuitem-2-9"><span class="docs-label">Hybrid and Jump Equation Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../hybrid_jump_fitting/hybrid_diffeq/">Training Neural Networks in Hybrid Differential Equations</a></li><li><a class="tocitem" href="../../hybrid_jump_fitting/bouncing_ball/">Bouncing Ball Hybrid ODE Optimization</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-10" type="checkbox"/><label class="tocitem" for="menuitem-2-10"><span class="docs-label">Bayesian Estimation Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/turing_bayesian/">Bayesian Estimation of Differential Equations with Probabilistic Programming</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-11" type="checkbox"/><label class="tocitem" for="menuitem-2-11"><span class="docs-label">Optimal and Model Predictive Control Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../optimal_control/optimal_control/">Solving Optimal Control Problems with Universal Differential Equations</a></li><li><a class="tocitem" href="../../optimal_control/feedback_control/">Universal Differential Equations for Neural Feedback Control</a></li><li><a class="tocitem" href="../../optimal_control/SDE_control/">Controlling Stochastic Differential Equations</a></li></ul></li></ul></li><li><span class="tocitem">Manual and APIs</span><ul><li><a class="tocitem" href="../../manual/differential_equation_sensitivities/">Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)</a></li><li><a class="tocitem" href="../../manual/nonlinear_solve_sensitivities/">Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)</a></li><li><a class="tocitem" href="../../manual/direct_forward_sensitivity/">Direct Forward Sensitivity Analysis of ODEs</a></li><li><a class="tocitem" href="../../manual/direct_adjoint_sensitivities/">Direct Adjoint Sensitivities of Differential Equations</a></li></ul></li><li><a class="tocitem" href="../../Benchmark/">Benchmarks</a></li><li><a class="tocitem" href="../../sensitivity_math/">Sensitivity Math Details</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li><a class="is-disabled">Differentiating Ordinary Differential Equations (ODE) Tutorials</a></li><li class="is-active"><a href>Adjoint Sensitivity Analysis of Continuous Functionals</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Adjoint Sensitivity Analysis of Continuous Functionals</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/SciMLSensitivity.jl/blob/master/docs/src/ad_examples/adjoint_continuous_functional.md" title="Edit on GitHub"><span class="docs-icon fab">ï</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="continuous_loss"><a class="docs-heading-anchor" href="#continuous_loss">Adjoint Sensitivity Analysis of Continuous Functionals</a><a id="continuous_loss-1"></a><a class="docs-heading-anchor-permalink" href="#continuous_loss" title="Permalink"></a></h1><p><a href="../differentiating_ode/#auto_diff">The automatic differentiation tutorial</a> demonstrated how to use AD packages like ForwardDiff.jl and Zygote.jl to compute derivatives of differential equation solutions with respect to initial conditions and parameters. The subsequent <a href="../direct_sensitivity/#direct_sensitivity">direct sensitivity analysis tutorial</a> showed how to directly use the SciMLSensitivity.jl internals to define and solve the augmented differential equation systems which are used in the automatic differentiation process.</p><p>While these internal functions give more flexibility, the previous demonstration focused on a case which was possible via automatic differentiation: discrete cost functionals. What is meant by discrete cost functionals is differentiation of a cost which uses a finite number of time points. In the automatic differentiation case, these finite time points are the points returned by <code>solve</code>, i.e. those chosen by the <code>saveat</code> option in the solve call. In the direct adjoint sensitivity tooling, these were the time points chosen by the <code>ts</code> vector.</p><p>However, there is an expanded set of cost functionals supported by SciMLSensitivity.jl, continuous cost functionals, which are not possible through automatic differentiation interfaces. In an abstract sense, a continuous cost functional is a total cost <span>$G$</span> defined as the integral of the instantanious cost <span>$g$</span> at all time points. In other words, the total cost is defined as:</p><p class="math-container">\[G(u,p)=G(u(\cdot,p))=\int_{t_{0}}^{T}g(u(t,p),p)dt\]</p><p>Notice that this cost function cannot accurately be computed using only estimates of <code>u</code> at discrete time points. The purpose of this tutorial is to demonstrate how such cost functionals can be easily evaluated using the direct sensitivity analysis interfaces.</p><h2 id="Example:-Continuous-Functionals-with-Forward-Sensitivity-Analysis-via-Interpolation"><a class="docs-heading-anchor" href="#Example:-Continuous-Functionals-with-Forward-Sensitivity-Analysis-via-Interpolation">Example: Continuous Functionals with Forward Sensitivity Analysis via Interpolation</a><a id="Example:-Continuous-Functionals-with-Forward-Sensitivity-Analysis-via-Interpolation-1"></a><a class="docs-heading-anchor-permalink" href="#Example:-Continuous-Functionals-with-Forward-Sensitivity-Analysis-via-Interpolation" title="Permalink"></a></h2><p>Evaluating continuous cost functionals with forward sensitivity analysis is rather straightforward since one can simply use the fact that the solution from <code>ODEForwardSensitivityProblem</code> is continuous when <code>dense=true</code>. For example,</p><pre><code class="language-julia hljs">using OrdinaryDiffEq, SciMLSensitivity

function f(du,u,p,t)
  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]
  du[2] = dy = -p[3]*u[2] + u[1]*u[2]
end

p = [1.5,1.0,3.0]
prob = ODEForwardSensitivityProblem(f,[1.0;1.0],(0.0,10.0),p)
sol = solve(prob,DP8())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">retcode: Success
Interpolation: specialized 7th order interpolation
t: 29-element Vector{Float64}:
  0.0
  0.0008156803234081559
  0.005709762263857092
  0.0350742539065507
  0.21126120376271237
  0.7310736576107115
  1.540222712617339
  1.8813610466661779
  2.152579392464959
  2.4063311841696478
  â®
  7.063355055637446
  7.725935939669195
  8.248979441432317
  8.558003582514011
  8.826370842927059
  9.171011754187145
  9.493946497917326
  9.834929283472757
 10.0
u: 29-element Vector{Vector{Float64}}:
 [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
 [1.000408588538797, 0.9983701355642965, 0.000816013510644824, 3.322154010506493e-7, -0.0008153483114736799, -3.320348233838799e-7, 3.3244140163739216e-7, -0.0008143507848015046]
 [1.0028915156848317, 0.9886535575433295, 0.005726241237749595, 1.6146661657253676e-5, -0.005693685298331232, -1.6085381411877104e-5, 1.622392391840203e-5, -0.005644946211107334]
 [1.0189121274128703, 0.9325571368196612, 0.035730565614057214, 0.0005806610224735032, -0.034509633035320036, -0.0005673264615114402, 0.0005982168608307318, -0.03270217921302392]
 [1.1547444753248808, 0.6650474487943194, 0.24252997273953153, 0.01620058797923608, -0.198498945739975, -0.014142604007354084, 0.019606496433572655, -0.13955624899729338]
 [1.9959026411822718, 0.30725094819300236, 1.3911332658550328, 0.12370946057242008, -0.7599570019860626, -0.07996649485520504, 0.22938885567774317, -0.20775306589835096]
 [5.30194567946053, 0.4275038176301537, 6.007173244666811, 1.378441778030569, -2.283870425183431, -0.623462248893163, 1.6987114297214083, -0.3708646913283792]
 [6.8702723310901295, 1.2712401591810842, 2.482449626359105, 6.439151700037799, -1.3710505647874744, -2.7849768648683777, 3.2715017511539424, -0.46731359361629526]
 [5.679446513843018, 3.3399703081159786, -12.310270279196507, 12.730860582111236, 2.90563205459914, -6.735838408409488, 2.6735629496567994, 0.8629101364446949]
 [2.8838282002507136, 4.57403857987998, -11.50192475754792, 1.5722474815418457, 3.149560282389645, -5.129125042632567, 0.2620888410181659, 1.5914280086423986]
 â®
 [1.4188559373191922, 0.45747117721990466, 4.0345730575991805, -1.6292340104788547, -0.02328531538568726, -0.22674039853297237, 0.9917652543963326, -0.638337264202254]
 [3.105286408605591, 0.25723901264027416, 12.030706505671914, 0.3657288649741977, -0.3594670814358994, -0.1562962149538488, 2.9860724103159155, -0.2135072543485681]
 [5.721950106631197, 0.5147791449780601, 19.322713832885665, 5.150407774561523, -0.8979267203135737, -0.4767887879979121, 5.4868266280623645, 0.4525830529452884]
 [6.9045644791116585, 1.4959711323293163, 0.8111460438513347, 21.257023017125366, -0.885529900291283, -1.837556476410295, 3.431317057907666, 3.210786998858488]
 [5.251408633416557, 3.677081894045012, -40.30711600763158, 31.383646964911545, 0.415505603414129, -4.822192363404264, -4.808988602487445, 6.282699534622149]
 [1.9684993733166822, 4.224446642146764, -19.72010623548457, -13.790594696972407, 0.6970930173849572, -4.432962960251689, -3.4673013009932574, -1.767994652510742]
 [1.0719720028424078, 2.5266939022673727, -4.294296713681639, -16.729797806817487, 0.3407022900162246, -2.2485501409033666, -0.8127688495258327, -3.42797696441485]
 [0.9574127494597999, 1.2680817248527774, 0.6626271434785644, -9.021542819507147, 0.21249816908491037, -1.0143392771168123, 0.21400382117613845, -2.2552162974026566]
 [1.026505547286025, 0.9095251254958595, 2.1626974566892803, -6.256489916332188, 0.1883893214244694, -0.6976152811241049, 0.5638188536930522, -1.7090441864606456]</code></pre><p>gives a continuous solution <code>sol(t)</code> with the derivative at each time point. This can then be used to define a continuous cost function via <a href="https://github.com/SciML/Integrals.jl">Integrals.jl</a>, though the derivative would need to be defined by hand using the extra sensitivity terms.</p><h2 id="Example:-Continuous-Adjoints-on-an-Energy-Functional"><a class="docs-heading-anchor" href="#Example:-Continuous-Adjoints-on-an-Energy-Functional">Example: Continuous Adjoints on an Energy Functional</a><a id="Example:-Continuous-Adjoints-on-an-Energy-Functional-1"></a><a class="docs-heading-anchor-permalink" href="#Example:-Continuous-Adjoints-on-an-Energy-Functional" title="Permalink"></a></h2><p>Continuous adjoints on a continuous functional are more automatic than forward mode. In this case we&#39;d like to calculate the adjoint sensitivity of the scalar energy functional:</p><p class="math-container">\[G(u,p)=\int_{0}^{T}\frac{\sum_{i=1}^{n}u_{i}^{2}(t)}{2}dt\]</p><p>which is:</p><pre><code class="language-julia hljs">g(u,p,t) = (sum(u).^2) ./ 2</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">g (generic function with 1 method)</code></pre><p>Notice that the gradient of this function with respect to the state <code>u</code> is:</p><pre><code class="language-julia hljs">function dg(out,u,p,t)
  out[1]= u[1] + u[2]
  out[2]= u[1] + u[2]
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">dg (generic function with 1 method)</code></pre><p>To get the adjoint sensitivities, we call:</p><pre><code class="language-julia hljs">prob = ODEProblem(f,[1.0;1.0],(0.0,10.0),p)
sol = solve(prob,DP8())
res = adjoint_sensitivities(sol,Vern9(),dgdu_continuous=dg,g=g,abstol=1e-8,reltol=1e-8)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([-57.4304576527421, -14.286740920907548], [21.070509833784705 -101.3664068223125 63.16462173070765])</code></pre><p>Notice that we can check this against autodifferentiation and numerical differentiation as follows:</p><pre><code class="language-julia hljs">using QuadGK, ForwardDiff, Calculus
function G(p)
  tmp_prob = remake(prob,p=p)
  sol = solve(tmp_prob,Vern9(),abstol=1e-14,reltol=1e-14)
  res,err = quadgk((t)-&gt; (sum(sol(t)).^2)./2,0.0,10.0,atol=1e-14,rtol=1e-10)
  res
end
res2 = ForwardDiff.gradient(G,[1.5,1.0,3.0])
res3 = Calculus.gradient(G,[1.5,1.0,3.0])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Float64}:
   21.051470346665642
 -101.40824363360299
   63.1928818469471</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../direct_sensitivity/">Â« Direct Sensitivity Analysis Functionality</a><a class="docs-footer-nextpage" href="../chaotic_ode/">Sensitivity analysis for chaotic systems (shadowing methods) Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.22 on <span class="colophon-date" title="Thursday 4 August 2022 18:15">Thursday 4 August 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
